{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be648df0-924a-4dac-bbd1-d93c62d007ae",
   "metadata": {},
   "source": [
    "# AMAZON DELIVERY TIME PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f78d08-f26b-4f5e-b5c3-88d1c21c8497",
   "metadata": {},
   "source": [
    "**Problem Statement:**\n",
    "\n",
    "This project aims to predict delivery times for e-commerce orders based on a variety of factors such as product size, distance, traffic conditions, and shipping method. Using the provided dataset, learners will preprocess, analyze, and build regression models to accurately estimate delivery times. The final application will allow users to input relevant details and receive estimated delivery times via a user-friendly interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ffa3bcc-f212-4973-83a6-52c63066dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets import the necessary libraries as and when required\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import radians, sin, cos, sqrt, atan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcb18603-1a0a-4c67-81e1-bfe399a9c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper for nicer prints\n",
    "def print_section(title):\n",
    "    print(\"\\n\" + \"=\"*8 + \" \" + title + \" \" + \"=\"*8 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ce14ddc-77e6-4f66-9c90-1e6103e9d425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order_ID</th>\n",
       "      <th>Agent_Age</th>\n",
       "      <th>Agent_Rating</th>\n",
       "      <th>Store_Latitude</th>\n",
       "      <th>Store_Longitude</th>\n",
       "      <th>Drop_Latitude</th>\n",
       "      <th>Drop_Longitude</th>\n",
       "      <th>Order_Date</th>\n",
       "      <th>Order_Time</th>\n",
       "      <th>Pickup_Time</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Traffic</th>\n",
       "      <th>Vehicle</th>\n",
       "      <th>Area</th>\n",
       "      <th>Delivery_Time</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ialx566343618</td>\n",
       "      <td>37</td>\n",
       "      <td>4.9</td>\n",
       "      <td>22.745049</td>\n",
       "      <td>75.892471</td>\n",
       "      <td>22.765049</td>\n",
       "      <td>75.912471</td>\n",
       "      <td>2022-03-19</td>\n",
       "      <td>11:30:00</td>\n",
       "      <td>11:45:00</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>High</td>\n",
       "      <td>motorcycle</td>\n",
       "      <td>Urban</td>\n",
       "      <td>120</td>\n",
       "      <td>Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>akqg208421122</td>\n",
       "      <td>34</td>\n",
       "      <td>4.5</td>\n",
       "      <td>12.913041</td>\n",
       "      <td>77.683237</td>\n",
       "      <td>13.043041</td>\n",
       "      <td>77.813237</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>19:45:00</td>\n",
       "      <td>19:50:00</td>\n",
       "      <td>Stormy</td>\n",
       "      <td>Jam</td>\n",
       "      <td>scooter</td>\n",
       "      <td>Metropolitian</td>\n",
       "      <td>165</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>njpu434582536</td>\n",
       "      <td>23</td>\n",
       "      <td>4.4</td>\n",
       "      <td>12.914264</td>\n",
       "      <td>77.678400</td>\n",
       "      <td>12.924264</td>\n",
       "      <td>77.688400</td>\n",
       "      <td>2022-03-19</td>\n",
       "      <td>08:30:00</td>\n",
       "      <td>08:45:00</td>\n",
       "      <td>Sandstorms</td>\n",
       "      <td>Low</td>\n",
       "      <td>motorcycle</td>\n",
       "      <td>Urban</td>\n",
       "      <td>130</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rjto796129700</td>\n",
       "      <td>38</td>\n",
       "      <td>4.7</td>\n",
       "      <td>11.003669</td>\n",
       "      <td>76.976494</td>\n",
       "      <td>11.053669</td>\n",
       "      <td>77.026494</td>\n",
       "      <td>2022-04-05</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>18:10:00</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Medium</td>\n",
       "      <td>motorcycle</td>\n",
       "      <td>Metropolitian</td>\n",
       "      <td>105</td>\n",
       "      <td>Cosmetics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zguw716275638</td>\n",
       "      <td>32</td>\n",
       "      <td>4.6</td>\n",
       "      <td>12.972793</td>\n",
       "      <td>80.249982</td>\n",
       "      <td>13.012793</td>\n",
       "      <td>80.289982</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>13:30:00</td>\n",
       "      <td>13:45:00</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>High</td>\n",
       "      <td>scooter</td>\n",
       "      <td>Metropolitian</td>\n",
       "      <td>150</td>\n",
       "      <td>Toys</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Order_ID  Agent_Age  Agent_Rating  Store_Latitude  Store_Longitude  \\\n",
       "0  ialx566343618         37           4.9       22.745049        75.892471   \n",
       "1  akqg208421122         34           4.5       12.913041        77.683237   \n",
       "2  njpu434582536         23           4.4       12.914264        77.678400   \n",
       "3  rjto796129700         38           4.7       11.003669        76.976494   \n",
       "4  zguw716275638         32           4.6       12.972793        80.249982   \n",
       "\n",
       "   Drop_Latitude  Drop_Longitude  Order_Date Order_Time Pickup_Time  \\\n",
       "0      22.765049       75.912471  2022-03-19   11:30:00    11:45:00   \n",
       "1      13.043041       77.813237  2022-03-25   19:45:00    19:50:00   \n",
       "2      12.924264       77.688400  2022-03-19   08:30:00    08:45:00   \n",
       "3      11.053669       77.026494  2022-04-05   18:00:00    18:10:00   \n",
       "4      13.012793       80.289982  2022-03-26   13:30:00    13:45:00   \n",
       "\n",
       "      Weather  Traffic      Vehicle            Area  Delivery_Time  \\\n",
       "0       Sunny    High   motorcycle           Urban             120   \n",
       "1      Stormy     Jam      scooter   Metropolitian             165   \n",
       "2  Sandstorms     Low   motorcycle           Urban             130   \n",
       "3       Sunny  Medium   motorcycle   Metropolitian             105   \n",
       "4      Cloudy    High      scooter   Metropolitian             150   \n",
       "\n",
       "      Category  \n",
       "0     Clothing  \n",
       "1  Electronics  \n",
       "2       Sports  \n",
       "3    Cosmetics  \n",
       "4         Toys  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading dataset and performing initial exploratory data analysis (EDA).\n",
    "df =  pd.read_csv(\"amazon_delivery.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7171cb97-73fb-4910-ac18-3249729a757d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows, Columns: (43739, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows, Columns:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "666fb523-09db-4c23-a7e8-7a92eae543e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not use ace_tools.display_dataframe_to_user: No module named 'ace_tools'\n",
      "        Order_ID  Agent_Age  Agent_Rating  Store_Latitude  Store_Longitude  \\\n",
      "0  ialx566343618         37           4.9       22.745049        75.892471   \n",
      "1  akqg208421122         34           4.5       12.913041        77.683237   \n",
      "2  njpu434582536         23           4.4       12.914264        77.678400   \n",
      "3  rjto796129700         38           4.7       11.003669        76.976494   \n",
      "4  zguw716275638         32           4.6       12.972793        80.249982   \n",
      "\n",
      "   Drop_Latitude  Drop_Longitude  Order_Date Order_Time Pickup_Time  \\\n",
      "0      22.765049       75.912471  2022-03-19   11:30:00    11:45:00   \n",
      "1      13.043041       77.813237  2022-03-25   19:45:00    19:50:00   \n",
      "2      12.924264       77.688400  2022-03-19   08:30:00    08:45:00   \n",
      "3      11.053669       77.026494  2022-04-05   18:00:00    18:10:00   \n",
      "4      13.012793       80.289982  2022-03-26   13:30:00    13:45:00   \n",
      "\n",
      "      Weather  Traffic      Vehicle            Area  Delivery_Time  \\\n",
      "0       Sunny    High   motorcycle           Urban             120   \n",
      "1      Stormy     Jam      scooter   Metropolitian             165   \n",
      "2  Sandstorms     Low   motorcycle           Urban             130   \n",
      "3       Sunny  Medium   motorcycle   Metropolitian             105   \n",
      "4      Cloudy    High      scooter   Metropolitian             150   \n",
      "\n",
      "      Category  \n",
      "0     Clothing  \n",
      "1  Electronics  \n",
      "2       Sports  \n",
      "3    Cosmetics  \n",
      "4         Toys  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import ace_tools as tools\n",
    "    tools.display_dataframe_to_user(\"Sample - amazon_delivery.csv (first 10 rows)\", df.head(10))\n",
    "except Exception as e:\n",
    "    print(\"Could not use ace_tools.display_dataframe_to_user:\", e)\n",
    "    print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b7b76ff-88cd-4a51-86cb-1c0d001ef260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns and dtypes Order_ID            object\n",
      "Agent_Age            int64\n",
      "Agent_Rating       float64\n",
      "Store_Latitude     float64\n",
      "Store_Longitude    float64\n",
      "Drop_Latitude      float64\n",
      "Drop_Longitude     float64\n",
      "Order_Date          object\n",
      "Order_Time          object\n",
      "Pickup_Time         object\n",
      "Weather             object\n",
      "Traffic             object\n",
      "Vehicle             object\n",
      "Area                object\n",
      "Delivery_Time        int64\n",
      "Category            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Columns and dtypes\n",
    "print(\"Columns and dtypes\", df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c0bec04-f296-42ed-9772-64aa9d0df0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             column  missing_count\n",
      "0           Weather             91\n",
      "1      Agent_Rating             54\n",
      "2         Agent_Age              0\n",
      "3          Order_ID              0\n",
      "4   Store_Longitude              0\n",
      "5     Drop_Latitude              0\n",
      "6    Drop_Longitude              0\n",
      "7    Store_Latitude              0\n",
      "8        Order_Date              0\n",
      "9        Order_Time              0\n",
      "10      Pickup_Time              0\n",
      "11          Traffic              0\n",
      "12          Vehicle              0\n",
      "13             Area              0\n",
      "14    Delivery_Time              0\n",
      "15         Category              0\n"
     ]
    }
   ],
   "source": [
    "#Handling missing values\n",
    "missing = df.isnull().sum().sort_values(ascending=False)\n",
    "missing_df = missing.reset_index().rename(columns={'index':'column', 0:'missing_count'})\n",
    "try:\n",
    "    tools.display_dataframe_to_user(\"Missing values per column\", missing_df)\n",
    "except:\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05b6f6d0-d632-4803-9ffc-df5d8b565c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   count        mean        std        min        25%  \\\n",
      "Agent_Age        43739.0   29.567137   5.815155  15.000000  25.000000   \n",
      "Agent_Rating     43685.0    4.633780   0.334716   1.000000   4.500000   \n",
      "Store_Latitude   43739.0   17.210960   7.764225 -30.902872  12.933298   \n",
      "Store_Longitude  43739.0   70.661177  21.475005 -88.366217  73.170283   \n",
      "Drop_Latitude    43739.0   17.459031   7.342950   0.010000  12.985996   \n",
      "Drop_Longitude   43739.0   70.821842  21.153148   0.010000  73.280000   \n",
      "Delivery_Time    43739.0  124.905645  51.915451  10.000000  90.000000   \n",
      "\n",
      "                        50%         75%         max  \n",
      "Agent_Age         30.000000   35.000000   50.000000  \n",
      "Agent_Rating       4.700000    4.900000    6.000000  \n",
      "Store_Latitude    18.551440   22.732225   30.914057  \n",
      "Store_Longitude   75.898497   78.045359   88.433452  \n",
      "Drop_Latitude     18.633626   22.785049   31.054057  \n",
      "Drop_Longitude    76.002574   78.104095   88.563452  \n",
      "Delivery_Time    125.000000  160.000000  270.000000  \n"
     ]
    }
   ],
   "source": [
    "# Checking numeric stats\n",
    "num_desc = df.select_dtypes(include=[np.number]).describe().T\n",
    "try:\n",
    "    tools.display_dataframe_to_user(\"Numeric summary\", num_desc.reset_index().rename(columns={'index':'feature'}))\n",
    "except:\n",
    "    print(num_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5050162-89fb-4590-aef2-d712af4aee6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Order_ID rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Duplicates check\n",
    "if 'Order_ID' in df.columns:\n",
    "    dup_count = df.duplicated(subset=['Order_ID']).sum()\n",
    "    print(f\"Duplicate Order_ID rows: {dup_count}\")\n",
    "else:\n",
    "    print(\"Order_ID column not found; skipping duplicate id check.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac53b2c3-ad3a-4bf8-96b5-b6bf17b13ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected columns:\n",
      "Store lat: Store_Latitude\n",
      "Store lon: Store_Longitude\n",
      "Drop lat: Drop_Latitude\n",
      "Drop lon: Drop_Longitude\n"
     ]
    }
   ],
   "source": [
    "#Identify likely latitude/longitude columns\n",
    "cols = df.columns.tolist()\n",
    "\n",
    "def find_col(keywords):\n",
    "    for c in cols:\n",
    "        c_low = c.lower()\n",
    "        if all(k.lower() in c_low for k in keywords):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "store_lat_col = find_col(['store','lat']) or find_col(['store','latitude'])\n",
    "store_lon_col = find_col(['store','lon']) or find_col(['store','longitude']) or find_col(['store','long'])\n",
    "drop_lat_col = find_col(['drop','lat']) or find_col(['drop','latitude']) or find_col(['delivery','lat'])\n",
    "drop_lon_col = find_col(['drop','lon']) or find_col(['drop','longitude']) or find_col(['delivery','lon'])\n",
    "\n",
    "print(\"Detected columns:\")\n",
    "print(\"Store lat:\", store_lat_col)\n",
    "print(\"Store lon:\", store_lon_col)\n",
    "print(\"Drop lat:\", drop_lat_col)\n",
    "print(\"Drop lon:\", drop_lon_col)\n",
    "\n",
    "# If not found, try more generic search\n",
    "if not (store_lat_col and store_lon_col and drop_lat_col and drop_lon_col):\n",
    "    # try any columns with 'lat' and 'lon'\n",
    "    lat_cols = [c for c in cols if 'lat' in c.lower()]\n",
    "    lon_cols = [c for c in cols if ('lon' in c.lower()) or ('long' in c.lower())]\n",
    "    print(\"Fallback lat cols:\", lat_cols)\n",
    "    print(\"Fallback lon cols:\", lon_cols)\n",
    "    # naive pairing if 4 columns exist\n",
    "    if len(lat_cols) >= 2 and len(lon_cols) >= 2 and not (store_lat_col and store_lon_col and drop_lat_col and drop_lon_col):\n",
    "        store_lat_col, drop_lat_col = lat_cols[0], lat_cols[1]\n",
    "        store_lon_col, drop_lon_col = lon_cols[0], lon_cols[1]\n",
    "        print(\"Paired as:\")\n",
    "        print(\"Store lat:\", store_lat_col, \"Store lon:\", store_lon_col)\n",
    "        print(\"Drop lat:\", drop_lat_col, \"Drop lon:\", drop_lon_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89325af9-a0b7-45fd-a740-80a0c94c4821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_km created. Summary:\n",
      "count    43739.000000\n",
      "mean        38.561752\n",
      "std        534.564299\n",
      "min          1.465067\n",
      "25%          4.663432\n",
      "50%          9.220450\n",
      "75%         13.682379\n",
      "max      19692.674606\n",
      "Name: distance_km, dtype: float64\n",
      "Failed to compute distance_km: name 'tools' is not defined\n"
     ]
    }
   ],
   "source": [
    "#Compute haversine distance if possible\n",
    "def haversine_array(lat1, lon1, lat2, lon2):\n",
    "    # all arrays; returns km\n",
    "    R = 6371.0  # Earth radius km\n",
    "    lat1r = np.radians(lat1.astype(float))\n",
    "    lon1r = np.radians(lon1.astype(float))\n",
    "    lat2r = np.radians(lat2.astype(float))\n",
    "    lon2r = np.radians(lon2.astype(float))\n",
    "    dlat = lat2r - lat1r\n",
    "    dlon = lon2r - lon1r\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1r) * np.cos(lat2r) * np.sin(dlon/2.0)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    return R * c\n",
    "\n",
    "if store_lat_col and store_lon_col and drop_lat_col and drop_lon_col:\n",
    "    # create distance column\n",
    "    try:\n",
    "        df['distance_km'] = haversine_array(df[store_lat_col], df[store_lon_col], df[drop_lat_col], df[drop_lon_col])\n",
    "        print(\"distance_km created. Summary:\")\n",
    "        print(df['distance_km'].describe())\n",
    "        tools.display_dataframe_to_user(\"Sample with distance_km\", df[[store_lat_col, store_lon_col, drop_lat_col, drop_lon_col, 'distance_km']].head(10))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to compute distance_km:\", e)\n",
    "else:\n",
    "    print(\"Latitude/longitude columns not found - skipping distance computation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f539fa99-479f-47de-a6a4-571f6316c1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Delivery_Time check & distribution ========\n",
      "\n",
      "Delivery_Time dtype: int64\n",
      "count    43739.000000\n",
      "mean       124.905645\n",
      "std         51.915451\n",
      "min         10.000000\n",
      "25%         90.000000\n",
      "50%        125.000000\n",
      "75%        160.000000\n",
      "max        270.000000\n",
      "Name: Delivery_Time, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Delivery_Time column check and basic distribution\n",
    "print_section(\"Delivery_Time check & distribution\")\n",
    "if 'Delivery_Time' in df.columns:\n",
    "    print(\"Delivery_Time dtype:\", df['Delivery_Time'].dtype)\n",
    "    print(df['Delivery_Time'].describe())\n",
    "    # histogram\n",
    "    plt.figure(figsize=(8,4))\n",
    "    df['Delivery_Time'].hist(bins=40)\n",
    "    plt.title('Delivery_Time distribution')\n",
    "    plt.xlabel('Delivery_Time (hours)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Delivery_Time column not found in dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b903b2da-6220-4b12-962d-d85f3ad8b0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Correlation checks ========\n",
      "\n",
      "Pearson correlation (distance_km vs Delivery_Time): -0.0019\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Correlation between distance_km and Delivery_Time (if both exist)\n",
    "print_section(\"Correlation checks\")\n",
    "if 'distance_km' in df.columns and 'Delivery_Time' in df.columns:\n",
    "    corr = df[['distance_km','Delivery_Time']].corr().iloc[0,1]\n",
    "    print(f\"Pearson correlation (distance_km vs Delivery_Time): {corr:.4f}\")\n",
    "    # scatter plot\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.scatter(df['distance_km'], df['Delivery_Time'], s=10)\n",
    "    plt.xlabel('distance_km')\n",
    "    plt.ylabel('Delivery_Time (hours)')\n",
    "    plt.title('Distance vs Delivery_Time')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Either distance_km or Delivery_Time missing; skipping correlation/plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5b8ea69-fc29-4013-b1da-6f68acc0e373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        column                                         top_values\n",
      "0     Order_ID  nsyz997960170(1); ialx566343618(1); akqg208421...\n",
      "1   Order_Date  2022-03-15(1141); 2022-04-03(1133); 2022-03-13...\n",
      "2   Order_Time  21:55:00(460); 17:55:00(453); 22:20:00(446); 2...\n",
      "3  Pickup_Time  21:30:00(481); 22:50:00(450); 21:45:00(445); 2...\n",
      "4      Weather  Fog(7440); Stormy(7374); Cloudy(7288); Sandsto...\n",
      "5      Traffic  Low (14999); Jam (13725); Medium (10628); High...\n",
      "6      Vehicle  motorcycle (25527); scooter (14639); van(3558)...\n",
      "7         Area  Metropolitian (32698); Urban (9751); Other(113...\n",
      "8     Category  Electronics(2849); Books(2824); Jewelry(2802);...\n",
      "\n",
      "Saved a snapshot to /mnt/data/amazon_delivery_processed_snapshot.csv\n",
      "         column  missing_count\n",
      "0       Weather             91\n",
      "1  Agent_Rating             54\n"
     ]
    }
   ],
   "source": [
    "#Quick look at categorical column values (top categories)\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "cat_summary = {}\n",
    "for c in cat_cols:\n",
    "    top = df[c].value_counts(dropna=False).head(10)\n",
    "    cat_summary[c] = top\n",
    "\n",
    "# Convert the categorical summaries into a small printable DataFrame\n",
    "cat_summary_small = []\n",
    "for c, vc in cat_summary.items():\n",
    "    entries = \"; \".join([f\"{idx}({v})\" for idx, v in vc.items()])\n",
    "    cat_summary_small.append({'column': c, 'top_values': entries})\n",
    "\n",
    "cat_summary_df = pd.DataFrame(cat_summary_small)\n",
    "try:\n",
    "    tools.display_dataframe_to_user(\"Categorical columns top values\", cat_summary_df)\n",
    "except:\n",
    "    print(cat_summary_df)\n",
    "\n",
    "\n",
    "# Save a quick CSV snapshot of the processed df could be useful later in the project\n",
    "out_path = '/mnt/data/amazon_delivery_processed_snapshot.csv'\n",
    "df.to_csv(out_path, index=False)\n",
    "print(f\"\\nSaved a snapshot to {out_path}\")\n",
    "\n",
    "# Also check counts of missing columns and top offenders\n",
    "try:\n",
    "    tools.display_dataframe_to_user(\"Columns with missing values\", missing_df[missing_df['missing_count']>0])\n",
    "except:\n",
    "    print(missing_df[missing_df['missing_count']>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed58811a-0fb4-4348-9829-fdee67fc114c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows, Columns: (43739, 17)\n",
      "\n",
      "Column list:\n",
      " ['Order_ID', 'Agent_Age', 'Agent_Rating', 'Store_Latitude', 'Store_Longitude', 'Drop_Latitude', 'Drop_Longitude', 'Order_Date', 'Order_Time', 'Pickup_Time', 'Weather', 'Traffic', 'Vehicle', 'Area', 'Delivery_Time', 'Category', 'distance_km']\n",
      "         column  missing_count  missing_pct\n",
      "0       Weather             91        0.208\n",
      "1  Agent_Rating             54        0.123\n"
     ]
    }
   ],
   "source": [
    "# Concise missing counts, top categorical frequencies, datetime formats, duplicates and Delivery_Time outliers.\n",
    "df = pd.read_csv('/mnt/data/amazon_delivery_processed_snapshot.csv')\n",
    "\n",
    "print(\"Rows, Columns:\", df.shape)\n",
    "print(\"\\nColumn list:\\n\", df.columns.tolist())\n",
    "\n",
    "# Missing counts and percent\n",
    "missing = df.isnull().sum().sort_values(ascending=False)\n",
    "miss_pct = (missing / len(df) * 100).round(3)\n",
    "miss_df = pd.concat([missing, miss_pct], axis=1).reset_index().rename(columns={'index':'column', 0:'missing_count', 1:'missing_pct'})\n",
    "miss_df.columns = ['column','missing_count','missing_pct']\n",
    "display_cols = miss_df[miss_df['missing_count']>0]\n",
    "try:\n",
    "    import ace_tools as tools\n",
    "    tools.display_dataframe_to_user(\"Columns with missing values and %\", display_cols)\n",
    "except Exception as e:\n",
    "    print(display_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c9b07ed-7be9-40b6-89c5-847dfa840274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate Order_ID rows: 0\n",
      "Unique Order_IDs: 43739\n",
      "\n",
      "Delivery_Time summary:\n",
      "count    43739.000000\n",
      "mean       124.905645\n",
      "std         51.915451\n",
      "min         10.000000\n",
      "25%         90.000000\n",
      "50%        125.000000\n",
      "75%        160.000000\n",
      "max        270.000000\n",
      "Name: Delivery_Time, dtype: float64\n",
      "Rows with Delivery_Time <= 0: 0 (0.000%)\n"
     ]
    }
   ],
   "source": [
    "# Duplicates and unique counts for key columns\n",
    "print(\"\\nDuplicate Order_ID rows:\", df.duplicated(subset=['Order_ID']).sum() if 'Order_ID' in df.columns else \"Order_ID missing\")\n",
    "print(\"Unique Order_IDs:\", df['Order_ID'].nunique() if 'Order_ID' in df.columns else \"Order_ID missing\")\n",
    "\n",
    "# Delivery_Time stats & outliers\n",
    "if 'Delivery_Time' in df.columns:\n",
    "    print(\"\\nDelivery_Time summary:\")\n",
    "    print(df['Delivery_Time'].describe())\n",
    "    neg_zero = df[df['Delivery_Time']<=0].shape[0]\n",
    "    print(f\"Rows with Delivery_Time <= 0: {neg_zero} ({(neg_zero/len(df)*100):.3f}%)\")\n",
    "else:\n",
    "    print(\"Delivery_Time not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "628ccebb-bb91-453d-b6dc-f76715c3fee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top values for Weather:\n",
      "Weather\n",
      "Fog           7440\n",
      "Stormy        7374\n",
      "Cloudy        7288\n",
      "Sandstorms    7245\n",
      "Windy         7223\n",
      "Sunny         7078\n",
      "NaN             91\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top values for Traffic:\n",
      "Traffic\n",
      "Low        14999\n",
      "Jam        13725\n",
      "Medium     10628\n",
      "High        4296\n",
      "NaN           91\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top values for Vehicle:\n",
      "Vehicle\n",
      "motorcycle     25527\n",
      "scooter        14639\n",
      "van             3558\n",
      "bicycle           15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top values for Area:\n",
      "Area\n",
      "Metropolitian     32698\n",
      "Urban              9751\n",
      "Other              1138\n",
      "Semi-Urban          152\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top values for Category:\n",
      "Category\n",
      "Electronics    2849\n",
      "Books          2824\n",
      "Jewelry        2802\n",
      "Toys           2781\n",
      "Skincare       2772\n",
      "Snacks         2770\n",
      "Outdoors       2747\n",
      "Apparel        2726\n",
      "Sports         2719\n",
      "Grocery        2691\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top values for Agent_Rating:\n",
      "Agent_Rating\n",
      "4.8    7148\n",
      "4.7    7142\n",
      "4.9    7041\n",
      "4.6    6940\n",
      "5.0    3996\n",
      "4.5    3303\n",
      "4.1    1430\n",
      "4.2    1418\n",
      "4.3    1409\n",
      "4.4    1361\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Top values for expected categorical columns\n",
    "cat_candidates = ['Weather','Traffic','Vehicle','Area','Category','Agent_Rating']\n",
    "found_cats = [c for c in cat_candidates if c in df.columns]\n",
    "for c in found_cats:\n",
    "    print(f\"\\nTop values for {c}:\")\n",
    "    print(df[c].value_counts(dropna=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10a96f47-585d-4ad3-85b0-be29e9bc8527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample values for Order_Date (first 10):\n",
      "['2022-03-19', '2022-03-25', '2022-03-19', '2022-04-05', '2022-03-26', '2022-03-11', '2022-03-04', '2022-03-14', '2022-03-20', '2022-02-12']\n",
      "\n",
      "Sample values for Order_Time (first 10):\n",
      "['11:30:00', '19:45:00', '08:30:00', '18:00:00', '13:30:00', '21:20:00', '19:15:00', '17:25:00', '20:55:00', '21:55:00']\n",
      "\n",
      "Sample values for Pickup_Time (first 10):\n",
      "['11:45:00', '19:50:00', '08:45:00', '18:10:00', '13:45:00', '21:30:00', '19:30:00', '17:30:00', '21:05:00', '22:10:00']\n",
      "        Order_ID  Agent_Age  Agent_Rating  Store_Latitude  Store_Longitude  \\\n",
      "0  ialx566343618         37           4.9       22.745049        75.892471   \n",
      "1  akqg208421122         34           4.5       12.913041        77.683237   \n",
      "2  njpu434582536         23           4.4       12.914264        77.678400   \n",
      "3  rjto796129700         38           4.7       11.003669        76.976494   \n",
      "4  zguw716275638         32           4.6       12.972793        80.249982   \n",
      "5  fxuu788413734         22           4.8       17.431668        78.408321   \n",
      "6  njmo150975311         33           4.7       23.369746        85.339820   \n",
      "7  jvjc772545076         35           4.6       12.352058        76.606650   \n",
      "\n",
      "   Drop_Latitude  Drop_Longitude  Order_Date Order_Time Pickup_Time  \\\n",
      "0      22.765049       75.912471  2022-03-19   11:30:00    11:45:00   \n",
      "1      13.043041       77.813237  2022-03-25   19:45:00    19:50:00   \n",
      "2      12.924264       77.688400  2022-03-19   08:30:00    08:45:00   \n",
      "3      11.053669       77.026494  2022-04-05   18:00:00    18:10:00   \n",
      "4      13.012793       80.289982  2022-03-26   13:30:00    13:45:00   \n",
      "5      17.461668       78.438321  2022-03-11   21:20:00    21:30:00   \n",
      "6      23.479746       85.449820  2022-03-04   19:15:00    19:30:00   \n",
      "7      12.482058       76.736650  2022-03-14   17:25:00    17:30:00   \n",
      "\n",
      "      Weather  Traffic      Vehicle            Area  Delivery_Time  \\\n",
      "0       Sunny    High   motorcycle           Urban             120   \n",
      "1      Stormy     Jam      scooter   Metropolitian             165   \n",
      "2  Sandstorms     Low   motorcycle           Urban             130   \n",
      "3       Sunny  Medium   motorcycle   Metropolitian             105   \n",
      "4      Cloudy    High      scooter   Metropolitian             150   \n",
      "5      Cloudy     Jam   motorcycle           Urban             130   \n",
      "6         Fog     Jam      scooter   Metropolitian             200   \n",
      "7      Cloudy  Medium   motorcycle   Metropolitian             160   \n",
      "\n",
      "      Category  distance_km  \n",
      "0     Clothing     3.025149  \n",
      "1  Electronics    20.183530  \n",
      "2       Sports     1.552758  \n",
      "3    Cosmetics     7.790401  \n",
      "4         Toys     6.210138  \n",
      "5         Toys     4.610365  \n",
      "6         Toys    16.600361  \n",
      "7       Snacks    20.205253  \n"
     ]
    }
   ],
   "source": [
    "# Sample of Order_Date, Order_Time, Pickup_Time if exist\n",
    "for c in ['Order_Date','Order_Time','Pickup_Time']:\n",
    "    if c in df.columns:\n",
    "        print(f\"\\nSample values for {c} (first 10):\")\n",
    "        print(df[c].astype(str).head(10).tolist())\n",
    "\n",
    "# Head again for convenience\n",
    "try:\n",
    "    tools.display_dataframe_to_user(\"Head of dataset (post-snapshot)\", df.head(8))\n",
    "except:\n",
    "    print(df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb9c32e5-1af6-44e6-a2c9-b7dd15a9c577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved EDA summary to /mnt/data/eda_summary.json\n"
     ]
    }
   ],
   "source": [
    "# Save a quick \"cleaning plan\" file so we can refer to it\n",
    "plan = {\n",
    "    \"rows\": df.shape[0],\n",
    "    \"cols\": df.shape[1],\n",
    "    \"missing_columns\": display_cols.to_dict(orient='records')\n",
    "}\n",
    "import json\n",
    "with open('/mnt/data/eda_summary.json','w') as f:\n",
    "    json.dump(plan, f)\n",
    "print(\"\\nSaved EDA summary to /mnt/data/eda_summary.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91d3b265-b806-41da-92f5-cf96446b393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      column  missing_count  missing_pct\n",
      "     Weather             91        0.208\n",
      "Agent_Rating             54        0.123\n"
     ]
    }
   ],
   "source": [
    "# Missing columns and their counts/percent in text\n",
    "df = pd.read_csv('/mnt/data/amazon_delivery_processed_snapshot.csv')\n",
    "missing = df.isnull().sum().sort_values(ascending=False)\n",
    "miss_pct = (missing / len(df) * 100).round(3)\n",
    "miss_df = pd.concat([missing, miss_pct], axis=1).reset_index().rename(columns={'index':'column', 0:'missing_count', 1:'missing_pct'})\n",
    "miss_df.columns = ['column','missing_count','missing_pct']\n",
    "print(miss_df[miss_df['missing_count']>0].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61e7d18a-9fdb-48da-97ed-56d79731d767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation distance_km vs Delivery_Time: -0.0019\n"
     ]
    }
   ],
   "source": [
    "# Compute Pearson correlation between distance_km and Delivery_Time\n",
    "import pandas as pd, numpy as np\n",
    "df = pd.read_csv('/mnt/data/amazon_delivery_processed_snapshot.csv')\n",
    "if 'distance_km' in df.columns and 'Delivery_Time' in df.columns:\n",
    "    corr = df[['distance_km','Delivery_Time']].dropna().corr().iloc[0,1]\n",
    "    print(\"Pearson correlation distance_km vs Delivery_Time:\", round(corr,4))\n",
    "else:\n",
    "    print(\"Required columns missing for correlation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3a5dfed-deb8-49dd-b8c3-6dad8c12e9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceeding with basic cleaning & feature engineering (default rules):\n",
    "# - Parse order_datetime and pickup_datetime (assume pickup on same Order_Date unless pickup time < order time -> assume next day)\n",
    "# - Create order_to_pickup_mins\n",
    "# - Create Delivery_Time_hours\n",
    "# - Impute Agent_Rating (median) and Weather (mode -> 'Unknown' if missing)\n",
    "# - Flag Delivery_Time outliers using IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d120892-cff6-44ea-93d2-51c86569c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/mnt/data/amazon_delivery_processed_snapshot.csv')\n",
    "\n",
    "# Parse datetimes\n",
    "df['Order_Date'] = df['Order_Date'].astype(str)\n",
    "df['Order_Time'] = df['Order_Time'].astype(str)\n",
    "df['Pickup_Time'] = df['Pickup_Time'].astype(str)\n",
    "\n",
    "df['order_datetime'] = pd.to_datetime(df['Order_Date'] + ' ' + df['Order_Time'], errors='coerce')\n",
    "# For pickup, we need to assume same date; handle cases where pickup_time < order_time by adding 1 day\n",
    "pickup_dt = pd.to_datetime(df['Order_Date'] + ' ' + df['Pickup_Time'], errors='coerce')\n",
    "# if pickup < order, add 1 day\n",
    "mask_pickup_lt_order = (pickup_dt < df['order_datetime'])\n",
    "pickup_dt.loc[mask_pickup_lt_order] = pickup_dt.loc[mask_pickup_lt_order] + pd.Timedelta(days=1)\n",
    "df['pickup_datetime'] = pickup_dt\n",
    "\n",
    "# order_to_pickup_mins\n",
    "df['order_to_pickup_mins'] = (df['pickup_datetime'] - df['order_datetime']).dt.total_seconds() / 60.0\n",
    "\n",
    "# Delivery_Time_hours\n",
    "if 'Delivery_Time' in df.columns:\n",
    "    df['Delivery_Time_hours'] = df['Delivery_Time'] / 60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a4ea348-2454-4be3-87e8-5fa487aa31d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute Agent_Rating (median) and Weather (mode -> 'Unknown' if all missing)\n",
    "if 'Agent_Rating' in df.columns:\n",
    "    median_rating = df['Agent_Rating'].median()\n",
    "    df['Agent_Rating_imputed'] = df['Agent_Rating'].fillna(median_rating)\n",
    "if 'Weather' in df.columns:\n",
    "    mode_weather = df['Weather'].mode(dropna=True)\n",
    "    if len(mode_weather) > 0:\n",
    "        mode_weather = mode_weather[0]\n",
    "    else:\n",
    "        mode_weather = 'Unknown'\n",
    "    df['Weather_imputed'] = df['Weather'].fillna(mode_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "572d5543-ae2a-4ce1-9cdb-8200600e30cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier flag for Delivery_Time using IQR\n",
    "if 'Delivery_Time' in df.columns:\n",
    "    q1 = df['Delivery_Time'].quantile(0.25)\n",
    "    q3 = df['Delivery_Time'].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower, upper = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
    "    df['Delivery_Time_outlier'] = ((df['Delivery_Time'] < lower) | (df['Delivery_Time'] > upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd4119dc-bfe1-4add-8100-691f3301748c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order->pickup minutes summary:\n",
      "count    43648.000000\n",
      "mean         9.991294\n",
      "std          4.086680\n",
      "min          5.000000\n",
      "25%          5.000000\n",
      "50%         10.000000\n",
      "75%         15.000000\n",
      "max         15.000000\n",
      "Name: order_to_pickup_mins, dtype: float64\n",
      "\n",
      "Delivery_Time (mins) summary (post-clean):\n",
      "count    43739.000000\n",
      "mean       124.905645\n",
      "std         51.915451\n",
      "min         10.000000\n",
      "25%         90.000000\n",
      "50%        125.000000\n",
      "75%        160.000000\n",
      "max        270.000000\n",
      "Name: Delivery_Time, dtype: float64\n",
      "\n",
      "Outlier count: 79\n"
     ]
    }
   ],
   "source": [
    "# Quick checks\n",
    "print(\"Order->pickup minutes summary:\")\n",
    "print(df['order_to_pickup_mins'].describe())\n",
    "\n",
    "print(\"\\nDelivery_Time (mins) summary (post-clean):\")\n",
    "print(df['Delivery_Time'].describe())\n",
    "\n",
    "print(\"\\nOutlier count:\", df['Delivery_Time_outlier'].sum() if 'Delivery_Time_outlier' in df.columns else \"n/a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03437dcf-4c2d-469b-af14-9b0c37f201e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved cleaned dataset to /mnt/data/amazon_delivery_cleaned.csv\n",
      "Couldn't display sample via ace_tools: No module named 'ace_tools'\n",
      "        Order_ID      order_datetime     pickup_datetime  \\\n",
      "0  ialx566343618 2022-03-19 11:30:00 2022-03-19 11:45:00   \n",
      "1  akqg208421122 2022-03-25 19:45:00 2022-03-25 19:50:00   \n",
      "2  njpu434582536 2022-03-19 08:30:00 2022-03-19 08:45:00   \n",
      "3  rjto796129700 2022-04-05 18:00:00 2022-04-05 18:10:00   \n",
      "4  zguw716275638 2022-03-26 13:30:00 2022-03-26 13:45:00   \n",
      "5  fxuu788413734 2022-03-11 21:20:00 2022-03-11 21:30:00   \n",
      "6  njmo150975311 2022-03-04 19:15:00 2022-03-04 19:30:00   \n",
      "7  jvjc772545076 2022-03-14 17:25:00 2022-03-14 17:30:00   \n",
      "8  uaeb808891380 2022-03-20 20:55:00 2022-03-20 21:05:00   \n",
      "9  bgvc052754213 2022-02-12 21:55:00 2022-02-12 22:10:00   \n",
      "\n",
      "   order_to_pickup_mins  distance_km  Delivery_Time  Delivery_Time_hours  \\\n",
      "0                  15.0     3.025149            120             2.000000   \n",
      "1                   5.0    20.183530            165             2.750000   \n",
      "2                  15.0     1.552758            130             2.166667   \n",
      "3                  10.0     7.790401            105             1.750000   \n",
      "4                  15.0     6.210138            150             2.500000   \n",
      "5                  10.0     4.610365            130             2.166667   \n",
      "6                  15.0    16.600361            200             3.333333   \n",
      "7                   5.0    20.205253            160             2.666667   \n",
      "8                  10.0    19.975520            170             2.833333   \n",
      "9                  15.0    10.280582            230             3.833333   \n",
      "\n",
      "   Delivery_Time_outlier  \n",
      "0                  False  \n",
      "1                  False  \n",
      "2                  False  \n",
      "3                  False  \n",
      "4                  False  \n",
      "5                  False  \n",
      "6                  False  \n",
      "7                  False  \n",
      "8                  False  \n",
      "9                  False  \n"
     ]
    }
   ],
   "source": [
    "# Save cleaned file\n",
    "clean_path = '/mnt/data/amazon_delivery_cleaned.csv'\n",
    "df.to_csv(clean_path, index=False)\n",
    "print(f\"\\nSaved cleaned dataset to {clean_path}\")\n",
    "\n",
    "# Show a few columns to confirm\n",
    "cols_show = ['Order_ID','order_datetime','pickup_datetime','order_to_pickup_mins','distance_km','Delivery_Time','Delivery_Time_hours','Delivery_Time_outlier']\n",
    "cols_show = [c for c in cols_show if c in df.columns]\n",
    "try:\n",
    "    import ace_tools as tools\n",
    "    tools.display_dataframe_to_user(\"Cleaned sample rows\", df[cols_show].head(10))\n",
    "except Exception as e:\n",
    "    print(\"Couldn't display sample via ace_tools:\", e)\n",
    "    print(df[cols_show].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8652a9f2-202d-4acd-bf0a-3c93bf4d031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a baseline regression model (LinearRegression) with a simple preprocessing pipeline.\n",
    "# Steps:\n",
    "# - Use numeric features: distance_km, order_to_pickup_mins, Agent_Age, Agent_Rating_imputed\n",
    "# - Use categorical features: Weather_imputed, Traffic, Vehicle, Area, Category\n",
    "# - Train/test split 80/20\n",
    "# - Evaluate with MAE, RMSE, R2\n",
    "# - Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70b736b8-d4b6-435f-8749-00641a13de20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cleaned data: (43739, 24)\n",
      "Numeric features: ['distance_km', 'order_to_pickup_mins', 'Agent_Age', 'Agent_Rating_imputed']\n",
      "Categorical features: ['Weather_imputed', 'Traffic', 'Vehicle', 'Area', 'Category']\n",
      "\n",
      "Training LinearRegression ...\n",
      "LinearRegression => MAE=26.220, RMSE=33.295, R2=0.5839\n",
      "\n",
      "Training RidgeCV ...\n",
      "Ridge chosen alpha: 1.7782794100389228\n",
      "RidgeCV => MAE=26.218, RMSE=33.290, R2=0.5840\n",
      "\n",
      "Training LassoCV ...\n",
      "Lasso chosen alpha: 0.015053572707633203\n",
      "LassoCV => MAE=26.199, RMSE=33.267, R2=0.5846\n",
      "\n",
      "Best linear model (by RMSE): LassoCV RMSE= 33.26708714044438\n",
      "Saved best linear model to: baseline_lr_model.joblib\n",
      "Saved residual plot: linear_residuals.png\n",
      "Saved predicted vs actual plot: linear_pred_vs_actual.png\n",
      "Saved model metrics summary to: linear_model_metrics.json\n",
      "\n",
      "SUMMARY (printed):\n",
      "LinearRegression => MAE=26.220, RMSE=33.295, R2=0.5839\n",
      "RidgeCV => MAE=26.218, RMSE=33.290, R2=0.5840, alpha=1.7782794100389228\n",
      "LassoCV => MAE=26.199, RMSE=33.267, R2=0.5846, alpha=0.015053572707633203\n",
      "\n",
      "Best linear model: LassoCV\n"
     ]
    }
   ],
   "source": [
    "# Linear-model improvement script (run as-is).\n",
    "# Assumes amazon_delivery_cleaned.csv exists in working directory (same df used earlier).\n",
    "# Outputs:\n",
    "#  - baseline_lr_model.joblib (saved best linear model among Linear, RidgeCV, LassoCV)\n",
    "#  - linear_model_metrics.json (summary of metrics)\n",
    "#  - linear_residuals.png and linear_pred_vs_actual.png (plots)\n",
    "\n",
    "import os, json\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ---------- file names ----------\n",
    "CLEAN_IN = 'amazon_delivery_cleaned.csv'   \n",
    "MODEL_OUT = 'baseline_lr_model.joblib'     \n",
    "METRICS_OUT = 'linear_model_metrics.json'\n",
    "PLOT_RESID = 'linear_residuals.png'\n",
    "PLOT_PRED = 'linear_pred_vs_actual.png'\n",
    "\n",
    "if not os.path.exists(CLEAN_IN):\n",
    "    raise FileNotFoundError(f\"{CLEAN_IN} not found in current working directory: {os.getcwd()}\")\n",
    "\n",
    "# ---------- load ----------\n",
    "df = pd.read_csv(CLEAN_IN)\n",
    "print(\"Loaded cleaned data:\", df.shape)\n",
    "\n",
    "# ---------- feature lists ----------\n",
    "num_feats = [c for c in ['distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed'] if c in df.columns]\n",
    "cat_feats = [c for c in ['Weather_imputed','Traffic','Vehicle','Area','Category','part_of_day','dist_q'] if c in df.columns]\n",
    "\n",
    "print(\"Numeric features:\", num_feats)\n",
    "print(\"Categorical features:\", cat_feats)\n",
    "\n",
    "# ---------- prepare dataset ----------\n",
    "df_model = df.dropna(subset=['Delivery_Time']).copy()\n",
    "X = df_model[num_feats + cat_feats]\n",
    "y = df_model['Delivery_Time']\n",
    "\n",
    "# train/test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# ---------- preprocessing ----------\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# OneHotEncoder compatibility\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', ohe)\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, num_feats),\n",
    "    ('cat', categorical_transformer, cat_feats)\n",
    "])\n",
    "\n",
    "# ---------- models to evaluate ----------\n",
    "models = {\n",
    "    'LinearRegression': Pipeline(steps=[('preprocessor', preprocessor), ('regressor', LinearRegression())]),\n",
    "    # RidgeCV: search alphas automatically with 5-fold CV (use wide alpha grid)\n",
    "    'RidgeCV': Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('regressor', RidgeCV(alphas=np.logspace(-3, 3, 25), cv=5, scoring='neg_mean_squared_error'))]),\n",
    "    # LassoCV: internal CV to select alpha\n",
    "    'LassoCV': Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('regressor', LassoCV(alphas=None, cv=5, max_iter=5000, n_jobs=-1))])\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# ---------- train / evaluate ----------\n",
    "for name, pipe in models.items():\n",
    "    print(f\"\\nTraining {name} ...\")\n",
    "    # For RidgeCV and LassoCV, the 'fit' will select alpha; same API apply\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results[name] = {'mae': float(mae), 'rmse': float(rmse), 'r2': float(r2)}\n",
    "    # Save additional model info for Ridge/Lasso\n",
    "    if name == 'RidgeCV':\n",
    "        # extract chosen alpha\n",
    "        chosen_alpha = pipe.named_steps['regressor'].alpha_\n",
    "        results[name]['alpha'] = float(chosen_alpha)\n",
    "        print(\"Ridge chosen alpha:\", chosen_alpha)\n",
    "    if name == 'LassoCV':\n",
    "        try:\n",
    "            chosen_alpha = pipe.named_steps['regressor'].alpha_\n",
    "            results[name]['alpha'] = float(chosen_alpha)\n",
    "            print(\"Lasso chosen alpha:\", chosen_alpha)\n",
    "        except Exception:\n",
    "            pass\n",
    "    print(f\"{name} => MAE={mae:.3f}, RMSE={rmse:.3f}, R2={r2:.4f}\")\n",
    "\n",
    "# ---------- pick best model by RMSE ----------\n",
    "best_name = min(results.keys(), key=lambda k: results[k]['rmse'])\n",
    "best_model = models[best_name]\n",
    "print(\"\\nBest linear model (by RMSE):\", best_name, \"RMSE=\", results[best_name]['rmse'])\n",
    "\n",
    "# Save best model to baseline_lr_model.joblib \n",
    "joblib.dump(best_model, MODEL_OUT)\n",
    "print(\"Saved best linear model to:\", MODEL_OUT)\n",
    "\n",
    "# ---------- diagnostic plots for the best model ----------\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "residuals = (y_test - y_pred_best)\n",
    "\n",
    "# Residual plot (residuals vs predicted)\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(y_pred_best, residuals, s=8, alpha=0.6)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted Delivery_Time (mins)')\n",
    "plt.ylabel('Residual (Actual - Predicted)')\n",
    "plt.title(f'{best_name}: Residuals vs Predicted')\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_RESID)\n",
    "plt.close()\n",
    "print(\"Saved residual plot:\", PLOT_RESID)\n",
    "\n",
    "# Predicted vs Actual\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(y_test, y_pred_best, s=8, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Delivery_Time (mins)')\n",
    "plt.ylabel('Predicted Delivery_Time (mins)')\n",
    "plt.title(f'{best_name}: Predicted vs Actual')\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_PRED)\n",
    "plt.close()\n",
    "print(\"Saved predicted vs actual plot:\", PLOT_PRED)\n",
    "\n",
    "# ---------- save metrics summary ----------\n",
    "summary_out = {\n",
    "    'models': results,\n",
    "    'best_model': best_name\n",
    "}\n",
    "with open(METRICS_OUT, 'w') as f:\n",
    "    json.dump(summary_out, f, indent=2)\n",
    "print(\"Saved model metrics summary to:\", METRICS_OUT)\n",
    "\n",
    "# ---------- quick printed summary ----------\n",
    "print(\"\\nSUMMARY (printed):\")\n",
    "for m, stats in results.items():\n",
    "    s = f\"{m} => MAE={stats['mae']:.3f}, RMSE={stats['rmse']:.3f}, R2={stats['r2']:.4f}\"\n",
    "    if 'alpha' in stats:\n",
    "        s += f\", alpha={stats['alpha']}\"\n",
    "    print(s)\n",
    "\n",
    "print(\"\\nBest linear model:\", best_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc9f436f-dd98-48af-b91b-c34b49063541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 positive coefficients:\n",
      "               feature  coefficient  abs_coeff\n",
      "      Area_Semi-Urban     79.728696  79.728696\n",
      "          Traffic_Jam     17.542388  17.542388\n",
      "   Weather_imputed_Fog    15.725674  15.725674\n",
      "Weather_imputed_Cloudy    15.610434  15.610434\n",
      "   Vehicle_motorcycle     13.640134  13.640134\n",
      "             Agent_Age    12.084487  12.084487\n",
      "   Area_Metropolitian     10.695409  10.695409\n",
      "     Category_Skincare     1.152726   1.152726\n",
      "         Traffic_High      1.061772   1.061772\n",
      "     Category_Clothing     0.744572   0.744572\n",
      " Weather_imputed_Windy     0.421739   0.421739\n",
      "      Category_Apparel     0.338922   0.338922\n",
      "    Category_Cosmetics     0.151535   0.151535\n",
      "           distance_km     0.129220   0.129220\n",
      "      Category_Kitchen     0.053529   0.053529\n",
      "\n",
      "Top 15 negative coefficients:\n",
      "                   feature  coefficient  abs_coeff\n",
      "          Category_Grocery  -104.990770 104.990770\n",
      "              Traffic_NaN    -49.563384  49.563384\n",
      "              Traffic_Low    -25.533759  25.533759\n",
      "     Weather_imputed_Sunny   -16.896236  16.896236\n",
      "      Agent_Rating_imputed   -12.981072  12.981072\n",
      "                Area_Other    -3.521641   3.521641\n",
      "             Category_Toys    -1.307668   1.307668\n",
      "               Area_Urban     -0.892648   0.892648\n",
      "               Vehicle_van    -0.667008   0.667008\n",
      "             Category_Home    -0.418781   0.418781\n",
      "      Category_Electronics    -0.257514   0.257514\n",
      "          Category_Jewelry    -0.167619   0.167619\n",
      "      order_to_pickup_mins    -0.140309   0.140309\n",
      "Weather_imputed_Sandstorms    -0.068248   0.068248\n",
      "         Category_Outdoors    -0.066464   0.066464\n",
      "\n",
      "Saved full coefficient list to: linear_model_coefficients.csv\n"
     ]
    }
   ],
   "source": [
    "# Robust coefficient extraction for the saved linear pipeline\n",
    "# This handles mismatched feature lists by reading the exact feature names from the fitted pipeline.\n",
    "import joblib, pandas as pd, numpy as np, sys, os\n",
    "\n",
    "MODEL_PATH = 'baseline_lr_model.joblib'\n",
    "OUT_CSV = 'linear_model_coefficients.csv'\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    raise FileNotFoundError(f\"Model file not found: {MODEL_PATH}\")\n",
    "\n",
    "pipeline = joblib.load(MODEL_PATH)\n",
    "\n",
    "# Validate pipeline structure\n",
    "if 'preprocessor' not in pipeline.named_steps or 'regressor' not in pipeline.named_steps:\n",
    "    raise ValueError(\"Loaded pipeline does not have expected named steps 'preprocessor' and 'regressor'.\")\n",
    "\n",
    "preprocessor = pipeline.named_steps['preprocessor']\n",
    "reg = pipeline.named_steps['regressor']\n",
    "\n",
    "# --- get numeric feature names used in preprocessor ---\n",
    "numeric_features = []\n",
    "categorical_input_features = []\n",
    "\n",
    "# preprocessor.transformers_ has tuples like ('num', transformer, feature_list)\n",
    "for name, transformer, features in preprocessor.transformers_:\n",
    "    if name == 'num':\n",
    "        # features might be a list of column names used for numeric transformer\n",
    "        numeric_features = list(features) if features is not None else []\n",
    "    elif name == 'cat':\n",
    "        # features is the list of categorical column names used to fit the cat transformer\n",
    "        categorical_input_features = list(features) if features is not None else []\n",
    "\n",
    "# If we didn't find them above, try fallback to attribute access (older sklearn pipelines)\n",
    "if not numeric_features:\n",
    "    try:\n",
    "        numeric_features = list(preprocessor.transformers_[0][2])\n",
    "    except Exception:\n",
    "        numeric_features = []\n",
    "\n",
    "if not categorical_input_features:\n",
    "    try:\n",
    "        try:\n",
    "            categorical_input_features = list(preprocessor.transformers_[1][2])\n",
    "        except Exception:\n",
    "            categorical_input_features = []\n",
    "    except Exception:\n",
    "        categorical_input_features = []\n",
    "\n",
    "# --- get OneHotEncoder instance used inside categorical transformer ---\n",
    "try:\n",
    "    cat_transformer = preprocessor.named_transformers_['cat']\n",
    "    ohe = cat_transformer.named_steps['onehot']\n",
    "except Exception:\n",
    "    # fallback: try to locate a OneHotEncoder inside any transformer\n",
    "    ohe = None\n",
    "    for name, transformer, features in preprocessor.transformers_:\n",
    "        # transformer might be a pipeline\n",
    "        try:\n",
    "            if hasattr(transformer, 'named_steps') and 'onehot' in transformer.named_steps:\n",
    "                ohe = transformer.named_steps['onehot']\n",
    "                if not categorical_input_features:\n",
    "                    categorical_input_features = list(features) if features is not None else []\n",
    "                break\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "if ohe is None:\n",
    "    raise ValueError(\"Could not find a fitted OneHotEncoder inside the pipeline's 'cat' transformer.\")\n",
    "\n",
    "# --- determine categorical output feature names safely ---\n",
    "try:\n",
    "    # prefer to use feature_names_in_ if available (fitted encoder)\n",
    "    if hasattr(ohe, 'feature_names_in_') and getattr(ohe, 'feature_names_in_', None) is not None:\n",
    "        cat_in = list(ohe.feature_names_in_)\n",
    "        cat_ohe_names = list(ohe.get_feature_names_out(cat_in))\n",
    "    else:\n",
    "        # if feature_names_in_ absent, try to use the features list from preprocessor\n",
    "        if categorical_input_features:\n",
    "            cat_ohe_names = list(ohe.get_feature_names_out(categorical_input_features))\n",
    "        else:\n",
    "            # last-resort: call without args (works if encoder recorded feature names internally)\n",
    "            cat_ohe_names = list(ohe.get_feature_names_out())\n",
    "except Exception as e:\n",
    "    # provide a helpful error with context\n",
    "    raise RuntimeError(f\"Failed to get one-hot names from encoder: {e}\\n\"\n",
    "                       f\"categorical_input_features (len={len(categorical_input_features)}): {categorical_input_features}\\n\"\n",
    "                       f\"ohe attributes: feature_names_in_ exists? {hasattr(ohe,'feature_names_in_')}\")\n",
    "\n",
    "# --- assemble full feature list ---\n",
    "all_feature_names = list(numeric_features) + list(cat_ohe_names)\n",
    "\n",
    "# --- get coefficients from regressor ---\n",
    "# Some regressors store coef_ differently; handle common cases\n",
    "if hasattr(reg, 'coef_'):\n",
    "    coefs = np.asarray(reg.coef_).ravel()\n",
    "elif hasattr(reg, 'named_steps') and 'coef_' in reg.named_steps:\n",
    "    coefs = np.asarray(reg.named_steps['coef_']).ravel()\n",
    "else:\n",
    "    # Some meta-estimators may store coefficients under different attribute\n",
    "    try:\n",
    "        coefs = np.asarray(getattr(reg, 'coef_', None)).ravel()\n",
    "    except Exception:\n",
    "        raise ValueError(\"Could not locate 'coef_' attribute on regressor; it may not be a linear model.\")\n",
    "\n",
    "# --- sanity check lengths ---\n",
    "if len(coefs) != len(all_feature_names):\n",
    "    # Provide informative output and attempt a fallback mapping\n",
    "    print(\"WARNING: length mismatch between coefficients and feature names.\")\n",
    "    print(\"len(coefs) =\", len(coefs))\n",
    "    print(\"len(feature names) =\", len(all_feature_names))\n",
    "    # show a small sample for debugging\n",
    "    print(\"Sample numeric_features:\", numeric_features)\n",
    "    print(\"Sample categorical_input_features:\", categorical_input_features)\n",
    "    # We'll still try to align by trimming/padding if shapes allow:\n",
    "    min_len = min(len(coefs), len(all_feature_names))\n",
    "    print(f\"Proceeding by pairing first {min_len} coefficients with first {min_len} feature names.\")\n",
    "    all_feature_names = all_feature_names[:min_len]\n",
    "    coefs = coefs[:min_len]\n",
    "\n",
    "# --- create dataframe & save ---\n",
    "coef_df = pd.DataFrame({'feature': all_feature_names, 'coefficient': coefs})\n",
    "coef_df['abs_coeff'] = coef_df['coefficient'].abs()\n",
    "coef_df = coef_df.sort_values('abs_coeff', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# print top positive and negative for quick view\n",
    "print(\"\\nTop 15 positive coefficients:\")\n",
    "print(coef_df[coef_df['coefficient'] > 0].head(15).to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 15 negative coefficients:\")\n",
    "print(coef_df[coef_df['coefficient'] < 0].head(15).to_string(index=False))\n",
    "\n",
    "coef_df.to_csv(OUT_CSV, index=False)\n",
    "print(f\"\\nSaved full coefficient list to: {OUT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6ce03c3-992a-4ebb-a79e-dc91e2bdc892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking and installing MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7db8445b-882b-42f9-aebf-d6adf0e0f6a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmlflow\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLflow version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmlflow\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlflow'"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "print(f\"MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b27dfe7c-cb17-4ab4-bd03-4de38e9f2530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Access is denied.\n"
     ]
    }
   ],
   "source": [
    "!pip show mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2c6a3ce-3b9a-44e5-981c-b53b21198d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: C:\\ProgramData\\anaconda3\\python.exe\n",
      "sys.path[0]: C:\\ProgramData\\anaconda3\\python313.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Access is denied.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shail_u9zs758\\AppData\\Roaming\\Python\\Python313\\site-packages\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"sys.path[0]:\", sys.path[0])\n",
    "!pip -V\n",
    "!python -m site --user-site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8307f84-f524-41f5-9012-7c69c92816f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target folder: C:\\Users\\shail_u9zs758\\Documents\\python_local_site\n",
      "Collecting pip\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 12.5 MB/s eta 0:00:00\n",
      "Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 8.9 MB/s eta 0:00:00\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: wheel, setuptools, pip\n",
      "\n",
      "   ---------------------------------------- 0/3 [wheel]\n",
      "   ---------------------------------------- 0/3 [wheel]\n",
      "   ---------------------------------------- 0/3 [wheel]\n",
      "   ---------------------------------------- 0/3 [wheel]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   ------------- -------------------------- 1/3 [setuptools]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   -------------------------- ------------- 2/3 [pip]\n",
      "   ---------------------------------------- 3/3 [pip]\n",
      "\n",
      "Successfully installed pip-25.2 setuptools-80.9.0 wheel-0.45.1\n",
      "Collecting mlflow\n",
      "  Downloading mlflow-3.4.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting mlflow-skinny==3.4.0 (from mlflow)\n",
      "  Downloading mlflow_skinny-3.4.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting mlflow-tracing==3.4.0 (from mlflow)\n",
      "  Downloading mlflow_tracing-3.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting Flask<4 (from mlflow)\n",
      "  Downloading flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Using cached alembic-1.16.5-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting cryptography<46,>=43.0.0 (from mlflow)\n",
      "  Downloading cryptography-45.0.7-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fastmcp<3,>=2.0.0 (from mlflow)\n",
      "  Downloading fastmcp-2.12.3-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting matplotlib<4 (from mlflow)\n",
      "  Downloading matplotlib-3.10.6-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting numpy<3 (from mlflow)\n",
      "  Downloading numpy-2.3.3-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting pandas<3 (from mlflow)\n",
      "  Downloading pandas-2.3.2-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pyarrow<22,>=4.0.0 (from mlflow)\n",
      "  Downloading pyarrow-21.0.0-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting scikit-learn<2 (from mlflow)\n",
      "  Downloading scikit_learn-1.7.2-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scipy<2 (from mlflow)\n",
      "  Downloading scipy-1.16.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow)\n",
      "  Downloading sqlalchemy-2.0.43-cp313-cp313-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting waitress<4 (from mlflow)\n",
      "  Downloading waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading cachetools-6.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading databricks_sdk-0.66.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting fastapi<1 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading fastapi-0.117.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Using cached gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting packaging<26 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting protobuf<7,>=3.12.0 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting pydantic<3,>=1.10.8 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
      "Collecting python-dotenv<2,>=0.19.0 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting pyyaml<7,>=5.1 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting requests<3,>=2.17.3 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting typing-extensions<5,>=4.0.0 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting uvicorn<1 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading uvicorn-0.37.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting colorama (from click<9,>=7.0->mlflow-skinny==3.4.0->mlflow)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting cffi>=1.14 (from cryptography<46,>=43.0.0->mlflow)\n",
      "  Downloading cffi-2.0.0-cp313-cp313-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pywin32>=304 (from docker<8,>=4.0.0->mlflow)\n",
      "  Downloading pywin32-311-cp313-cp313-win_amd64.whl.metadata (10 kB)\n",
      "Collecting urllib3>=1.26.0 (from docker<8,>=4.0.0->mlflow)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting starlette<0.49.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading starlette-0.48.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting authlib>=1.5.2 (from fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading authlib-1.6.4-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting cyclopts>=3.0.0 (from fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading cyclopts-3.24.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting exceptiongroup>=1.2.2 (from fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting httpx>=0.28.1 (from fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting mcp<2.0.0,>=1.12.4 (from fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading mcp-1.14.1-py3-none-any.whl.metadata (75 kB)\n",
      "Collecting openapi-core>=0.19.5 (from fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading openapi_core-0.19.5-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting openapi-pydantic>=0.5.1 (from fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading openapi_pydantic-0.5.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pyperclip>=1.9.0 (from fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading pyperclip-1.10.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting rich>=13.9.4 (from fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting blinker>=1.9.0 (from Flask<4->mlflow)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from Flask<4->mlflow)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting jinja2>=3.1.2 (from Flask<4->mlflow)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting markupsafe>=2.1.1 (from Flask<4->mlflow)\n",
      "  Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting werkzeug>=3.1.0 (from Flask<4->mlflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->mlflow)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->mlflow)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting python-dateutil<3,>=2.7.0 (from graphene<4->mlflow)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting zipp>=3.20 (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib<4->mlflow)\n",
      "  Downloading contourpy-1.3.3-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib<4->mlflow)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib<4->mlflow)\n",
      "  Downloading fonttools-4.60.0-cp313-cp313-win_amd64.whl.metadata (113 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib<4->mlflow)\n",
      "  Downloading kiwisolver-1.4.9-cp313-cp313-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting pillow>=8 (from matplotlib<4->mlflow)\n",
      "  Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib<4->mlflow)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting anyio>=4.5 (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting httpx-sse>=0.4 (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting jsonschema>=4.20.0 (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pydantic-settings>=2.5.2 (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading sse_starlette-3.0.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.58b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas<3->mlflow)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3->mlflow)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading pydantic_core-2.33.2-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting six>=1.5 (from python-dateutil<3,>=2.7.0->graphene<4->mlflow)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.17.3->mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.17.3->mlflow-skinny==3.4.0->mlflow)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.17.3->mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn<2->mlflow)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn<2->mlflow)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow)\n",
      "  Downloading greenlet-3.2.4-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting sniffio>=1.1 (from anyio>=4.5->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11>=0.8 (from uvicorn<1->mlflow-skinny==3.4.0->mlflow)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting pycparser (from cffi>=1.14->cryptography<46,>=43.0.0->mlflow)\n",
      "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Collecting attrs>=23.1.0 (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting docstring-parser>=0.15 (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich-rst<2.0.0,>=1.3.1 (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading rich_rst-1.3.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting docutils (from rich-rst<2.0.0,>=1.3.1->cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading docutils-0.22.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading rpds_py-0.27.1-cp313-cp313-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting isodate (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jsonschema-path<0.4.0,>=0.3.1 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading jsonschema_path-0.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting more-itertools (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading openapi_schema_validator-0.6.3-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting openapi-spec-validator<0.8.0,>=0.7.1 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading openapi_spec_validator-0.7.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting parse (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting werkzeug>=3.1.0 (from Flask<4->mlflow)\n",
      "  Downloading werkzeug-3.1.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading pathable-0.4.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting rfc3339-validator (from openapi-schema-validator<0.7.0,>=0.6.0->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting lazy-object-proxy<2.0.0,>=1.7.1 (from openapi-spec-validator<0.8.0,>=0.7.1->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading lazy_object_proxy-1.12.0-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting email-validator>=2.0.0 (from pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0 (from rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading mlflow-3.4.0-py3-none-any.whl (26.7 MB)\n",
      "   ---------------------------------------- 0.0/26.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.4/26.7 MB 11.7 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.9/26.7 MB 9.6 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.5/26.7 MB 8.9 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 7.1/26.7 MB 8.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 8.7/26.7 MB 8.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 10.0/26.7 MB 8.1 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 11.5/26.7 MB 8.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 13.4/26.7 MB 8.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.9/26.7 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 16.5/26.7 MB 8.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 18.1/26.7 MB 7.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 19.7/26.7 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 21.2/26.7 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 23.1/26.7 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.6/26.7 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.7 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.7/26.7 MB 7.7 MB/s eta 0:00:00\n",
      "Downloading mlflow_skinny-3.4.0-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 10.0 MB/s eta 0:00:00\n",
      "Downloading mlflow_tracing-3.4.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 7.5 MB/s eta 0:00:00\n",
      "Using cached alembic-1.16.5-py3-none-any.whl (247 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading cryptography-45.0.7-cp311-abi3-win_amd64.whl (3.4 MB)\n",
      "   ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 2.4/3.4 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.1/3.4 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.4/3.4 MB 7.3 MB/s eta 0:00:00\n",
      "Downloading databricks_sdk-0.66.0-py3-none-any.whl (717 kB)\n",
      "   ---------------------------------------- 0.0/717.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 717.5/717.5 kB 11.8 MB/s eta 0:00:00\n",
      "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Downloading fastapi-0.117.1-py3-none-any.whl (95 kB)\n",
      "Downloading fastmcp-2.12.3-py3-none-any.whl (314 kB)\n",
      "Downloading flask-3.1.2-py3-none-any.whl (103 kB)\n",
      "Using cached gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Downloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading matplotlib-3.10.6-cp313-cp313-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 2.4/8.1 MB 10.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.7/8.1 MB 9.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.5/8.1 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.1/8.1 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 8.0 MB/s eta 0:00:00\n",
      "Downloading mcp-1.14.1-py3-none-any.whl (163 kB)\n",
      "Downloading numpy-2.3.3-cp313-cp313-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.8/12.8 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.4/12.8 MB 8.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.2/12.8 MB 8.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.8/12.8 MB 8.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.4/12.8 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.0/12.8 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.5/12.8 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
      "Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
      "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Downloading pandas-2.3.2-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.4/11.0 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.9/11.0 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.5/11.0 MB 8.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.1/11.0 MB 8.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.2/11.0 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 7.7 MB/s eta 0:00:00\n",
      "Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Downloading pyarrow-21.0.0-cp313-cp313-win_amd64.whl (26.1 MB)\n",
      "   ---------------------------------------- 0.0/26.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.1/26.1 MB 10.6 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.7/26.1 MB 9.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.2/26.1 MB 8.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 6.8/26.1 MB 8.3 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 8.4/26.1 MB 8.2 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 10.0/26.1 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.8/26.1 MB 8.0 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 13.4/26.1 MB 8.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.9/26.1 MB 7.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 16.5/26.1 MB 7.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 18.1/26.1 MB 7.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 19.7/26.1 MB 7.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.2/26.1 MB 7.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 22.0/26.1 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.1/26.1 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.7/26.1 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.1/26.1 MB 7.5 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 10.8 MB/s eta 0:00:00\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading scikit_learn-1.7.2-cp313-cp313-win_amd64.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 2.4/8.7 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.7/8.7 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.2/8.7 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.8/8.7 MB 8.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.4/8.7 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 7.9 MB/s eta 0:00:00\n",
      "Downloading scipy-1.16.2-cp313-cp313-win_amd64.whl (38.5 MB)\n",
      "   ---------------------------------------- 0.0/38.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.1/38.5 MB 10.6 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 3.7/38.5 MB 9.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 5.2/38.5 MB 8.5 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 6.8/38.5 MB 8.3 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 8.4/38.5 MB 8.2 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 10.0/38.5 MB 8.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 11.5/38.5 MB 8.0 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 13.1/38.5 MB 8.0 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 14.9/38.5 MB 7.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 16.5/38.5 MB 7.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 18.1/38.5 MB 7.9 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 19.7/38.5 MB 7.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 21.2/38.5 MB 7.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 22.8/38.5 MB 7.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 24.4/38.5 MB 7.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 26.0/38.5 MB 7.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.8/38.5 MB 7.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.4/38.5 MB 7.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 30.9/38.5 MB 7.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.5/38.5 MB 7.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.1/38.5 MB 7.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 35.9/38.5 MB 7.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.5/38.5 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.5 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.5/38.5 MB 7.6 MB/s eta 0:00:00\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading sqlalchemy-2.0.43-cp313-cp313-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 10.2 MB/s eta 0:00:00\n",
      "Downloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Downloading starlette-0.48.0-py3-none-any.whl (73 kB)\n",
      "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading uvicorn-0.37.0-py3-none-any.whl (67 kB)\n",
      "Downloading waitress-3.0.2-py3-none-any.whl (56 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading authlib-1.6.4-py2.py3-none-any.whl (243 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Downloading cffi-2.0.0-cp313-cp313-win_amd64.whl (183 kB)\n",
      "Downloading contourpy-1.3.3-cp313-cp313-win_amd64.whl (226 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading cyclopts-3.24.0-py3-none-any.whl (86 kB)\n",
      "Downloading rich_rst-1.3.1-py3-none-any.whl (11 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\n",
      "Downloading fonttools-4.60.0-cp313-cp313-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 2.1/2.3 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 9.4 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.2.4-cp313-cp313-win_amd64.whl (299 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading kiwisolver-1.4.9-cp313-cp313-win_amd64.whl (73 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Downloading openapi_core-0.19.5-py3-none-any.whl (106 kB)\n",
      "Downloading jsonschema_path-0.3.4-py3-none-any.whl (14 kB)\n",
      "Downloading openapi_schema_validator-0.6.3-py3-none-any.whl (8.8 kB)\n",
      "Downloading openapi_spec_validator-0.7.2-py3-none-any.whl (39 kB)\n",
      "Downloading lazy_object_proxy-1.12.0-cp313-cp313-win_amd64.whl (26 kB)\n",
      "Downloading pathable-0.4.4-py3-none-any.whl (9.6 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading werkzeug-3.1.1-py3-none-any.whl (224 kB)\n",
      "Downloading openapi_pydantic-0.5.1-py3-none-any.whl (96 kB)\n",
      "Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.6/7.0 MB 8.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.4/7.0 MB 8.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.5/7.0 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/7.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 8.2 MB/s eta 0:00:00\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
      "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
      "Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Downloading pyperclip-1.10.0-py3-none-any.whl (11 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading pywin32-311-cp313-cp313-win_amd64.whl (9.5 MB)\n",
      "   ---------------------------------------- 0.0/9.5 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.4/9.5 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.9/9.5 MB 9.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.5/9.5 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.8/9.5 MB 8.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.4/9.5 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.5/9.5 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 10.3 MB/s eta 0:00:00\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading rpds_py-0.27.1-cp313-cp313-win_amd64.whl (232 kB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading sse_starlette-3.0.2-py3-none-any.whl (11 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading docutils-0.22.2-py3-none-any.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 632.7/632.7 kB 6.5 MB/s eta 0:00:00\n",
      "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Using cached mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Downloading more_itertools-10.8.0-py3-none-any.whl (69 kB)\n",
      "Downloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
      "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Installing collected packages: pywin32, pytz, pyperclip, parse, zipp, waitress, urllib3, tzdata, typing-extensions, threadpoolctl, sqlparse, sniffio, smmap, six, rpds-py, pyyaml, python-multipart, python-dotenv, pyparsing, pygments, pycparser, pyasn1, pyarrow, protobuf, pillow, pathable, packaging, numpy, more-itertools, mdurl, markupsafe, lazy-object-proxy, kiwisolver, joblib, itsdangerous, isodate, idna, httpx-sse, h11, greenlet, graphql-core, fonttools, exceptiongroup, docutils, docstring-parser, dnspython, cycler, colorama, cloudpickle, charset_normalizer, certifi, cachetools, blinker, attrs, annotated-types, werkzeug, typing-inspection, sqlalchemy, scipy, rsa, rfc3339-validator, requests, referencing, python-dateutil, pydantic-core, pyasn1-modules, opentelemetry-proto, markdown-it-py, Mako, jinja2, importlib_metadata, httpcore, graphql-relay, gitdb, email-validator, contourpy, click, cffi, anyio, uvicorn, starlette, sse-starlette, scikit-learn, rich, pydantic, pandas, opentelemetry-api, matplotlib, jsonschema-specifications, jsonschema-path, httpx, graphene, google-auth, gitpython, Flask, docker, cryptography, alembic, rich-rst, pydantic-settings, opentelemetry-semantic-conventions, openapi-pydantic, jsonschema, fastapi, databricks-sdk, authlib, opentelemetry-sdk, openapi-schema-validator, mcp, cyclopts, openapi-spec-validator, mlflow-tracing, mlflow-skinny, openapi-core, fastmcp, mlflow\n",
      "\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   0/116 [pywin32]\n",
      "   ----------------------------------------   1/116 [pytz]\n",
      "   ----------------------------------------   1/116 [pytz]\n",
      "   ----------------------------------------   1/116 [pytz]\n",
      "   ----------------------------------------   1/116 [pytz]\n",
      "   ----------------------------------------   1/116 [pytz]\n",
      "   ----------------------------------------   1/116 [pytz]\n",
      "   - --------------------------------------   3/116 [parse]\n",
      "   - --------------------------------------   4/116 [zipp]\n",
      "   - --------------------------------------   5/116 [waitress]\n",
      "   - --------------------------------------   5/116 [waitress]\n",
      "   - --------------------------------------   5/116 [waitress]\n",
      "   - --------------------------------------   5/116 [waitress]\n",
      "   -- -------------------------------------   6/116 [urllib3]\n",
      "   -- -------------------------------------   6/116 [urllib3]\n",
      "   -- -------------------------------------   6/116 [urllib3]\n",
      "   -- -------------------------------------   6/116 [urllib3]\n",
      "   -- -------------------------------------   6/116 [urllib3]\n",
      "   -- -------------------------------------   6/116 [urllib3]\n",
      "   -- -------------------------------------   6/116 [urllib3]\n",
      "   -- -------------------------------------   6/116 [urllib3]\n",
      "   -- -------------------------------------   7/116 [tzdata]\n",
      "   -- -------------------------------------   7/116 [tzdata]\n",
      "   -- -------------------------------------   7/116 [tzdata]\n",
      "   -- -------------------------------------   7/116 [tzdata]\n",
      "   -- -------------------------------------   8/116 [typing-extensions]\n",
      "   --- ------------------------------------  10/116 [sqlparse]\n",
      "   --- ------------------------------------  10/116 [sqlparse]\n",
      "   --- ------------------------------------  10/116 [sqlparse]\n",
      "   --- ------------------------------------  10/116 [sqlparse]\n",
      "   --- ------------------------------------  10/116 [sqlparse]\n",
      "   --- ------------------------------------  10/116 [sqlparse]\n",
      "   --- ------------------------------------  11/116 [sniffio]\n",
      "   ---- -----------------------------------  12/116 [smmap]\n",
      "   ---- -----------------------------------  13/116 [six]\n",
      "   ----- ----------------------------------  15/116 [pyyaml]\n",
      "   ----- ----------------------------------  15/116 [pyyaml]\n",
      "   ----- ----------------------------------  15/116 [pyyaml]\n",
      "   ----- ----------------------------------  15/116 [pyyaml]\n",
      "   ----- ----------------------------------  16/116 [python-multipart]\n",
      "   ----- ----------------------------------  17/116 [python-dotenv]\n",
      "   ----- ----------------------------------  17/116 [python-dotenv]\n",
      "   ----- ----------------------------------  17/116 [python-dotenv]\n",
      "   ------ ---------------------------------  18/116 [pyparsing]\n",
      "   ------ ---------------------------------  18/116 [pyparsing]\n",
      "   ------ ---------------------------------  18/116 [pyparsing]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  19/116 [pygments]\n",
      "   ------ ---------------------------------  20/116 [pycparser]\n",
      "   ------ ---------------------------------  20/116 [pycparser]\n",
      "   ------ ---------------------------------  20/116 [pycparser]\n",
      "   ------ ---------------------------------  20/116 [pycparser]\n",
      "   ------ ---------------------------------  20/116 [pycparser]\n",
      "   ------- --------------------------------  21/116 [pyasn1]\n",
      "   ------- --------------------------------  21/116 [pyasn1]\n",
      "   ------- --------------------------------  21/116 [pyasn1]\n",
      "   ------- --------------------------------  21/116 [pyasn1]\n",
      "   ------- --------------------------------  21/116 [pyasn1]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  22/116 [pyarrow]\n",
      "   ------- --------------------------------  23/116 [protobuf]\n",
      "   ------- --------------------------------  23/116 [protobuf]\n",
      "   ------- --------------------------------  23/116 [protobuf]\n",
      "   ------- --------------------------------  23/116 [protobuf]\n",
      "   ------- --------------------------------  23/116 [protobuf]\n",
      "   ------- --------------------------------  23/116 [protobuf]\n",
      "   ------- --------------------------------  23/116 [protobuf]\n",
      "   ------- --------------------------------  23/116 [protobuf]\n",
      "   ------- --------------------------------  23/116 [protobuf]\n",
      "   ------- --------------------------------  23/116 [protobuf]\n",
      "   ------- --------------------------------  23/116 [protobuf]\n",
      "   ------- --------------------------------  23/116 [protobuf]\n",
      "   -------- -------------------------------  24/116 [pillow]\n",
      "   -------- -------------------------------  24/116 [pillow]\n",
      "   -------- -------------------------------  24/116 [pillow]\n",
      "   -------- -------------------------------  24/116 [pillow]\n",
      "   -------- -------------------------------  24/116 [pillow]\n",
      "   -------- -------------------------------  24/116 [pillow]\n",
      "   -------- -------------------------------  24/116 [pillow]\n",
      "   -------- -------------------------------  24/116 [pillow]\n",
      "   -------- -------------------------------  24/116 [pillow]\n",
      "   -------- -------------------------------  24/116 [pillow]\n",
      "   -------- -------------------------------  24/116 [pillow]\n",
      "   -------- -------------------------------  24/116 [pillow]\n",
      "   -------- -------------------------------  24/116 [pillow]\n",
      "   -------- -------------------------------  24/116 [pillow]\n",
      "   -------- -------------------------------  24/116 [pillow]\n",
      "   -------- -------------------------------  24/116 [pillow]\n",
      "   -------- -------------------------------  24/116 [pillow]\n",
      "   -------- -------------------------------  24/116 [pillow]\n",
      "   -------- -------------------------------  24/116 [pillow]\n",
      "   -------- -------------------------------  25/116 [pathable]\n",
      "   -------- -------------------------------  26/116 [packaging]\n",
      "   -------- -------------------------------  26/116 [packaging]\n",
      "   -------- -------------------------------  26/116 [packaging]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  27/116 [numpy]\n",
      "   --------- ------------------------------  28/116 [more-itertools]\n",
      "   ---------- -----------------------------  29/116 [mdurl]\n",
      "   ---------- -----------------------------  31/116 [lazy-object-proxy]\n",
      "   ----------- ----------------------------  32/116 [kiwisolver]\n",
      "   ----------- ----------------------------  33/116 [joblib]\n",
      "   ----------- ----------------------------  33/116 [joblib]\n",
      "   ----------- ----------------------------  33/116 [joblib]\n",
      "   ----------- ----------------------------  33/116 [joblib]\n",
      "   ----------- ----------------------------  33/116 [joblib]\n",
      "   ----------- ----------------------------  33/116 [joblib]\n",
      "   ----------- ----------------------------  33/116 [joblib]\n",
      "   ----------- ----------------------------  33/116 [joblib]\n",
      "   ----------- ----------------------------  33/116 [joblib]\n",
      "   ----------- ----------------------------  33/116 [joblib]\n",
      "   ----------- ----------------------------  33/116 [joblib]\n",
      "   ----------- ----------------------------  33/116 [joblib]\n",
      "   ----------- ----------------------------  33/116 [joblib]\n",
      "   ----------- ----------------------------  33/116 [joblib]\n",
      "   ----------- ----------------------------  33/116 [joblib]\n",
      "   ----------- ----------------------------  34/116 [itsdangerous]\n",
      "   ------------ ---------------------------  35/116 [isodate]\n",
      "   ------------ ---------------------------  35/116 [isodate]\n",
      "   ------------ ---------------------------  36/116 [idna]\n",
      "   ------------ ---------------------------  36/116 [idna]\n",
      "   ------------ ---------------------------  37/116 [httpx-sse]\n",
      "   ------------- --------------------------  38/116 [h11]\n",
      "   ------------- --------------------------  38/116 [h11]\n",
      "   ------------- --------------------------  39/116 [greenlet]\n",
      "   ------------- --------------------------  39/116 [greenlet]\n",
      "   ------------- --------------------------  39/116 [greenlet]\n",
      "   ------------- --------------------------  39/116 [greenlet]\n",
      "   ------------- --------------------------  39/116 [greenlet]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   ------------- --------------------------  40/116 [graphql-core]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  41/116 [fonttools]\n",
      "   -------------- -------------------------  42/116 [exceptiongroup]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   -------------- -------------------------  43/116 [docutils]\n",
      "   --------------- ------------------------  44/116 [docstring-parser]\n",
      "   --------------- ------------------------  44/116 [docstring-parser]\n",
      "   --------------- ------------------------  44/116 [docstring-parser]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   --------------- ------------------------  45/116 [dnspython]\n",
      "   ---------------- -----------------------  47/116 [colorama]\n",
      "   ---------------- -----------------------  47/116 [colorama]\n",
      "   ---------------- -----------------------  48/116 [cloudpickle]\n",
      "   ---------------- -----------------------  49/116 [charset_normalizer]\n",
      "   ---------------- -----------------------  49/116 [charset_normalizer]\n",
      "   ---------------- -----------------------  49/116 [charset_normalizer]\n",
      "   ---------------- -----------------------  49/116 [charset_normalizer]\n",
      "   ----------------- ----------------------  50/116 [certifi]\n",
      "   ----------------- ----------------------  52/116 [blinker]\n",
      "   ------------------ ---------------------  53/116 [attrs]\n",
      "   ------------------ ---------------------  53/116 [attrs]\n",
      "   ------------------ ---------------------  53/116 [attrs]\n",
      "   ------------------ ---------------------  53/116 [attrs]\n",
      "   ------------------ ---------------------  55/116 [werkzeug]\n",
      "   ------------------ ---------------------  55/116 [werkzeug]\n",
      "   ------------------ ---------------------  55/116 [werkzeug]\n",
      "   ------------------ ---------------------  55/116 [werkzeug]\n",
      "   ------------------ ---------------------  55/116 [werkzeug]\n",
      "   ------------------ ---------------------  55/116 [werkzeug]\n",
      "   ------------------ ---------------------  55/116 [werkzeug]\n",
      "   ------------------ ---------------------  55/116 [werkzeug]\n",
      "   ------------------ ---------------------  55/116 [werkzeug]\n",
      "   ------------------ ---------------------  55/116 [werkzeug]\n",
      "   ------------------ ---------------------  55/116 [werkzeug]\n",
      "   ------------------- --------------------  56/116 [typing-inspection]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   ------------------- --------------------  57/116 [sqlalchemy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  58/116 [scipy]\n",
      "   -------------------- -------------------  59/116 [rsa]\n",
      "   -------------------- -------------------  59/116 [rsa]\n",
      "   -------------------- -------------------  59/116 [rsa]\n",
      "   -------------------- -------------------  59/116 [rsa]\n",
      "   -------------------- -------------------  59/116 [rsa]\n",
      "   -------------------- -------------------  59/116 [rsa]\n",
      "   -------------------- -------------------  59/116 [rsa]\n",
      "   -------------------- -------------------  59/116 [rsa]\n",
      "   -------------------- -------------------  59/116 [rsa]\n",
      "   -------------------- -------------------  59/116 [rsa]\n",
      "   -------------------- -------------------  59/116 [rsa]\n",
      "   -------------------- -------------------  60/116 [rfc3339-validator]\n",
      "   --------------------- ------------------  61/116 [requests]\n",
      "   --------------------- ------------------  61/116 [requests]\n",
      "   --------------------- ------------------  61/116 [requests]\n",
      "   --------------------- ------------------  62/116 [referencing]\n",
      "   --------------------- ------------------  62/116 [referencing]\n",
      "   --------------------- ------------------  63/116 [python-dateutil]\n",
      "   --------------------- ------------------  63/116 [python-dateutil]\n",
      "   --------------------- ------------------  63/116 [python-dateutil]\n",
      "   ---------------------- -----------------  64/116 [pydantic-core]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  65/116 [pyasn1-modules]\n",
      "   ---------------------- -----------------  66/116 [opentelemetry-proto]\n",
      "   ---------------------- -----------------  66/116 [opentelemetry-proto]\n",
      "   ---------------------- -----------------  66/116 [opentelemetry-proto]\n",
      "   ---------------------- -----------------  66/116 [opentelemetry-proto]\n",
      "   ----------------------- ----------------  67/116 [markdown-it-py]\n",
      "   ----------------------- ----------------  67/116 [markdown-it-py]\n",
      "   ----------------------- ----------------  67/116 [markdown-it-py]\n",
      "   ----------------------- ----------------  67/116 [markdown-it-py]\n",
      "   ----------------------- ----------------  67/116 [markdown-it-py]\n",
      "   ----------------------- ----------------  67/116 [markdown-it-py]\n",
      "   ----------------------- ----------------  67/116 [markdown-it-py]\n",
      "   ----------------------- ----------------  67/116 [markdown-it-py]\n",
      "   ----------------------- ----------------  67/116 [markdown-it-py]\n",
      "   ----------------------- ----------------  67/116 [markdown-it-py]\n",
      "   ----------------------- ----------------  67/116 [markdown-it-py]\n",
      "   ----------------------- ----------------  67/116 [markdown-it-py]\n",
      "   ----------------------- ----------------  68/116 [Mako]\n",
      "   ----------------------- ----------------  68/116 [Mako]\n",
      "   ----------------------- ----------------  68/116 [Mako]\n",
      "   ----------------------- ----------------  68/116 [Mako]\n",
      "   ----------------------- ----------------  68/116 [Mako]\n",
      "   ----------------------- ----------------  68/116 [Mako]\n",
      "   ----------------------- ----------------  68/116 [Mako]\n",
      "   ----------------------- ----------------  68/116 [Mako]\n",
      "   ----------------------- ----------------  69/116 [jinja2]\n",
      "   ----------------------- ----------------  69/116 [jinja2]\n",
      "   ----------------------- ----------------  69/116 [jinja2]\n",
      "   ----------------------- ----------------  69/116 [jinja2]\n",
      "   ----------------------- ----------------  69/116 [jinja2]\n",
      "   ----------------------- ----------------  69/116 [jinja2]\n",
      "   ------------------------ ---------------  70/116 [importlib_metadata]\n",
      "   ------------------------ ---------------  70/116 [importlib_metadata]\n",
      "   ------------------------ ---------------  71/116 [httpcore]\n",
      "   ------------------------ ---------------  71/116 [httpcore]\n",
      "   ------------------------ ---------------  71/116 [httpcore]\n",
      "   ------------------------ ---------------  71/116 [httpcore]\n",
      "   ------------------------ ---------------  71/116 [httpcore]\n",
      "   ------------------------ ---------------  71/116 [httpcore]\n",
      "   ------------------------ ---------------  72/116 [graphql-relay]\n",
      "   ------------------------ ---------------  72/116 [graphql-relay]\n",
      "   ------------------------ ---------------  72/116 [graphql-relay]\n",
      "   ------------------------- --------------  73/116 [gitdb]\n",
      "   ------------------------- --------------  73/116 [gitdb]\n",
      "   ------------------------- --------------  73/116 [gitdb]\n",
      "   ------------------------- --------------  73/116 [gitdb]\n",
      "   ------------------------- --------------  74/116 [email-validator]\n",
      "   ------------------------- --------------  74/116 [email-validator]\n",
      "   ------------------------- --------------  74/116 [email-validator]\n",
      "   ------------------------- --------------  75/116 [contourpy]\n",
      "   ------------------------- --------------  75/116 [contourpy]\n",
      "   ------------------------- --------------  75/116 [contourpy]\n",
      "   -------------------------- -------------  76/116 [click]\n",
      "   -------------------------- -------------  76/116 [click]\n",
      "   -------------------------- -------------  76/116 [click]\n",
      "   -------------------------- -------------  76/116 [click]\n",
      "   -------------------------- -------------  77/116 [cffi]\n",
      "   -------------------------- -------------  77/116 [cffi]\n",
      "   -------------------------- -------------  77/116 [cffi]\n",
      "   -------------------------- -------------  77/116 [cffi]\n",
      "   -------------------------- -------------  78/116 [anyio]\n",
      "   -------------------------- -------------  78/116 [anyio]\n",
      "   -------------------------- -------------  78/116 [anyio]\n",
      "   -------------------------- -------------  78/116 [anyio]\n",
      "   -------------------------- -------------  78/116 [anyio]\n",
      "   -------------------------- -------------  78/116 [anyio]\n",
      "   -------------------------- -------------  78/116 [anyio]\n",
      "   -------------------------- -------------  78/116 [anyio]\n",
      "   --------------------------- ------------  79/116 [uvicorn]\n",
      "   --------------------------- ------------  79/116 [uvicorn]\n",
      "   --------------------------- ------------  79/116 [uvicorn]\n",
      "   --------------------------- ------------  79/116 [uvicorn]\n",
      "   --------------------------- ------------  79/116 [uvicorn]\n",
      "   --------------------------- ------------  79/116 [uvicorn]\n",
      "   --------------------------- ------------  79/116 [uvicorn]\n",
      "   --------------------------- ------------  79/116 [uvicorn]\n",
      "   --------------------------- ------------  80/116 [starlette]\n",
      "   --------------------------- ------------  80/116 [starlette]\n",
      "   --------------------------- ------------  80/116 [starlette]\n",
      "   --------------------------- ------------  80/116 [starlette]\n",
      "   --------------------------- ------------  80/116 [starlette]\n",
      "   --------------------------- ------------  80/116 [starlette]\n",
      "   --------------------------- ------------  80/116 [starlette]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  82/116 [scikit-learn]\n",
      "   ---------------------------- -----------  83/116 [rich]\n",
      "   ---------------------------- -----------  83/116 [rich]\n",
      "   ---------------------------- -----------  83/116 [rich]\n",
      "   ---------------------------- -----------  83/116 [rich]\n",
      "   ---------------------------- -----------  83/116 [rich]\n",
      "   ---------------------------- -----------  83/116 [rich]\n",
      "   ---------------------------- -----------  83/116 [rich]\n",
      "   ---------------------------- -----------  83/116 [rich]\n",
      "   ---------------------------- -----------  83/116 [rich]\n",
      "   ---------------------------- -----------  83/116 [rich]\n",
      "   ---------------------------- -----------  83/116 [rich]\n",
      "   ---------------------------- -----------  83/116 [rich]\n",
      "   ---------------------------- -----------  83/116 [rich]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ---------------------------- -----------  84/116 [pydantic]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  85/116 [pandas]\n",
      "   ----------------------------- ----------  86/116 [opentelemetry-api]\n",
      "   ----------------------------- ----------  86/116 [opentelemetry-api]\n",
      "   ----------------------------- ----------  86/116 [opentelemetry-api]\n",
      "   ----------------------------- ----------  86/116 [opentelemetry-api]\n",
      "   ----------------------------- ----------  86/116 [opentelemetry-api]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  87/116 [matplotlib]\n",
      "   ------------------------------ ---------  88/116 [jsonschema-specifications]\n",
      "   ------------------------------ ---------  89/116 [jsonschema-path]\n",
      "   ------------------------------ ---------  89/116 [jsonschema-path]\n",
      "   ------------------------------- --------  90/116 [httpx]\n",
      "   ------------------------------- --------  90/116 [httpx]\n",
      "   ------------------------------- --------  90/116 [httpx]\n",
      "   ------------------------------- --------  90/116 [httpx]\n",
      "   ------------------------------- --------  90/116 [httpx]\n",
      "   ------------------------------- --------  90/116 [httpx]\n",
      "   ------------------------------- --------  90/116 [httpx]\n",
      "   ------------------------------- --------  91/116 [graphene]\n",
      "   ------------------------------- --------  91/116 [graphene]\n",
      "   ------------------------------- --------  91/116 [graphene]\n",
      "   ------------------------------- --------  91/116 [graphene]\n",
      "   ------------------------------- --------  91/116 [graphene]\n",
      "   ------------------------------- --------  91/116 [graphene]\n",
      "   ------------------------------- --------  91/116 [graphene]\n",
      "   ------------------------------- --------  91/116 [graphene]\n",
      "   ------------------------------- --------  91/116 [graphene]\n",
      "   ------------------------------- --------  91/116 [graphene]\n",
      "   ------------------------------- --------  91/116 [graphene]\n",
      "   ------------------------------- --------  91/116 [graphene]\n",
      "   ------------------------------- --------  91/116 [graphene]\n",
      "   ------------------------------- --------  91/116 [graphene]\n",
      "   ------------------------------- --------  91/116 [graphene]\n",
      "   ------------------------------- --------  91/116 [graphene]\n",
      "   ------------------------------- --------  91/116 [graphene]\n",
      "   ------------------------------- --------  92/116 [google-auth]\n",
      "   ------------------------------- --------  92/116 [google-auth]\n",
      "   ------------------------------- --------  92/116 [google-auth]\n",
      "   ------------------------------- --------  92/116 [google-auth]\n",
      "   ------------------------------- --------  92/116 [google-auth]\n",
      "   ------------------------------- --------  92/116 [google-auth]\n",
      "   ------------------------------- --------  92/116 [google-auth]\n",
      "   ------------------------------- --------  92/116 [google-auth]\n",
      "   ------------------------------- --------  92/116 [google-auth]\n",
      "   ------------------------------- --------  92/116 [google-auth]\n",
      "   ------------------------------- --------  92/116 [google-auth]\n",
      "   ------------------------------- --------  92/116 [google-auth]\n",
      "   ------------------------------- --------  92/116 [google-auth]\n",
      "   ------------------------------- --------  92/116 [google-auth]\n",
      "   -------------------------------- -------  93/116 [gitpython]\n",
      "   -------------------------------- -------  93/116 [gitpython]\n",
      "   -------------------------------- -------  93/116 [gitpython]\n",
      "   -------------------------------- -------  93/116 [gitpython]\n",
      "   -------------------------------- -------  93/116 [gitpython]\n",
      "   -------------------------------- -------  93/116 [gitpython]\n",
      "   -------------------------------- -------  93/116 [gitpython]\n",
      "   -------------------------------- -------  94/116 [Flask]\n",
      "   -------------------------------- -------  94/116 [Flask]\n",
      "   -------------------------------- -------  94/116 [Flask]\n",
      "   -------------------------------- -------  94/116 [Flask]\n",
      "   -------------------------------- -------  94/116 [Flask]\n",
      "   -------------------------------- -------  94/116 [Flask]\n",
      "   -------------------------------- -------  94/116 [Flask]\n",
      "   -------------------------------- -------  95/116 [docker]\n",
      "   -------------------------------- -------  95/116 [docker]\n",
      "   -------------------------------- -------  95/116 [docker]\n",
      "   -------------------------------- -------  95/116 [docker]\n",
      "   -------------------------------- -------  95/116 [docker]\n",
      "   -------------------------------- -------  95/116 [docker]\n",
      "   -------------------------------- -------  95/116 [docker]\n",
      "   -------------------------------- -------  95/116 [docker]\n",
      "   -------------------------------- -------  95/116 [docker]\n",
      "   -------------------------------- -------  95/116 [docker]\n",
      "   -------------------------------- -------  95/116 [docker]\n",
      "   -------------------------------- -------  95/116 [docker]\n",
      "   --------------------------------- ------  96/116 [cryptography]\n",
      "   --------------------------------- ------  96/116 [cryptography]\n",
      "   --------------------------------- ------  96/116 [cryptography]\n",
      "   --------------------------------- ------  96/116 [cryptography]\n",
      "   --------------------------------- ------  96/116 [cryptography]\n",
      "   --------------------------------- ------  96/116 [cryptography]\n",
      "   --------------------------------- ------  96/116 [cryptography]\n",
      "   --------------------------------- ------  96/116 [cryptography]\n",
      "   --------------------------------- ------  96/116 [cryptography]\n",
      "   --------------------------------- ------  96/116 [cryptography]\n",
      "   --------------------------------- ------  96/116 [cryptography]\n",
      "   --------------------------------- ------  96/116 [cryptography]\n",
      "   --------------------------------- ------  96/116 [cryptography]\n",
      "   --------------------------------- ------  97/116 [alembic]\n",
      "   --------------------------------- ------  97/116 [alembic]\n",
      "   --------------------------------- ------  97/116 [alembic]\n",
      "   --------------------------------- ------  97/116 [alembic]\n",
      "   --------------------------------- ------  97/116 [alembic]\n",
      "   --------------------------------- ------  97/116 [alembic]\n",
      "   --------------------------------- ------  97/116 [alembic]\n",
      "   --------------------------------- ------  97/116 [alembic]\n",
      "   --------------------------------- ------  97/116 [alembic]\n",
      "   --------------------------------- ------  97/116 [alembic]\n",
      "   --------------------------------- ------  97/116 [alembic]\n",
      "   --------------------------------- ------  97/116 [alembic]\n",
      "   --------------------------------- ------  97/116 [alembic]\n",
      "   --------------------------------- ------  97/116 [alembic]\n",
      "   --------------------------------- ------  97/116 [alembic]\n",
      "   --------------------------------- ------  98/116 [rich-rst]\n",
      "   ---------------------------------- -----  99/116 [pydantic-settings]\n",
      "   ---------------------------------- -----  99/116 [pydantic-settings]\n",
      "   ---------------------------------- -----  99/116 [pydantic-settings]\n",
      "   ---------------------------------- -----  99/116 [pydantic-settings]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   -------------------------- ---- 100/116 [opentelemetry-semantic-conventions]\n",
      "   ---------------------------------- ----- 101/116 [openapi-pydantic]\n",
      "   ---------------------------------- ----- 101/116 [openapi-pydantic]\n",
      "   ---------------------------------- ----- 101/116 [openapi-pydantic]\n",
      "   ---------------------------------- ----- 101/116 [openapi-pydantic]\n",
      "   ---------------------------------- ----- 101/116 [openapi-pydantic]\n",
      "   ---------------------------------- ----- 101/116 [openapi-pydantic]\n",
      "   ---------------------------------- ----- 101/116 [openapi-pydantic]\n",
      "   ---------------------------------- ----- 101/116 [openapi-pydantic]\n",
      "   ---------------------------------- ----- 101/116 [openapi-pydantic]\n",
      "   ---------------------------------- ----- 101/116 [openapi-pydantic]\n",
      "   ---------------------------------- ----- 101/116 [openapi-pydantic]\n",
      "   ----------------------------------- ---- 102/116 [jsonschema]\n",
      "   ----------------------------------- ---- 102/116 [jsonschema]\n",
      "   ----------------------------------- ---- 102/116 [jsonschema]\n",
      "   ----------------------------------- ---- 102/116 [jsonschema]\n",
      "   ----------------------------------- ---- 102/116 [jsonschema]\n",
      "   ----------------------------------- ---- 102/116 [jsonschema]\n",
      "   ----------------------------------- ---- 102/116 [jsonschema]\n",
      "   ----------------------------------- ---- 102/116 [jsonschema]\n",
      "   ----------------------------------- ---- 103/116 [fastapi]\n",
      "   ----------------------------------- ---- 103/116 [fastapi]\n",
      "   ----------------------------------- ---- 103/116 [fastapi]\n",
      "   ----------------------------------- ---- 103/116 [fastapi]\n",
      "   ----------------------------------- ---- 103/116 [fastapi]\n",
      "   ----------------------------------- ---- 103/116 [fastapi]\n",
      "   ----------------------------------- ---- 103/116 [fastapi]\n",
      "   ----------------------------------- ---- 103/116 [fastapi]\n",
      "   ----------------------------------- ---- 103/116 [fastapi]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ----------------------------------- ---- 104/116 [databricks-sdk]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 105/116 [authlib]\n",
      "   ------------------------------------ --- 106/116 [opentelemetry-sdk]\n",
      "   ------------------------------------ --- 106/116 [opentelemetry-sdk]\n",
      "   ------------------------------------ --- 106/116 [opentelemetry-sdk]\n",
      "   ------------------------------------ --- 106/116 [opentelemetry-sdk]\n",
      "   ------------------------------------ --- 106/116 [opentelemetry-sdk]\n",
      "   ------------------------------------ --- 106/116 [opentelemetry-sdk]\n",
      "   ------------------------------------ --- 106/116 [opentelemetry-sdk]\n",
      "   ------------------------------------ --- 106/116 [opentelemetry-sdk]\n",
      "   ------------------------------------ --- 106/116 [opentelemetry-sdk]\n",
      "   ------------------------------------ --- 107/116 [openapi-schema-validator]\n",
      "   ------------------------------------- -- 108/116 [mcp]\n",
      "   ------------------------------------- -- 108/116 [mcp]\n",
      "   ------------------------------------- -- 108/116 [mcp]\n",
      "   ------------------------------------- -- 108/116 [mcp]\n",
      "   ------------------------------------- -- 108/116 [mcp]\n",
      "   ------------------------------------- -- 108/116 [mcp]\n",
      "   ------------------------------------- -- 108/116 [mcp]\n",
      "   ------------------------------------- -- 108/116 [mcp]\n",
      "   ------------------------------------- -- 108/116 [mcp]\n",
      "   ------------------------------------- -- 108/116 [mcp]\n",
      "   ------------------------------------- -- 108/116 [mcp]\n",
      "   ------------------------------------- -- 108/116 [mcp]\n",
      "   ------------------------------------- -- 108/116 [mcp]\n",
      "   ------------------------------------- -- 108/116 [mcp]\n",
      "   ------------------------------------- -- 108/116 [mcp]\n",
      "   ------------------------------------- -- 108/116 [mcp]\n",
      "   ------------------------------------- -- 109/116 [cyclopts]\n",
      "   ------------------------------------- -- 109/116 [cyclopts]\n",
      "   ------------------------------------- -- 109/116 [cyclopts]\n",
      "   ------------------------------------- -- 109/116 [cyclopts]\n",
      "   ------------------------------------- -- 109/116 [cyclopts]\n",
      "   ------------------------------------- -- 110/116 [openapi-spec-validator]\n",
      "   ------------------------------------- -- 110/116 [openapi-spec-validator]\n",
      "   ------------------------------------- -- 110/116 [openapi-spec-validator]\n",
      "   ------------------------------------- -- 110/116 [openapi-spec-validator]\n",
      "   ------------------------------------- -- 110/116 [openapi-spec-validator]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 111/116 [mlflow-tracing]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 112/116 [mlflow-skinny]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   -------------------------------------- - 113/116 [openapi-core]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  114/116 [fastmcp]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------  115/116 [mlflow]\n",
      "   ---------------------------------------- 116/116 [mlflow]\n",
      "\n",
      "Successfully installed Flask-3.1.2 Mako-1.3.10 alembic-1.16.5 annotated-types-0.7.0 anyio-4.11.0 attrs-25.3.0 authlib-1.6.4 blinker-1.9.0 cachetools-5.5.2 certifi-2025.8.3 cffi-2.0.0 charset_normalizer-3.4.3 click-8.3.0 cloudpickle-3.1.1 colorama-0.4.6 contourpy-1.3.3 cryptography-45.0.7 cycler-0.12.1 cyclopts-3.24.0 databricks-sdk-0.66.0 dnspython-2.8.0 docker-7.1.0 docstring-parser-0.17.0 docutils-0.22.2 email-validator-2.3.0 exceptiongroup-1.3.0 fastapi-0.117.1 fastmcp-2.12.3 fonttools-4.60.0 gitdb-4.0.12 gitpython-3.1.45 google-auth-2.40.3 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 greenlet-3.2.4 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.1 idna-3.10 importlib_metadata-8.7.0 isodate-0.7.2 itsdangerous-2.2.0 jinja2-3.1.6 joblib-1.5.2 jsonschema-4.25.1 jsonschema-path-0.3.4 jsonschema-specifications-2025.9.1 kiwisolver-1.4.9 lazy-object-proxy-1.12.0 markdown-it-py-4.0.0 markupsafe-3.0.2 matplotlib-3.10.6 mcp-1.14.1 mdurl-0.1.2 mlflow-3.4.0 mlflow-skinny-3.4.0 mlflow-tracing-3.4.0 more-itertools-10.8.0 numpy-2.3.3 openapi-core-0.19.5 openapi-pydantic-0.5.1 openapi-schema-validator-0.6.3 openapi-spec-validator-0.7.2 opentelemetry-api-1.37.0 opentelemetry-proto-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0 packaging-25.0 pandas-2.3.2 parse-1.20.2 pathable-0.4.4 pillow-11.3.0 protobuf-6.32.1 pyarrow-21.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pycparser-2.23 pydantic-2.11.9 pydantic-core-2.33.2 pydantic-settings-2.10.1 pygments-2.19.2 pyparsing-3.2.5 pyperclip-1.10.0 python-dateutil-2.9.0.post0 python-dotenv-1.1.1 python-multipart-0.0.20 pytz-2025.2 pywin32-311 pyyaml-6.0.2 referencing-0.36.2 requests-2.32.5 rfc3339-validator-0.1.4 rich-14.1.0 rich-rst-1.3.1 rpds-py-0.27.1 rsa-4.9.1 scikit-learn-1.7.2 scipy-1.16.2 six-1.17.0 smmap-5.0.2 sniffio-1.3.1 sqlalchemy-2.0.43 sqlparse-0.5.3 sse-starlette-3.0.2 starlette-0.48.0 threadpoolctl-3.6.0 typing-extensions-4.15.0 typing-inspection-0.4.1 tzdata-2025.2 urllib3-2.5.0 uvicorn-0.37.0 waitress-3.0.2 werkzeug-3.1.1 zipp-3.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mdit-py-plugins 0.3.0 requires markdown-it-py<3.0.0,>=1.0.0, but you have markdown-it-py 4.0.0 which is incompatible.\n",
      "numba 0.61.0 requires numpy<2.2,>=1.24, but you have numpy 2.3.3 which is incompatible.\n",
      "pyopenssl 25.0.0 requires cryptography<45,>=41.0.5, but you have cryptography 45.0.7 which is incompatible.\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\n",
      "sphinx 8.2.3 requires docutils<0.22,>=0.20, but you have docutils 0.22.2 which is incompatible.\n",
      "streamlit 1.45.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "WARNING: Target directory C:\\Users\\shail_u9zs758\\Documents\\python_local_site\\bin already exists. Specify --upgrade to force replacement.\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a writable target folder (in your Documents)\n",
    "import os, sys\n",
    "target = os.path.expanduser(r\"~\\Documents\\python_local_site\")\n",
    "os.makedirs(target, exist_ok=True)\n",
    "print(\"target folder:\", target)\n",
    "\n",
    "# 2. Install mlflow into that folder using the same Python as the notebook kernel\n",
    "!{sys.executable} -m pip install --upgrade pip setuptools wheel --target \"{target}\"\n",
    "!{sys.executable} -m pip install mlflow --target \"{target}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27365355-6fbd-4b8b-9b24-15473799ba17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.path[0]: C:\\Users\\shail_u9zs758\\Documents\\python_local_site\n",
      "mlflow version: 3.4.0\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "target = os.path.expanduser(r\"~\\Documents\\python_local_site\")\n",
    "if target not in sys.path:\n",
    "    sys.path.insert(0, target)\n",
    "print(\"sys.path[0]:\", sys.path[0])\n",
    "\n",
    "# Now import mlflow and show version\n",
    "import mlflow\n",
    "print(\"mlflow version:\", mlflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3878a4e-c20b-4ee0-a81f-b8cd4587a183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged example run. Check local tracking store (default).\n"
     ]
    }
   ],
   "source": [
    "#small experiment with mlflow\n",
    "import mlflow\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"learning_rate\", 0.01)\n",
    "    mlflow.log_metric(\"accuracy\", 0.92)\n",
    "    # save a small artifact\n",
    "    with open(\"info.txt\", \"w\") as f:\n",
    "        f.write(\"test artifact\")\n",
    "    mlflow.log_artifact(\"info.txt\")\n",
    "print(\"Logged example run. Check local tracking store (default).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b547d97-96b3-45a0-a3e4-304b64b358c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing scikit-learn ...\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scikit-learn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m, in \u001b[0;36mensure\u001b[1;34m(pkg, import_name)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(import_name)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\importlib\\__init__.py:88\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     87\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1324\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scikit-learn'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m plt \u001b[38;5;241m=\u001b[39m ensure(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mpyplot\n\u001b[0;32m     21\u001b[0m joblib \u001b[38;5;241m=\u001b[39m ensure(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m sklearn \u001b[38;5;241m=\u001b[39m ensure(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit-learn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m mlflow \u001b[38;5;241m=\u001b[39m ensure(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlflow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# sklearn subimports\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m, in \u001b[0;36mensure\u001b[1;34m(pkg, import_name)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m subprocess\u001b[38;5;241m.\u001b[39mcheck_call([sys\u001b[38;5;241m.\u001b[39mexecutable, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-m\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstall\u001b[39m\u001b[38;5;124m\"\u001b[39m, pkg])\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(import_name)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\importlib\\__init__.py:88\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     87\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1324\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scikit-learn'"
     ]
    }
   ],
   "source": [
    "# MLflow logging script for linear models (baseline)\n",
    "# It will train LinearRegression, RidgeCV, LassoCV and log each run to local mlruns via MLflow.\n",
    "\n",
    "import os, sys, subprocess, json\n",
    "import importlib\n",
    "from math import sqrt\n",
    "\n",
    "# ----------------- helper: ensure packages -----------------\n",
    "def ensure(pkg, import_name=None):\n",
    "    import_name = import_name or pkg\n",
    "    try:\n",
    "        return importlib.import_module(import_name)\n",
    "    except Exception:\n",
    "        print(f\"Installing {pkg} ...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "        return importlib.import_module(import_name)\n",
    "\n",
    "pd = ensure(\"pandas\")\n",
    "np = ensure(\"numpy\")\n",
    "plt = ensure(\"matplotlib\").pyplot\n",
    "joblib = ensure(\"joblib\")\n",
    "sklearn = ensure(\"scikit-learn\")\n",
    "mlflow = ensure(\"mlflow\")\n",
    "\n",
    "# sklearn subimports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ----------------- filenames (kept same) -----------------\n",
    "CLEAN_IN = 'amazon_delivery_cleaned.csv'\n",
    "BASELINE_OUT = 'baseline_lr_model.joblib'\n",
    "RIDGE_OUT = 'ridge_model.joblib'\n",
    "LASSO_OUT = 'lasso_model.joblib'\n",
    "COEF_CSV = 'linear_model_coefficients.csv'            # will be overwritten per model with model name prefix\n",
    "SUMMARY_JSON = 'mlflow_models_summary.json'\n",
    "\n",
    "if not os.path.exists(CLEAN_IN):\n",
    "    raise FileNotFoundError(f\"{CLEAN_IN} not found. Place it in the current working directory: {os.getcwd()}\")\n",
    "\n",
    "# ----------------- load dataset -----------------\n",
    "df = pd.read_csv(CLEAN_IN)\n",
    "print(\"Loaded cleaned data:\", df.shape)\n",
    "\n",
    "# ----------------- feature lists (use same choices) -----------------\n",
    "num_feats = [c for c in ['distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed'] if c in df.columns]\n",
    "cat_feats = [c for c in ['Weather_imputed','Traffic','Vehicle','Area','Category','part_of_day','dist_q'] if c in df.columns]\n",
    "\n",
    "print(\"Numeric features:\", num_feats)\n",
    "print(\"Categorical features:\", cat_feats)\n",
    "\n",
    "# ----------------- prepare modeling dataset -----------------\n",
    "df_model = df.dropna(subset=['Delivery_Time']).copy()\n",
    "X = df_model[num_feats + cat_feats]\n",
    "y = df_model['Delivery_Time']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# ----------------- preprocessing (compat-safe) -----------------\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# OneHotEncoder compatibility (sparse_output vs sparse)\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', ohe)\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, num_feats),\n",
    "    ('cat', categorical_transformer, cat_feats)\n",
    "])\n",
    "\n",
    "# ----------------- models to train -----------------\n",
    "models = {\n",
    "    'LinearRegression': Pipeline(steps=[('preprocessor', preprocessor), ('regressor', LinearRegression())]),\n",
    "    'RidgeCV': Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('regressor', RidgeCV(alphas=np.logspace(-3, 3, 25), cv=5, scoring='neg_mean_squared_error'))]),\n",
    "    'LassoCV': Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('regressor', LassoCV(alphas=None, cv=5, max_iter=5000, n_jobs=-1))])\n",
    "}\n",
    "\n",
    "# ----------------- helper to extract feature names & coefficients robustly -----------------\n",
    "def extract_feature_names_and_coefs(pipeline):\n",
    "    \"\"\"\n",
    "    Given a fitted pipeline with steps: preprocessor -> regressor (linear),\n",
    "    return a list of feature names (after preprocessing) and the regressor coefficients.\n",
    "    \"\"\"\n",
    "    pre = pipeline.named_steps['preprocessor']\n",
    "    reg = pipeline.named_steps['regressor']\n",
    "    # numeric features as provided to transformer\n",
    "    numeric_features = []\n",
    "    categorical_input_features = []\n",
    "    # attempt to read transformer metadata\n",
    "    try:\n",
    "        for nm, transformer, features in pre.transformers_:\n",
    "            if nm == 'num':\n",
    "                numeric_features = list(features) if features is not None else []\n",
    "            elif nm == 'cat':\n",
    "                categorical_input_features = list(features) if features is not None else []\n",
    "    except Exception:\n",
    "        # fallback: use our lists\n",
    "        numeric_features = [c for c in num_feats if c in df.columns]\n",
    "        categorical_input_features = [c for c in cat_feats if c in df.columns]\n",
    "    # find ohe inside cat transformer\n",
    "    try:\n",
    "        cat_transformer = pre.named_transformers_['cat']\n",
    "        ohe_local = cat_transformer.named_steps['onehot']\n",
    "    except Exception:\n",
    "        # fallback search\n",
    "        ohe_local = None\n",
    "        for nm, transformer, features in pre.transformers_:\n",
    "            if hasattr(transformer, 'named_steps') and 'onehot' in transformer.named_steps:\n",
    "                ohe_local = transformer.named_steps['onehot']\n",
    "                if not categorical_input_features:\n",
    "                    categorical_input_features = list(features) if features is not None else []\n",
    "                break\n",
    "    if ohe_local is None:\n",
    "        raise RuntimeError(\"Could not locate OneHotEncoder in pipeline's categorical transformer.\")\n",
    "    # get categorical output names\n",
    "    try:\n",
    "        if hasattr(ohe_local, 'feature_names_in_') and getattr(ohe_local, 'feature_names_in_', None) is not None:\n",
    "            cat_in = list(ohe_local.feature_names_in_)\n",
    "            cat_ohe_names = list(ohe_local.get_feature_names_out(cat_in))\n",
    "        else:\n",
    "            if categorical_input_features:\n",
    "                cat_ohe_names = list(ohe_local.get_feature_names_out(categorical_input_features))\n",
    "            else:\n",
    "                cat_ohe_names = list(ohe_local.get_feature_names_out())\n",
    "    except Exception:\n",
    "        # last resort: call without args\n",
    "        cat_ohe_names = list(ohe_local.get_feature_names_out())\n",
    "    all_names = list(numeric_features) + list(cat_ohe_names)\n",
    "    # coefficients\n",
    "    if hasattr(reg, 'coef_'):\n",
    "        coefs = np.asarray(reg.coef_).ravel()\n",
    "    else:\n",
    "        raise RuntimeError(\"Regressor does not expose coef_.\")\n",
    "    # align lengths (trim if mismatch)\n",
    "    if len(coefs) != len(all_names):\n",
    "        minlen = min(len(coefs), len(all_names))\n",
    "        all_names = all_names[:minlen]\n",
    "        coefs = coefs[:minlen]\n",
    "    return all_names, coefs\n",
    "\n",
    "# ----------------- ensure mlruns dir exists -----------------\n",
    "os.makedirs(\"mlruns\", exist_ok=True)\n",
    "mlflow.set_tracking_uri(\"file://\" + os.path.abspath(\"mlruns\"))\n",
    "print(\"MLflow tracking URI:\", mlflow.get_tracking_uri())\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "# ----------------- training + mlflow logging loop -----------------\n",
    "for name, pipe in models.items():\n",
    "    print(\"\\n=== Training & logging:\", name, \"===\")\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        # Fit\n",
    "        pipe.fit(X_train, y_train)\n",
    "        # Predict & metrics\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"{name} => MAE={mae:.3f}, RMSE={rmse:.3f}, R2={r2:.4f}\")\n",
    "        # params: if model has alpha chosen, log it\n",
    "        try:\n",
    "            reg = pipe.named_steps['regressor']\n",
    "            if hasattr(reg, 'alpha_'):\n",
    "                mlflow.log_param('alpha', float(reg.alpha_))\n",
    "            elif hasattr(reg, 'alpha'):\n",
    "                mlflow.log_param('alpha', float(reg.alpha))\n",
    "        except Exception:\n",
    "            pass\n",
    "        # log metrics\n",
    "        mlflow.log_metric('mae', float(mae))\n",
    "        mlflow.log_metric('rmse', float(rmse))\n",
    "        mlflow.log_metric('r2', float(r2))\n",
    "        # save model locally and log as artifact\n",
    "        out_name = {'LinearRegression': BASELINE_OUT, 'RidgeCV': RIDGE_OUT, 'LassoCV': LASSO_OUT}[name]\n",
    "        joblib.dump(pipe, out_name)\n",
    "        mlflow.log_artifact(out_name)\n",
    "        # Extract coefficients and save CSV\n",
    "        try:\n",
    "            feat_names, coefs = extract_feature_names_and_coefs(pipe)\n",
    "            coef_df = pd.DataFrame({'feature': feat_names, 'coefficient': coefs})\n",
    "            coef_df['abs_coeff'] = coef_df['coefficient'].abs()\n",
    "            coef_df = coef_df.sort_values('abs_coeff', ascending=False)\n",
    "            coef_csv_name = f\"{name}_coefficients.csv\"\n",
    "            coef_df.to_csv(coef_csv_name, index=False)\n",
    "            mlflow.log_artifact(coef_csv_name)\n",
    "            print(\"Saved & logged coefficients to artifact:\", coef_csv_name)\n",
    "        except Exception as e:\n",
    "            print(\"Warning: failed to extract/log coefficients:\", e)\n",
    "        # diagnostic plots: residuals & pred vs actual\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            residuals = y_test - y_pred\n",
    "            plt.figure(figsize=(8,5))\n",
    "            plt.scatter(y_pred, residuals, s=8, alpha=0.6)\n",
    "            plt.axhline(0, color='red', linestyle='--')\n",
    "            plt.xlabel('Predicted Delivery_Time (mins)')\n",
    "            plt.ylabel('Residual (Actual - Predicted)')\n",
    "            plt.title(f'{name}: Residuals vs Predicted')\n",
    "            resid_plot = f\"{name}_residuals.png\"\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(resid_plot)\n",
    "            plt.close()\n",
    "            mlflow.log_artifact(resid_plot)\n",
    "            # predicted vs actual\n",
    "            plt.figure(figsize=(7,7))\n",
    "            plt.scatter(y_test, y_pred, s=8, alpha=0.6)\n",
    "            plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "            plt.xlabel('Actual Delivery_Time (mins)')\n",
    "            plt.ylabel('Predicted Delivery_Time (mins)')\n",
    "            plt.title(f'{name}: Predicted vs Actual')\n",
    "            pred_plot = f\"{name}_pred_vs_actual.png\"\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(pred_plot)\n",
    "            plt.close()\n",
    "            mlflow.log_artifact(pred_plot)\n",
    "            print(\"Saved & logged plots:\", resid_plot, pred_plot)\n",
    "        except Exception as e:\n",
    "            print(\"Warning: failed to create/log plots:\", e)\n",
    "        # log the cleaned dataset snapshot as artifact (small)\n",
    "        try:\n",
    "            snapshot_name = f\"{name}_data_snapshot.csv\"\n",
    "            X_test_copy = X_test.copy()\n",
    "            X_test_copy['Delivery_Time_actual'] = y_test\n",
    "            X_test_copy['Delivery_Time_pred'] = y_pred\n",
    "            X_test_copy.to_csv(snapshot_name, index=False)\n",
    "            mlflow.log_artifact(snapshot_name)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # end mlflow run\n",
    "\n",
    "    results_summary.append({'model': name, 'mae': mae, 'rmse': rmse, 'r2': r2})\n",
    "\n",
    "# ----------------- save a summary JSON -----------------\n",
    "with open(SUMMARY_JSON, 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "print(\"Saved summary JSON:\", SUMMARY_JSON)\n",
    "\n",
    "print(\"\\nDone. To view experiments, run in terminal:\\n  mlflow ui\\nand open http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c17ca566-3962-4c25-b0c7-27f0aa8dedc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages available. mlflow version: 3.4.0\n",
      "Loaded cleaned data: (43739, 24)\n",
      "MLflow tracking URI: file:///C:/Users/shail_u9zs758/mlruns\n",
      "\n",
      "Training & logging LinearRegression ...\n",
      "LinearRegression: MAE=26.220, RMSE=33.295, R2=0.5839\n",
      "Saved coefficients -> LinearRegression_coefficients.csv\n",
      "Saved & logged plots.\n",
      "\n",
      "Training & logging RidgeCV ...\n",
      "RidgeCV: MAE=26.218, RMSE=33.290, R2=0.5840\n",
      "Saved coefficients -> RidgeCV_coefficients.csv\n",
      "Saved & logged plots.\n",
      "\n",
      "Training & logging LassoCV ...\n",
      "LassoCV: MAE=26.199, RMSE=33.267, R2=0.5846\n",
      "Saved coefficients -> LassoCV_coefficients.csv\n",
      "Saved & logged plots.\n",
      "\n",
      "MLflow baseline runs completed. Summary saved to mlflow_models_summary.json\n"
     ]
    }
   ],
   "source": [
    "# Single-cell installer + MLflow baseline run.\n",
    "import sys, subprocess, importlib, os, json\n",
    "from math import sqrt\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------ 1) ensure packages in current kernel ----------------\n",
    "packages = [\n",
    "    (\"scikit-learn\", \"sklearn\"),\n",
    "    (\"mlflow\", \"mlflow\"),\n",
    "    (\"joblib\", \"joblib\"),\n",
    "    (\"matplotlib\", \"matplotlib\"),\n",
    "    (\"pandas\", \"pandas\"),\n",
    "    (\"numpy\", \"numpy\")\n",
    "]\n",
    "# lightgbm optional, not required for this run\n",
    "for pkg, import_name in packages:\n",
    "    try:\n",
    "        importlib.import_module(import_name)\n",
    "    except Exception:\n",
    "        print(f\"Installing {pkg} ...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "# now import everything we need\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, joblib\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "print(\"Packages available. mlflow version:\", mlflow.__version__)\n",
    "\n",
    "# ------------ 2) filenames & load data ----------------\n",
    "CLEAN_IN = 'amazon_delivery_cleaned.csv'\n",
    "if not os.path.exists(CLEAN_IN):\n",
    "    raise FileNotFoundError(f\"{CLEAN_IN} not found in working directory: {os.getcwd()}\")\n",
    "\n",
    "df = pd.read_csv(CLEAN_IN)\n",
    "print(\"Loaded cleaned data:\", df.shape)\n",
    "\n",
    "# same feature lists used previously (keeps names identical)\n",
    "num_feats = [c for c in ['distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed'] if c in df.columns]\n",
    "cat_feats = [c for c in ['Weather_imputed','Traffic','Vehicle','Area','Category','part_of_day','dist_q'] if c in df.columns]\n",
    "\n",
    "# modeling dataset and split\n",
    "df_model = df.dropna(subset=['Delivery_Time']).copy()\n",
    "X = df_model[num_feats + cat_feats]\n",
    "y = df_model['Delivery_Time']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# preprocessing (compat-safe)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', ohe)\n",
    "])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, num_feats),\n",
    "    ('cat', categorical_transformer, cat_feats)\n",
    "])\n",
    "\n",
    "# models to train\n",
    "models = {\n",
    "    'LinearRegression': Pipeline(steps=[('preprocessor', preprocessor), ('regressor', LinearRegression())]),\n",
    "    'RidgeCV': Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('regressor', RidgeCV(alphas=np.logspace(-3, 3, 25), cv=5, scoring='neg_mean_squared_error'))]),\n",
    "    'LassoCV': Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('regressor', LassoCV(alphas=None, cv=5, max_iter=5000, n_jobs=-1))])\n",
    "}\n",
    "\n",
    "# mlflow setup (local folder mlruns)\n",
    "os.makedirs(\"mlruns\", exist_ok=True)\n",
    "mlflow.set_tracking_uri(Path(os.path.abspath(\"mlruns\")).as_uri())\n",
    "print(\"MLflow tracking URI:\", mlflow.get_tracking_uri())\n",
    "\n",
    "# helper: extract names & coefs (robust)\n",
    "def extract_feature_names_and_coefs(pipeline, num_feats_local=num_feats):\n",
    "    pre = pipeline.named_steps['preprocessor']\n",
    "    reg = pipeline.named_steps['regressor']\n",
    "    # numeric features from transformer metadata if possible\n",
    "    numeric_features = []\n",
    "    categorical_input_features = []\n",
    "    try:\n",
    "        for nm, transformer, features in pre.transformers_:\n",
    "            if nm == 'num':\n",
    "                numeric_features = list(features) if features is not None else []\n",
    "            elif nm == 'cat':\n",
    "                categorical_input_features = list(features) if features is not None else []\n",
    "    except Exception:\n",
    "        numeric_features = [c for c in num_feats_local if c in df.columns]\n",
    "        categorical_input_features = [c for c in cat_feats if c in df.columns]\n",
    "    # find OHE\n",
    "    ohe_local = None\n",
    "    try:\n",
    "        cat_transformer = pre.named_transformers_['cat']\n",
    "        ohe_local = cat_transformer.named_steps['onehot']\n",
    "    except Exception:\n",
    "        for nm, transformer, features in pre.transformers_:\n",
    "            try:\n",
    "                if hasattr(transformer, 'named_steps') and 'onehot' in transformer.named_steps:\n",
    "                    ohe_local = transformer.named_steps['onehot']\n",
    "                    if not categorical_input_features:\n",
    "                        categorical_input_features = list(features) if features is not None else []\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "    if ohe_local is None:\n",
    "        raise RuntimeError(\"OneHotEncoder not found in pipeline.\")\n",
    "    # get ohe output names\n",
    "    try:\n",
    "        if hasattr(ohe_local, 'feature_names_in_') and getattr(ohe_local, 'feature_names_in_', None) is not None:\n",
    "            cat_in = list(ohe_local.feature_names_in_)\n",
    "            cat_ohe_names = list(ohe_local.get_feature_names_out(cat_in))\n",
    "        else:\n",
    "            if categorical_input_features:\n",
    "                cat_ohe_names = list(ohe_local.get_feature_names_out(categorical_input_features))\n",
    "            else:\n",
    "                cat_ohe_names = list(ohe_local.get_feature_names_out())\n",
    "    except Exception:\n",
    "        cat_ohe_names = list(ohe_local.get_feature_names_out())\n",
    "    all_names = list(numeric_features) + list(cat_ohe_names)\n",
    "    # get coefficients\n",
    "    if hasattr(reg, 'coef_'):\n",
    "        coefs = np.asarray(reg.coef_).ravel()\n",
    "    else:\n",
    "        raise RuntimeError(\"Regressor has no coef_.\")\n",
    "    # align lengths if mismatch\n",
    "    if len(coefs) != len(all_names):\n",
    "        minlen = min(len(coefs), len(all_names))\n",
    "        all_names = all_names[:minlen]\n",
    "        coefs = coefs[:minlen]\n",
    "    return all_names, coefs\n",
    "\n",
    "# run training + mlflow logging\n",
    "results_summary = []\n",
    "for name, pipe in models.items():\n",
    "    print(f\"\\nTraining & logging {name} ...\")\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"{name}: MAE={mae:.3f}, RMSE={rmse:.3f}, R2={r2:.4f}\")\n",
    "        # log metrics & params\n",
    "        mlflow.log_metric(\"mae\", float(mae)); mlflow.log_metric(\"rmse\", float(rmse)); mlflow.log_metric(\"r2\", float(r2))\n",
    "        # save model artifact and log\n",
    "        out_map = {'LinearRegression':'baseline_lr_model.joblib','RidgeCV':'ridge_model.joblib','LassoCV':'lasso_model.joblib'}\n",
    "        out_file = out_map[name]\n",
    "        joblib.dump(pipe, out_file)\n",
    "        mlflow.log_artifact(out_file)\n",
    "        # extract and save coefficients (if linear)\n",
    "        try:\n",
    "            feat_names, coefs = extract_feature_names_and_coefs(pipe)\n",
    "            coef_df = pd.DataFrame({'feature': feat_names, 'coefficient': coefs})\n",
    "            coef_df['abs_coeff'] = coef_df['coefficient'].abs()\n",
    "            coef_df = coef_df.sort_values('abs_coeff', ascending=False)\n",
    "            coef_csv = f\"{name}_coefficients.csv\"\n",
    "            coef_df.to_csv(coef_csv, index=False)\n",
    "            mlflow.log_artifact(coef_csv)\n",
    "            print(\"Saved coefficients ->\", coef_csv)\n",
    "        except Exception as e:\n",
    "            print(\"Could not extract coefficients:\", e)\n",
    "        # save diagnostic plots and log\n",
    "        try:\n",
    "            residuals = y_test - y_pred\n",
    "            plt.figure(figsize=(8,5)); plt.scatter(y_pred, residuals, s=8, alpha=0.6); plt.axhline(0, color='r', ls='--')\n",
    "            plt.xlabel('Predicted'); plt.ylabel('Residual'); plt.title(f'{name} residuals'); resid_plot = f\"{name}_residuals.png\"; plt.tight_layout(); plt.savefig(resid_plot); plt.close(); mlflow.log_artifact(resid_plot)\n",
    "            plt.figure(figsize=(7,7)); plt.scatter(y_test, y_pred, s=8, alpha=0.6); plt.plot([y_test.min(), y_test.max()],[y_test.min(), y_test.max()],'r--')\n",
    "            plt.xlabel('Actual'); plt.ylabel('Predicted'); plt.title(f'{name} pred vs actual'); pred_plot = f\"{name}_pred_vs_actual.png\"; plt.tight_layout(); plt.savefig(pred_plot); plt.close(); mlflow.log_artifact(pred_plot)\n",
    "            print(\"Saved & logged plots.\")\n",
    "        except Exception as e:\n",
    "            print(\"Plot logging failed:\", e)\n",
    "        # snapshot test data\n",
    "        try:\n",
    "            snap = X_test.copy(); snap['Delivery_Time_actual'] = y_test; snap['Delivery_Time_pred'] = y_pred\n",
    "            snapfile = f\"{name}_data_snapshot.csv\"; snap.to_csv(snapfile, index=False); mlflow.log_artifact(snapfile)\n",
    "        except Exception:\n",
    "            pass\n",
    "        results_summary.append({'model':name,'mae':mae,'rmse':rmse,'r2':r2})\n",
    "# save summary\n",
    "with open('mlflow_models_summary.json','w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "print(\"\\nMLflow baseline runs completed. Summary saved to mlflow_models_summary.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bd5542b-7be1-4270-bce8-7b7eae38dd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/24 21:18:23 INFO mlflow.tracking.fluent: Experiment with name 'post_feature_engineering' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLflow experiment: post_feature_engineering\n",
      "Loaded upgraded dataset shape: (43739, 35)\n",
      "Numeric features: ['distance_km', 'order_to_pickup_mins', 'Agent_Age', 'Agent_Rating_imputed', 'hour_sin', 'hour_cos']\n",
      "Categorical features: ['Weather_imputed', 'Traffic', 'Vehicle', 'Area', 'Category_grp', 'part_of_day', 'distance_bucket', 'Traffic_Weather', 'Area_PartOfDay', 'CatTraffic']\n",
      "\n",
      "Training & logging: LinearRegression\n",
      "LinearRegression: MAE=29.747, RMSE=39.692, R2=0.4086\n",
      "\n",
      "Training & logging: RidgeCV\n",
      "RidgeCV: MAE=29.747, RMSE=39.676, R2=0.4091\n",
      "\n",
      "Training & logging: LassoCV\n",
      "LassoCV: MAE=29.721, RMSE=39.652, R2=0.4098\n",
      "\n",
      "Post-FE runs complete. Summary saved to mlflow_postfe_summary.json\n",
      "Open MLflow UI (mlflow ui) and compare 'baseline' vs 'post_feature_engineering'.\n"
     ]
    }
   ],
   "source": [
    "# Continue MLflow logging for post_feature_engineering\n",
    "# Clean version (no installs)  assumes amazon_delivery_cleaned.csv is already upgraded\n",
    "\n",
    "import os, json, joblib\n",
    "import mlflow\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------------ MLflow setup ------------------\n",
    "os.makedirs(\"mlruns\", exist_ok=True)\n",
    "mlflow.set_tracking_uri(Path(os.path.abspath(\"mlruns\")).as_uri())\n",
    "exp_name = \"post_feature_engineering\"\n",
    "mlflow.set_experiment(exp_name)\n",
    "print(\"Using MLflow experiment:\", exp_name)\n",
    "\n",
    "# ------------------ Load data ------------------\n",
    "RAW_CLEAN = 'amazon_delivery_cleaned.csv'\n",
    "df = pd.read_csv(RAW_CLEAN)\n",
    "print(\"Loaded upgraded dataset shape:\", df.shape)\n",
    "\n",
    "# ------------------ Feature lists ------------------\n",
    "num_feats = [c for c in [\n",
    "    'distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed',\n",
    "    'hour_sin','hour_cos','agent_perf_score'\n",
    "] if c in df.columns]\n",
    "\n",
    "cat_feats = [c for c in [\n",
    "    'Weather_imputed','Traffic','Vehicle','Area','Category_grp','part_of_day',\n",
    "    'distance_bucket','Traffic_Weather','Area_PartOfDay','CatTraffic','agent_experience_bucket'\n",
    "] if c in df.columns]\n",
    "\n",
    "print(\"Numeric features:\", num_feats)\n",
    "print(\"Categorical features:\", cat_feats)\n",
    "\n",
    "# ------------------ Train/test split ------------------\n",
    "df_model = df.dropna(subset=['Delivery_Time']).copy()\n",
    "X = df_model[num_feats + cat_feats]\n",
    "y = df_model['Delivery_Time']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# ------------------ Preprocessing ------------------\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', ohe)\n",
    "])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, num_feats),\n",
    "    ('cat', categorical_transformer, cat_feats)\n",
    "])\n",
    "\n",
    "# ------------------ Models ------------------\n",
    "models = {\n",
    "    'LinearRegression': Pipeline(steps=[('preprocessor', preprocessor), ('regressor', LinearRegression())]),\n",
    "    'RidgeCV': Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', RidgeCV(alphas=np.logspace(-3,3,25), cv=5, scoring='neg_mean_squared_error'))]),\n",
    "    'LassoCV': Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', LassoCV(alphas=None, cv=5, max_iter=5000, n_jobs=-1))])\n",
    "}\n",
    "\n",
    "# ------------------ Train + log ------------------\n",
    "results = []\n",
    "for name, pipe in models.items():\n",
    "    print(f\"\\nTraining & logging: {name}\")\n",
    "    with mlflow.start_run(run_name=f\"postFE_{name}\"):\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"{name}: MAE={mae:.3f}, RMSE={rmse:.3f}, R2={r2:.4f}\")\n",
    "        mlflow.log_metric('mae', float(mae))\n",
    "        mlflow.log_metric('rmse', float(rmse))\n",
    "        mlflow.log_metric('r2', float(r2))\n",
    "        # alpha if present\n",
    "        try:\n",
    "            reg = pipe.named_steps['regressor']\n",
    "            if hasattr(reg, 'alpha_'):\n",
    "                mlflow.log_param('alpha', float(reg.alpha_))\n",
    "        except Exception:\n",
    "            pass\n",
    "        # save model\n",
    "        model_file = f\"postFE_{name}_model.joblib\"\n",
    "        joblib.dump(pipe, model_file)\n",
    "        mlflow.log_artifact(model_file)\n",
    "        # plots\n",
    "        residuals = y_test - y_pred\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.scatter(y_pred, residuals, s=8, alpha=0.6)\n",
    "        plt.axhline(0, color='r', linestyle='--')\n",
    "        plt.xlabel('Predicted'); plt.ylabel('Residual')\n",
    "        plt.title(f'{name} Residuals')\n",
    "        resid_plot = f\"postFE_{name}_residuals.png\"\n",
    "        plt.savefig(resid_plot); plt.close()\n",
    "        mlflow.log_artifact(resid_plot)\n",
    "\n",
    "        plt.figure(figsize=(7,7))\n",
    "        plt.scatter(y_test, y_pred, s=8, alpha=0.6)\n",
    "        plt.plot([y_test.min(), y_test.max()],[y_test.min(), y_test.max()],'r--')\n",
    "        plt.xlabel('Actual'); plt.ylabel('Predicted')\n",
    "        plt.title(f'{name} Predicted vs Actual')\n",
    "        pred_plot = f\"postFE_{name}_pred_vs_actual.png\"\n",
    "        plt.savefig(pred_plot); plt.close()\n",
    "        mlflow.log_artifact(pred_plot)\n",
    "\n",
    "        results.append({'model': name, 'mae': mae, 'rmse': rmse, 'r2': r2})\n",
    "\n",
    "# ------------------ Save summary ------------------\n",
    "with open('mlflow_postfe_summary.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"\\nPost-FE runs complete. Summary saved to mlflow_postfe_summary.json\")\n",
    "print(\"Open MLflow UI (mlflow ui) and compare 'baseline' vs 'post_feature_engineering'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caef8e2d-4721-4561-a99d-9f19e6074de5",
   "metadata": {},
   "source": [
    "##  Model Performance: Baseline vs Post-Feature-Engineering (Linear Models)\n",
    "\n",
    "###  Baseline (before FE)\n",
    "- **LinearRegression**  MAE  **26.22**, RMSE  **33.30**, R  **0.584**  \n",
    "- **RidgeCV**  MAE  26.22, RMSE  33.29, R  0.584  \n",
    "- **LassoCV**  MAE  26.20, RMSE  33.27, R  0.585  \n",
    "\n",
    "---\n",
    "\n",
    "###  Post-FE (after engineered features)\n",
    "- **LinearRegression**  MAE  29.75, RMSE  39.69, R  0.409  \n",
    "- **RidgeCV**  MAE  29.75, RMSE  39.68, R  0.409  \n",
    "- **LassoCV**  MAE  29.72, RMSE  39.65, R  0.410  \n",
    "\n",
    "---\n",
    "\n",
    "###  Interpretation\n",
    "- **Performance dropped after adding engineered features.**  \n",
    "  - RMSE increased from ~33  ~39 minutes.  \n",
    "  - R dropped from ~0.58  ~0.41.  \n",
    "\n",
    "**Why?**  \n",
    "- Linear models struggle with many categorical interactions (large one-hot expansions)  signal dilution.  \n",
    "- The new features (e.g., `Traffic_Weather`, `Area_PartOfDay`, `CatTraffic`) are **non-linear**  linear regression cannot capture them efficiently.  \n",
    "- These features are **very useful for tree-based models** (RandomForest / LightGBM), which naturally capture interactions.  \n",
    "\n",
    "---\n",
    "\n",
    "###  Takeaway\n",
    "- **Best linear option**: Lasso (baseline).  \n",
    "- **Engineered features are valuable**, but they shine with **non-linear models**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8795da15-fa1c-4487-b653-fdac87599779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proceeding ahead with MLflow for randomforest and lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9744c531-7485-4f92-8120-94918d52d773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/24 21:36:01 INFO mlflow.tracking.fluent: Experiment with name 'tree_models' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to MLflow experiment: tree_models | tracking URI: file:///C:/Users/shail_u9zs758/mlruns\n",
      "Loaded dataset shape: (43739, 35)\n",
      "Numeric features: ['distance_km', 'order_to_pickup_mins', 'Agent_Age', 'Agent_Rating_imputed', 'hour_sin', 'hour_cos']\n",
      "Categorical features: ['Weather_imputed', 'Traffic', 'Vehicle', 'Area', 'Category_grp', 'part_of_day', 'distance_bucket', 'Traffic_Weather', 'Area_PartOfDay', 'CatTraffic']\n",
      "\n",
      "=== Training RandomForest ===\n",
      "RandomForest => MAE=24.978, RMSE=35.462, R2=0.5279\n",
      "Saved feature importance to randomforest_feature_importance.csv\n",
      "\n",
      "=== Training LightGBM ===\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 567\n",
      "[LightGBM] [Info] Number of data points in the train set: 34991, number of used features: 118\n",
      "[LightGBM] [Info] Start training from score 125.043525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM => MAE=24.028, RMSE=34.213, R2=0.5606\n",
      "Saved feature importance to lightgbm_feature_importance.csv\n",
      "\n",
      "Saved summary to tree_models_summary.json\n",
      "Done. Use `mlflow ui` to view experiments and compare runs.\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to train RandomForest and LightGBM (if available) and log to MLflow\n",
    "# Clean, no installs  assumes amazon_delivery_cleaned.csv exists and mlflow is configured.\n",
    "import os, json, joblib\n",
    "from pathlib import Path\n",
    "from math import sqrt\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# optional LightGBM\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "    LGB_AVAILABLE = True\n",
    "except Exception:\n",
    "    LGB_AVAILABLE = False\n",
    "\n",
    "# -------- File names & MLflow setup --------\n",
    "CLEAN_IN = 'amazon_delivery_cleaned.csv'\n",
    "if not os.path.exists(CLEAN_IN):\n",
    "    raise FileNotFoundError(f\"{CLEAN_IN} not found in working dir: {os.getcwd()}\")\n",
    "\n",
    "# Windows-safe mlflow tracking URI\n",
    "os.makedirs(\"mlruns\", exist_ok=True)\n",
    "mlflow.set_tracking_uri(Path(os.path.abspath(\"mlruns\")).as_uri())\n",
    "\n",
    "EXP_NAME = 'tree_models'\n",
    "mlflow.set_experiment(EXP_NAME)\n",
    "print(\"Logging to MLflow experiment:\", EXP_NAME, \"| tracking URI:\", mlflow.get_tracking_uri())\n",
    "\n",
    "# -------- Load dataset & feature lists (post-FE features) --------\n",
    "df = pd.read_csv(CLEAN_IN)\n",
    "print(\"Loaded dataset shape:\", df.shape)\n",
    "\n",
    "# numeric and categorical features (same naming pattern used previously)\n",
    "num_feats = [c for c in [\n",
    "    'distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed',\n",
    "    'hour_sin','hour_cos','agent_perf_score'\n",
    "] if c in df.columns]\n",
    "\n",
    "cat_feats = [c for c in [\n",
    "    'Weather_imputed','Traffic','Vehicle','Area','Category_grp','part_of_day',\n",
    "    'distance_bucket','Traffic_Weather','Area_PartOfDay','CatTraffic','agent_experience_bucket'\n",
    "] if c in df.columns]\n",
    "\n",
    "print(\"Numeric features:\", num_feats)\n",
    "print(\"Categorical features:\", cat_feats)\n",
    "\n",
    "# -------- Prepare training data --------\n",
    "df_model = df.dropna(subset=['Delivery_Time']).copy()\n",
    "X = df_model[num_feats + cat_feats]\n",
    "y = df_model['Delivery_Time']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# -------- Preprocessing pipeline (compat-safe OHE) --------\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', ohe)\n",
    "])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, num_feats),\n",
    "    ('cat', categorical_transformer, cat_feats)\n",
    "])\n",
    "\n",
    "# helper to extract post-transform feature names\n",
    "def get_feature_names_from_preprocessor(preproc):\n",
    "    \"\"\"\n",
    "    Returns list of feature names after ColumnTransformer:\n",
    "      numeric features (as-is) + one-hot output names.\n",
    "    \"\"\"\n",
    "    num_names = list(preproc.transformers_[0][2]) if preproc.transformers_[0][2] is not None else []\n",
    "    # handle categorical OHE\n",
    "    ohe_inst = preproc.named_transformers_['cat'].named_steps['onehot']\n",
    "    try:\n",
    "        if hasattr(ohe_inst, 'feature_names_in_') and getattr(ohe_inst, 'feature_names_in_', None) is not None:\n",
    "            cat_in = list(ohe_inst.feature_names_in_)\n",
    "            cat_ohe = list(ohe_inst.get_feature_names_out(cat_in))\n",
    "        else:\n",
    "            cat_ohe = list(ohe_inst.get_feature_names_out())\n",
    "    except Exception:\n",
    "        # fallback (should rarely happen)\n",
    "        cat_ohe = list(ohe_inst.get_feature_names_out())\n",
    "    return num_names + cat_ohe\n",
    "\n",
    "# -------- Models to train --------\n",
    "models_to_run = []\n",
    "models_to_run.append(('RandomForest', RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)))\n",
    "if LGB_AVAILABLE:\n",
    "    models_to_run.append(('LightGBM', LGBMRegressor(random_state=42, n_estimators=500)))\n",
    "\n",
    "summary = []\n",
    "\n",
    "for model_name, estimator in models_to_run:\n",
    "    print(f\"\\n=== Training {model_name} ===\")\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', estimator)])\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"{model_name} => MAE={mae:.3f}, RMSE={rmse:.3f}, R2={r2:.4f}\")\n",
    "\n",
    "        # log metrics\n",
    "        mlflow.log_metric('mae', float(mae))\n",
    "        mlflow.log_metric('rmse', float(rmse))\n",
    "        mlflow.log_metric('r2', float(r2))\n",
    "\n",
    "        # save model artifact\n",
    "        model_file = f\"{model_name.lower()}_model.joblib\"\n",
    "        joblib.dump(pipeline, model_file)\n",
    "        mlflow.log_artifact(model_file)\n",
    "\n",
    "        # Save feature importances\n",
    "        try:\n",
    "            # get feature names (fit preprocessor already)\n",
    "            feat_names = get_feature_names_from_preprocessor(pipeline.named_steps['preprocessor'])\n",
    "            # extract importance depending on estimator type\n",
    "            reg = pipeline.named_steps['regressor']\n",
    "            if model_name == 'RandomForest' and hasattr(reg, 'feature_importances_'):\n",
    "                importances = reg.feature_importances_\n",
    "            elif model_name == 'LightGBM' and hasattr(reg, 'feature_importances_'):\n",
    "                importances = reg.feature_importances_\n",
    "            else:\n",
    "                importances = None\n",
    "            if importances is not None:\n",
    "                # align lengths\n",
    "                if len(importances) != len(feat_names):\n",
    "                    minlen = min(len(importances), len(feat_names))\n",
    "                    feat_names = feat_names[:minlen]\n",
    "                    importances = importances[:minlen]\n",
    "                fi_df = pd.DataFrame({'feature': feat_names, 'importance': importances})\n",
    "                fi_df = fi_df.sort_values('importance', ascending=False)\n",
    "                fi_csv = f\"{model_name.lower()}_feature_importance.csv\"\n",
    "                fi_df.to_csv(fi_csv, index=False)\n",
    "                mlflow.log_artifact(fi_csv)\n",
    "                print(\"Saved feature importance to\", fi_csv)\n",
    "        except Exception as e:\n",
    "            print(\"Could not extract feature importances:\", e)\n",
    "\n",
    "        # diagnostic plots (pred vs actual)\n",
    "        try:\n",
    "            plt.figure(figsize=(7,7))\n",
    "            plt.scatter(y_test, y_pred, s=8, alpha=0.6)\n",
    "            plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "            plt.xlabel('Actual Delivery_Time (mins)'); plt.ylabel('Predicted Delivery_Time (mins)')\n",
    "            plt.title(f'{model_name}: Predicted vs Actual')\n",
    "            pfile = f\"{model_name.lower()}_pred_vs_actual.png\"\n",
    "            plt.tight_layout(); plt.savefig(pfile); plt.close()\n",
    "            mlflow.log_artifact(pfile)\n",
    "        except Exception as e:\n",
    "            print(\"Plot failed:\", e)\n",
    "\n",
    "        summary.append({'model': model_name, 'mae': mae, 'rmse': rmse, 'r2': r2})\n",
    "    # end run\n",
    "\n",
    "# Save summary JSON\n",
    "with open('tree_models_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(\"\\nSaved summary to tree_models_summary.json\")\n",
    "print(\"Done. Use `mlflow ui` to view experiments and compare runs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f38ec0-1b87-4052-9c17-4b314c5d0065",
   "metadata": {},
   "source": [
    "## Model Performance Summary\n",
    "\n",
    "###  Baseline Linear Models (before Feature Engineering)\n",
    "- **LinearRegression**  MAE  26.22, RMSE  33.30, R  0.584  \n",
    "- **RidgeCV**  MAE  26.22, RMSE  33.29, R  0.584  \n",
    "- **LassoCV**  MAE  26.20, RMSE  33.27, R  0.585  (best linear baseline)\n",
    "\n",
    "---\n",
    "\n",
    "###  Post-Feature-Engineering Linear Models\n",
    "- **LinearRegression**  MAE  29.75, RMSE  39.69, R  0.409  \n",
    "- **RidgeCV**  MAE  29.75, RMSE  39.68, R  0.409  \n",
    "- **LassoCV**  MAE  29.72, RMSE  39.65, R  0.410  (drop in performance)\n",
    "\n",
    "---\n",
    "\n",
    "###  Tree-Based Models (with Feature Engineering)\n",
    "- **RandomForest**  MAE  24.98, RMSE  35.46, R  0.528  \n",
    "- **LightGBM**  MAE  24.03, RMSE  34.21, R  0.561  (best overall so far)\n",
    "\n",
    "---\n",
    "\n",
    "##  Interpretation\n",
    "- **Feature engineering reduced performance for linear models**, but **greatly benefited tree models**.  \n",
    "- **LightGBM outperformed RandomForest** by capturing non-linear relationships and interactions (e.g., `Traffic_Weather`, `Area_PartOfDay`, `CatTraffic`).  \n",
    "- Compared to baseline Lasso (R  0.585), LightGBM is slightly lower on R (0.561) but more robust for complex features.  \n",
    "- **Takeaway**: LightGBM is the current best candidate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2afed609-f2ff-4246-983d-f2f72cbc48cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/24 21:52:25 INFO mlflow.tracking.fluent: Experiment with name 'lightgbm_tuning' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow experiment: lightgbm_tuning | tracking URI: file:///C:/Users/shail_u9zs758/mlruns\n",
      "Loaded dataset: (43739, 35)\n",
      "Numeric features: ['distance_km', 'order_to_pickup_mins', 'Agent_Age', 'Agent_Rating_imputed', 'hour_sin', 'hour_cos']\n",
      "Categorical features: ['Weather_imputed', 'Traffic', 'Vehicle', 'Area', 'Category_grp', 'part_of_day', 'distance_bucket', 'Traffic_Weather', 'Area_PartOfDay', 'CatTraffic']\n",
      "Starting RandomizedSearchCV (this may take a while)...\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 583\n",
      "[LightGBM] [Info] Number of data points in the train set: 34991, number of used features: 126\n",
      "[LightGBM] [Info] Start training from score 125.043525\n",
      "Randomized search complete.\n",
      "Best params: {'regressor__subsample': 0.7, 'regressor__reg_lambda': 0.0, 'regressor__reg_alpha': 0.0, 'regressor__num_leaves': 31, 'regressor__n_estimators': 400, 'regressor__min_child_samples': 5, 'regressor__max_depth': 16, 'regressor__learning_rate': 0.02, 'regressor__colsample_bytree': 0.7}\n",
      "Best CV (neg MSE): -1164.9344038396512\n",
      "Test performance of best model -> MAE=23.733, RMSE=33.762, R2=0.5721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved feature importance to lgbm_tuned_feature_importance.csv\n",
      "Tuning finished. Artifacts saved:\n",
      " - lgbm_random_search_results.csv\n",
      " - lgbm_tuned_model.joblib\n",
      " - lgbm_tuned_feature_importance.csv\n",
      " - lgbm_tuning_summary.json\n",
      "\n",
      "View runs in MLflow UI: `mlflow ui` (then open http://127.0.0.1:5000)\n"
     ]
    }
   ],
   "source": [
    "# LightGBM hyperparameter tuning (RandomizedSearchCV) + MLflow logging\n",
    "import os, json, joblib\n",
    "from pathlib import Path\n",
    "from math import sqrt\n",
    "import pandas as pd, numpy as np\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Ensure LightGBM available\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "except Exception as e:\n",
    "    raise ImportError(\"lightgbm is not available in this environment. Install it first (pip install lightgbm).\") from e\n",
    "\n",
    "# ---------- Files & MLflow ----------\n",
    "CLEAN_IN = 'amazon_delivery_cleaned.csv'\n",
    "if not os.path.exists(CLEAN_IN):\n",
    "    raise FileNotFoundError(f\"{CLEAN_IN} not found in working dir: {os.getcwd()}\")\n",
    "\n",
    "os.makedirs(\"mlruns\", exist_ok=True)\n",
    "mlflow.set_tracking_uri(Path(os.path.abspath(\"mlruns\")).as_uri())\n",
    "EXP_NAME = \"lightgbm_tuning\"\n",
    "mlflow.set_experiment(EXP_NAME)\n",
    "print(\"MLflow experiment:\", EXP_NAME, \"| tracking URI:\", mlflow.get_tracking_uri())\n",
    "\n",
    "# ---------- Load dataset & features (post-FE) ----------\n",
    "df = pd.read_csv(CLEAN_IN)\n",
    "print(\"Loaded dataset:\", df.shape)\n",
    "\n",
    "num_feats = [c for c in [\n",
    "    'distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed',\n",
    "    'hour_sin','hour_cos','agent_perf_score'\n",
    "] if c in df.columns]\n",
    "\n",
    "cat_feats = [c for c in [\n",
    "    'Weather_imputed','Traffic','Vehicle','Area','Category_grp','part_of_day',\n",
    "    'distance_bucket','Traffic_Weather','Area_PartOfDay','CatTraffic','agent_experience_bucket'\n",
    "] if c in df.columns]\n",
    "\n",
    "print(\"Numeric features:\", num_feats)\n",
    "print(\"Categorical features:\", cat_feats)\n",
    "\n",
    "# ---------- Prepare data ----------\n",
    "df_model = df.dropna(subset=['Delivery_Time']).copy()\n",
    "X = df_model[num_feats + cat_feats]\n",
    "y = df_model['Delivery_Time']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# ---------- Preprocessing ----------\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "# OHE compatibility\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', ohe)\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, num_feats),\n",
    "    ('cat', categorical_transformer, cat_feats)\n",
    "])\n",
    "\n",
    "# ---------- Pipeline with LGBM ----------\n",
    "lgb = LGBMRegressor(random_state=42, n_jobs=-1)\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', lgb)])\n",
    "\n",
    "# ---------- Parameter distributions for RandomizedSearchCV ----------\n",
    "param_dist = {\n",
    "    'regressor__num_leaves': [31, 50, 80, 100, 150],\n",
    "    'regressor__learning_rate': [0.01, 0.02, 0.03, 0.05, 0.08, 0.1],\n",
    "    'regressor__n_estimators': [100, 200, 400, 800],\n",
    "    'regressor__max_depth': [-1, 6, 10, 16],\n",
    "    'regressor__min_child_samples': [5, 10, 20, 40, 80],\n",
    "    'regressor__subsample': [0.6, 0.7, 0.8, 1.0],\n",
    "    'regressor__colsample_bytree': [0.6, 0.7, 0.8, 1.0],\n",
    "    'regressor__reg_alpha': [0.0, 0.1, 0.5, 1.0],\n",
    "    'regressor__reg_lambda': [0.0, 0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# ---------- RandomizedSearchCV setup ----------\n",
    "n_iter_search = 30   # set to 30; reduce to 10 for faster runs\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=n_iter_search,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# ---------- Run randomized search and log to MLflow ----------\n",
    "with mlflow.start_run(run_name=\"lightgbm_randomized_search\"):\n",
    "    print(\"Starting RandomizedSearchCV (this may take a while)...\")\n",
    "    random_search.fit(X_train, y_train)\n",
    "    print(\"Randomized search complete.\")\n",
    "    # Save CV results\n",
    "    cv_results_df = pd.DataFrame(random_search.cv_results_)\n",
    "    cv_results_csv = 'lgbm_random_search_results.csv'\n",
    "    cv_results_df.to_csv(cv_results_csv, index=False)\n",
    "    mlflow.log_artifact(cv_results_csv)\n",
    "    # Best params & cv score\n",
    "    best_params = random_search.best_params_\n",
    "    best_score = random_search.best_score_   # negative MSE\n",
    "    print(\"Best params:\", best_params)\n",
    "    print(\"Best CV (neg MSE):\", best_score)\n",
    "    mlflow.log_param('n_iter_search', n_iter_search)\n",
    "    # log best params\n",
    "    for k,v in best_params.items():\n",
    "        mlflow.log_param(k, str(v))\n",
    "    mlflow.log_metric('best_cv_neg_mse', float(best_score))\n",
    "\n",
    "    # Evaluate best estimator on test set\n",
    "    best_pipe = random_search.best_estimator_\n",
    "    y_pred = best_pipe.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Test performance of best model -> MAE={mae:.3f}, RMSE={rmse:.3f}, R2={r2:.4f}\")\n",
    "\n",
    "    mlflow.log_metric('test_mae', float(mae))\n",
    "    mlflow.log_metric('test_rmse', float(rmse))\n",
    "    mlflow.log_metric('test_r2', float(r2))\n",
    "\n",
    "    # Save tuned model\n",
    "    tuned_model_file = 'lgbm_tuned_model.joblib'\n",
    "    joblib.dump(best_pipe, tuned_model_file)\n",
    "    mlflow.log_artifact(tuned_model_file)\n",
    "\n",
    "    # Feature importances (get feature names after preprocessing)\n",
    "    try:\n",
    "        pre = best_pipe.named_steps['preprocessor']\n",
    "        # numeric names\n",
    "        num_names = list(pre.transformers_[0][2]) if pre.transformers_[0][2] is not None else []\n",
    "        # categorical ohe names\n",
    "        ohe_inst = pre.named_transformers_['cat'].named_steps['onehot']\n",
    "        try:\n",
    "            if hasattr(ohe_inst, 'feature_names_in_') and getattr(ohe_inst,'feature_names_in_', None) is not None:\n",
    "                cat_in = list(ohe_inst.feature_names_in_)\n",
    "                cat_ohe = list(ohe_inst.get_feature_names_out(cat_in))\n",
    "            else:\n",
    "                cat_ohe = list(ohe_inst.get_feature_names_out())\n",
    "        except Exception:\n",
    "            cat_ohe = list(ohe_inst.get_feature_names_out())\n",
    "        feat_names = num_names + cat_ohe\n",
    "        # access underlying LGBM regressor\n",
    "        reg = best_pipe.named_steps['regressor']\n",
    "        importances = reg.feature_importances_\n",
    "        # align lengths\n",
    "        if len(importances) != len(feat_names):\n",
    "            minlen = min(len(importances), len(feat_names))\n",
    "            feat_names = feat_names[:minlen]\n",
    "            importances = importances[:minlen]\n",
    "        fi_df = pd.DataFrame({'feature': feat_names, 'importance': importances})\n",
    "        fi_df = fi_df.sort_values('importance', ascending=False)\n",
    "        fi_csv = 'lgbm_tuned_feature_importance.csv'\n",
    "        fi_df.to_csv(fi_csv, index=False)\n",
    "        mlflow.log_artifact(fi_csv)\n",
    "        print(\"Saved feature importance to\", fi_csv)\n",
    "    except Exception as e:\n",
    "        print(\"Warning: could not extract feature importances:\", e)\n",
    "\n",
    "    # save summary json\n",
    "    summary = {\n",
    "        'best_params': {k: str(v) for k, v in best_params.items()},\n",
    "        'best_cv_neg_mse': float(best_score),\n",
    "        'test_mae': float(mae),\n",
    "        'test_rmse': float(rmse),\n",
    "        'test_r2': float(r2)\n",
    "    }\n",
    "    with open('lgbm_tuning_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    mlflow.log_artifact('lgbm_tuning_summary.json')\n",
    "\n",
    "print(\"Tuning finished. Artifacts saved:\")\n",
    "print(\" -\", cv_results_csv)\n",
    "print(\" -\", tuned_model_file)\n",
    "print(\" - lgbm_tuned_feature_importance.csv\")\n",
    "print(\" - lgbm_tuning_summary.json\")\n",
    "print(\"\\nView runs in MLflow UI: `mlflow ui` (then open http://127.0.0.1:5000)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a7e68-e492-450b-b58c-9366b0c267b4",
   "metadata": {},
   "source": [
    "## LightGBM Hyperparameter Tuning  Results & Interpretation\n",
    "\n",
    "**Best hyperparameters found**\n",
    "- `num_leaves`: **31**  \n",
    "- `learning_rate`: **0.02**  \n",
    "- `n_estimators`: **400**  \n",
    "- `max_depth`: **16**  \n",
    "- `min_child_samples`: **5**  \n",
    "- `subsample`: **0.7**  \n",
    "- `colsample_bytree`: **0.7**  \n",
    "- `reg_alpha`: **0.0**, `reg_lambda`: **0.0**\n",
    "\n",
    "**Best CV score**\n",
    "- Best CV (negative MSE): **-1164.9344**\n",
    "\n",
    "**Test (holdout) performance of tuned LightGBM**\n",
    "- **MAE** = **23.733** minutes  \n",
    "- **RMSE** = **33.762** minutes  \n",
    "- **R** = **0.5721**\n",
    "\n",
    "**Artifacts**\n",
    "- `lgbm_random_search_results.csv`  CV results for all candidates.  \n",
    "- `lgbm_tuned_model.joblib`  the tuned pipeline (preprocessor + LGBM).  \n",
    "- `lgbm_tuned_feature_importance.csv`  feature importances.  \n",
    "- `lgbm_tuning_summary.json`  concise summary.\n",
    "\n",
    "### Comparison (selected models)\n",
    "- **Baseline Lasso (before FE)**  MAE  26.20, RMSE  33.27, R  0.585  \n",
    "- **LightGBM (untuned)**  MAE  24.03, RMSE  34.21, R  0.561  \n",
    "- **LightGBM (tuned)**  MAE = **23.73**, RMSE = **33.76**, R = **0.572**\n",
    "\n",
    "**Interpretation**\n",
    "- Tuning improved LightGBM (lower MAE and RMSE vs untuned).  \n",
    "- Tuned LightGBM now has superior MAE to the linear baseline and comparable RMSE.  \n",
    "- Engineered categorical interactions are being exploited by LightGBM; tree models are the right family for these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68513f60-4281-4c19-87b6-6a3d27f0c765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shap not found  installing shap...\n",
      "Num features detected: ['distance_km', 'order_to_pickup_mins', 'Agent_Age', 'Agent_Rating_imputed', 'hour_sin', 'hour_cos']\n",
      "Cat features detected: ['Weather_imputed', 'Traffic', 'Vehicle', 'Area', 'Category_grp', 'part_of_day', 'distance_bucket', 'Traffic_Weather', 'Area_PartOfDay', 'CatTraffic']\n",
      "Total transformed features (after preprocessor): 131\n",
      "Transformed X_test shape: (8748, 131)\n",
      "Computing SHAP values (this may take a minute)...\n",
      "Computed SHAP array shape: (8748, 131)\n",
      "Saved top 20 SHAP features to: shap_outputs\\shap_top20_features.csv\n",
      "Saved SHAP summary plot to: shap_outputs\\shap_summary.png\n",
      "Saved dependence plot for Agent_Age -> shap_outputs\\shap_dependence_Agent_Age.png\n",
      "Saved dependence plot for distance_km -> shap_outputs\\shap_dependence_distance_km.png\n",
      "Saved dependence plot for Agent_Rating_imputed -> shap_outputs\\shap_dependence_Agent_Rating_imputed.png\n",
      "Saved sample SHAP values to: shap_outputs\\shap_sample_values.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/24 23:59:24 INFO mlflow.tracking.fluent: Experiment with name 'explainability' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved compressed full SHAP array to: shap_outputs\\shap_values_full.npz\n",
      "\n",
      "SHAP explainability run complete.\n",
      "Artifacts saved under: shap_outputs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SHAP explainability\n",
    "# - Installs shap into the current kernel if missing\n",
    "# - Loads lgbm_tuned_model.joblib (pipeline: preprocessor + LGBMRegressor)\n",
    "# - Computes SHAP values on a held-out test set from amazon_delivery_cleaned.csv\n",
    "# - Saves: shap_summary.png, shap_top20_features.csv, shap_dependence_<feat>.png, shap_sample_values.csv\n",
    "# - Logs artifacts to MLflow experiment 'explainability'\n",
    "\n",
    "import os, sys, subprocess, joblib, json\n",
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Ensure shap is installed in the current kernel\n",
    "try:\n",
    "    import shap\n",
    "except Exception:\n",
    "    print(\"shap not found  installing shap...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"shap\"])\n",
    "    import shap\n",
    "\n",
    "# sklearn / mlflow imports\n",
    "from math import sqrt\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# File checks\n",
    "CLEAN_IN = 'amazon_delivery_cleaned.csv'\n",
    "TUNED_MODEL = 'lgbm_tuned_model.joblib'  # produced by your tuning run\n",
    "OUT_DIR = 'shap_outputs'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(CLEAN_IN):\n",
    "    raise FileNotFoundError(f\"{CLEAN_IN} not found in working dir: {os.getcwd()}\")\n",
    "\n",
    "if not os.path.exists(TUNED_MODEL):\n",
    "    raise FileNotFoundError(f\"{TUNED_MODEL} not found  please run LightGBM tuning first and ensure the file exists.\")\n",
    "\n",
    "# 2) Load data and recreate feature lists (post-FE)\n",
    "df = pd.read_csv(CLEAN_IN)\n",
    "# numeric & categorical feature lists used in the pipeline (post-FE)\n",
    "num_feats = [c for c in [\n",
    "    'distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed',\n",
    "    'hour_sin','hour_cos','agent_perf_score'\n",
    "] if c in df.columns]\n",
    "\n",
    "cat_feats = [c for c in [\n",
    "    'Weather_imputed','Traffic','Vehicle','Area','Category_grp','part_of_day',\n",
    "    'distance_bucket','Traffic_Weather','Area_PartOfDay','CatTraffic','agent_experience_bucket'\n",
    "] if c in df.columns]\n",
    "\n",
    "print(\"Num features detected:\", num_feats)\n",
    "print(\"Cat features detected:\", cat_feats)\n",
    "\n",
    "# Prepare model dataset and train/test split (same random_state used earlier)\n",
    "df_model = df.dropna(subset=['Delivery_Time']).copy()\n",
    "X = df_model[num_feats + cat_feats]\n",
    "y = df_model['Delivery_Time']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# 3) Load tuned pipeline\n",
    "pipeline = joblib.load(TUNED_MODEL)\n",
    "if not isinstance(pipeline, Pipeline):\n",
    "    raise RuntimeError(f\"{TUNED_MODEL} does not appear to be a sklearn Pipeline. It should be pipeline (preprocessor + regressor).\")\n",
    "\n",
    "# Extract preprocessor and regressor\n",
    "preprocessor = pipeline.named_steps.get('preprocessor', None)\n",
    "regressor = pipeline.named_steps.get('regressor', None)\n",
    "if preprocessor is None or regressor is None:\n",
    "    raise RuntimeError(\"Loaded pipeline must have named steps 'preprocessor' and 'regressor'.\")\n",
    "\n",
    "# 4) Reconstruct feature names after preprocessing (numeric + one-hot names)\n",
    "def get_feature_names_from_preprocessor(preproc):\n",
    "    # numeric input names\n",
    "    num_names = list(preproc.transformers_[0][2]) if preproc.transformers_[0][2] is not None else []\n",
    "    # categorical OHE expansion\n",
    "    cat_ohe_names = []\n",
    "    try:\n",
    "        cat_transformer = preproc.named_transformers_['cat']\n",
    "        ohe = cat_transformer.named_steps['onehot']\n",
    "        # try to use feature_names_in_ when available, else fallback to given cat_feats\n",
    "        try:\n",
    "            if hasattr(ohe, 'feature_names_in_') and getattr(ohe, 'feature_names_in_', None) is not None:\n",
    "                cat_in = list(ohe.feature_names_in_)\n",
    "                cat_ohe_names = list(ohe.get_feature_names_out(cat_in))\n",
    "            else:\n",
    "                # fallback to the cat_feats list passed earlier (must match encoder order)\n",
    "                cat_ohe_names = list(ohe.get_feature_names_out(cat_feats))\n",
    "        except Exception:\n",
    "            # last resort: call without args\n",
    "            cat_ohe_names = list(ohe.get_feature_names_out())\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\"Could not extract OneHotEncoder from preprocessor: \" + str(e))\n",
    "    return num_names + cat_ohe_names\n",
    "\n",
    "feature_names = get_feature_names_from_preprocessor(preprocessor)\n",
    "print(\"Total transformed features (after preprocessor):\", len(feature_names))\n",
    "\n",
    "# 5) Transform X_test using the preprocessor to the numeric matrix (what the regressor sees)\n",
    "X_test_trans = preprocessor.transform(X_test)  # numpy array\n",
    "print(\"Transformed X_test shape:\", X_test_trans.shape)\n",
    "\n",
    "# 6) Create SHAP explainer for tree model and compute shap values\n",
    "# For LGBMRegressor, use TreeExplainer\n",
    "explainer = shap.TreeExplainer(regressor)\n",
    "# shap can accept numpy arrays; pass transformed matrix\n",
    "print(\"Computing SHAP values (this may take a minute)...\")\n",
    "shap_values = explainer.shap_values(X_test_trans)  # shape (n_samples, n_features)\n",
    "# For LightGBM regressor, shap_values should be 1D per sample; ensure shape is (n_samples, n_features)\n",
    "shap_vals = np.array(shap_values)\n",
    "if shap_vals.ndim == 3 and shap_vals.shape[0] == 1:\n",
    "    # sometimes shap returns (1, n_samples, n_features)\n",
    "    shap_vals = shap_vals[0]\n",
    "print(\"Computed SHAP array shape:\", shap_vals.shape)\n",
    "\n",
    "# 7) Global summary: mean absolute SHAP -> top features\n",
    "mean_abs_shap = np.abs(shap_vals).mean(axis=0)\n",
    "shap_df = pd.DataFrame({'feature': feature_names, 'mean_abs_shap': mean_abs_shap})\n",
    "shap_df = shap_df.sort_values('mean_abs_shap', ascending=False).reset_index(drop=True)\n",
    "top20 = shap_df.head(20)\n",
    "top20_csv = os.path.join(OUT_DIR, 'shap_top20_features.csv')\n",
    "top20.to_csv(top20_csv, index=False)\n",
    "print(\"Saved top 20 SHAP features to:\", top20_csv)\n",
    "\n",
    "# 8) Save SHAP summary plot (global)\n",
    "plt.figure(figsize=(10,8))\n",
    "shap.summary_plot(shap_vals, features=X_test_trans, feature_names=feature_names, show=False, plot_type=\"bar\")\n",
    "plt.tight_layout()\n",
    "summary_png = os.path.join(OUT_DIR, 'shap_summary.png')\n",
    "plt.savefig(summary_png, dpi=200)\n",
    "plt.close()\n",
    "print(\"Saved SHAP summary plot to:\", summary_png)\n",
    "\n",
    "# 9) Dependence plots for top 3 features\n",
    "top_feats = top20['feature'].tolist()[:3]\n",
    "for feat in top_feats:\n",
    "    # shap.dependence_plot expects original data (matrix) and feature index or name\n",
    "    try:\n",
    "        idx = feature_names.index(feat)\n",
    "        plt.figure(figsize=(8,6))\n",
    "        shap.dependence_plot(idx, shap_vals, X_test_trans, feature_names=feature_names, show=False)\n",
    "        dep_png = os.path.join(OUT_DIR, f\"shap_dependence_{feat.replace(':','_').replace(' ','_')}.png\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dep_png, dpi=200)\n",
    "        plt.close()\n",
    "        print(\"Saved dependence plot for\", feat, \"->\", dep_png)\n",
    "    except Exception as e:\n",
    "        print(\"Could not create dependence plot for\", feat, \":\", e)\n",
    "\n",
    "# 10) Save per-sample SHAP values for first N rows (to keep size manageable)\n",
    "N = min(200, X_test_trans.shape[0])\n",
    "sample_shap = pd.DataFrame(shap_vals[:N, :], columns=feature_names)\n",
    "sample_shap.insert(0, 'row_index', np.arange(N))\n",
    "sample_csv = os.path.join(OUT_DIR, 'shap_sample_values.csv')\n",
    "sample_shap.to_csv(sample_csv, index=False)\n",
    "print(\"Saved sample SHAP values to:\", sample_csv)\n",
    "\n",
    "# 11) Save full SHAP matrix (optional - may be large). We'll save compressed npz\n",
    "full_shap_npz = os.path.join(OUT_DIR, 'shap_values_full.npz')\n",
    "np.savez_compressed(full_shap_npz, shap=shap_vals)\n",
    "print(\"Saved compressed full SHAP array to:\", full_shap_npz)\n",
    "\n",
    "# 12) Log artifacts to MLflow under experiment 'explainability'\n",
    "os.makedirs(\"mlruns\", exist_ok=True)\n",
    "mlflow.set_tracking_uri(Path(os.path.abspath(\"mlruns\")).as_uri())\n",
    "mlflow.set_experiment('explainability')\n",
    "with mlflow.start_run(run_name='shap_explainability'):\n",
    "    mlflow.log_artifact(summary_png)\n",
    "    mlflow.log_artifact(top20_csv)\n",
    "    mlflow.log_artifact(sample_csv)\n",
    "    mlflow.log_artifact(full_shap_npz)\n",
    "    # log dependence plots if created\n",
    "    for feat in top_feats:\n",
    "        dep_png = os.path.join(OUT_DIR, f\"shap_dependence_{feat.replace(':','_').replace(' ','_')}.png\")\n",
    "        if os.path.exists(dep_png):\n",
    "            mlflow.log_artifact(dep_png)\n",
    "    # Save a small JSON summary\n",
    "    expl_summary = {\n",
    "        'n_test_rows_explained': int(X_test_trans.shape[0]),\n",
    "        'n_transformed_features': int(X_test_trans.shape[1]),\n",
    "        'top_features': top20['feature'].tolist()\n",
    "    }\n",
    "    with open(os.path.join(OUT_DIR, 'shap_explain_summary.json'), 'w') as f:\n",
    "        json.dump(expl_summary, f, indent=2)\n",
    "    mlflow.log_artifact(os.path.join(OUT_DIR, 'shap_explain_summary.json'))\n",
    "\n",
    "print(\"\\nSHAP explainability run complete.\")\n",
    "print(\"Artifacts saved under:\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07516d92-1106-49a9-a349-83fb86cb1045",
   "metadata": {},
   "source": [
    "## SHAP Explainability Results (Tuned LightGBM)\n",
    "\n",
    "### Top 20 Most Influential Features\n",
    "1. Agent_Age  \n",
    "2. distance_km  \n",
    "3. Agent_Rating_imputed  \n",
    "4. Traffic_Low  \n",
    "5. Category_grp_Other  \n",
    "6. Vehicle_motorcycle  \n",
    "7. Weather_imputed_Sunny  \n",
    "8. Weather_imputed_Fog  \n",
    "9. Weather_imputed_Cloudy  \n",
    "10. Traffic_Jam  \n",
    "11. Area_Metropolitian  \n",
    "12. Traffic_Weather_Jam_Cloudy  \n",
    "13. Traffic_Weather_Jam_Fog  \n",
    "14. CatTraffic_Other_Low  \n",
    "15. distance_bucket_long  \n",
    "16. hour_sin  \n",
    "17. Vehicle_scooter  \n",
    "18. Traffic_Medium  \n",
    "19. Traffic_Weather_Medium_Fog  \n",
    "20. Traffic_Weather_Jam_Sunny  \n",
    "\n",
    "---\n",
    "\n",
    "### Insights\n",
    "- **Agent factors dominate**: Age and ratings are top drivers of delivery time.  \n",
    "- **Distance matters**: Both raw (`distance_km`) and binned (`distance_bucket_long`).  \n",
    "- **Traffic & Weather critical**: Interactions (e.g., Traffic  Weather) are highly impactful.  \n",
    "- **Category influences**: Category grouping and category  traffic interactions matter.  \n",
    "- **Vehicle effects**: Motorcycle and scooter usage strongly linked to delivery time.  \n",
    "- **Temporal effects**: `hour_sin` indicates time-of-day patterns.\n",
    "\n",
    "---\n",
    "\n",
    "### Takeaways\n",
    "- Engineered features (traffic  weather, category  traffic, distance bucket, temporal encodings) are highly valuable.  \n",
    "- Agent-related variables are crucial predictors.  \n",
    "- Using **LightGBM with native categorical features** (instead of OHE) could further improve accuracy by reducing feature dimensionality.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "184b7e2d-c587-4254-8b87-e1b7f7821848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/25 20:28:09 INFO mlflow.tracking.fluent: Experiment with name 'lightgbm_native_cat' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow experiment: lightgbm_native_cat | tracking URI: file:///C:/Users/shail_u9zs758/mlruns\n",
      "Loaded dataset shape: (43739, 35)\n",
      "Numeric features: ['distance_km', 'order_to_pickup_mins', 'Agent_Age', 'Agent_Rating_imputed', 'hour_sin', 'hour_cos']\n",
      "Categorical features (native): ['Weather_imputed', 'Traffic', 'Vehicle', 'Area', 'Category_grp', 'part_of_day', 'distance_bucket', 'Traffic_Weather', 'Area_PartOfDay', 'CatTraffic']\n",
      "Train/Val/Test shapes: (27992, 16) (6999, 16) (8748, 16)\n",
      "Processed feature matrix shapes: (27992, 16) (6999, 16) (8748, 16)\n",
      "Loaded tuned params from lgbm_tuning_summary.json\n",
      "Using LightGBM params: {'num_leaves': 31, 'learning_rate': 0.02, 'n_estimators': 400, 'max_depth': 16, 'min_child_samples': 5, 'subsample': 0.7, 'colsample_bytree': 0.7}\n",
      "Categorical features passed to LightGBM: ['Weather_imputed', 'Traffic', 'Vehicle', 'Area', 'Category_grp', 'part_of_day', 'distance_bucket', 'Traffic_Weather', 'Area_PartOfDay', 'CatTraffic']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LGBMRegressor.fit() got an unexpected keyword argument 'early_stopping_rounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 157\u001b[0m\n\u001b[0;32m    153\u001b[0m cat_feature_list \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cat_feats \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m X_train_proc\u001b[38;5;241m.\u001b[39mcolumns]\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategorical features passed to LightGBM:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cat_feature_list)\n\u001b[1;32m--> 157\u001b[0m lgb\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    158\u001b[0m     X_train_proc,\n\u001b[0;32m    159\u001b[0m     y_train,\n\u001b[0;32m    160\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39m[(X_val_proc, y_val)],\n\u001b[0;32m    161\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m    162\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    163\u001b[0m     categorical_feature\u001b[38;5;241m=\u001b[39mcat_feature_list,\n\u001b[0;32m    164\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\n\u001b[0;32m    165\u001b[0m )\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# ---------- Evaluate on test set ----------\u001b[39;00m\n\u001b[0;32m    168\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mpredict(X_test_proc)\n",
      "\u001b[1;31mTypeError\u001b[0m: LGBMRegressor.fit() got an unexpected keyword argument 'early_stopping_rounds'"
     ]
    }
   ],
   "source": [
    "# Train LightGBM using native categorical features (no OHE) + MLflow logging\n",
    "\n",
    "import os, json, joblib\n",
    "from pathlib import Path\n",
    "from math import sqrt\n",
    "import pandas as pd, numpy as np\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Ensure LightGBM is available\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "except Exception as e:\n",
    "    raise ImportError(\"lightgbm is not installed in this environment. Install it and re-run.\") from e\n",
    "\n",
    "# ---------- Files and MLflow setup ----------\n",
    "CLEAN_IN = 'amazon_delivery_cleaned.csv'\n",
    "if not os.path.exists(CLEAN_IN):\n",
    "    raise FileNotFoundError(f\"{CLEAN_IN} not found in working dir: {os.getcwd()}\")\n",
    "\n",
    "os.makedirs(\"mlruns\", exist_ok=True)\n",
    "mlflow.set_tracking_uri(Path(os.path.abspath(\"mlruns\")).as_uri())\n",
    "EXP_NAME = 'lightgbm_native_cat'\n",
    "mlflow.set_experiment(EXP_NAME)\n",
    "print(\"MLflow experiment:\", EXP_NAME, \"| tracking URI:\", mlflow.get_tracking_uri())\n",
    "\n",
    "# ---------- Load data and define features ----------\n",
    "df = pd.read_csv(CLEAN_IN)\n",
    "print(\"Loaded dataset shape:\", df.shape)\n",
    "\n",
    "# numeric & categorical feature lists (keep same names)\n",
    "num_feats = [c for c in [\n",
    "    'distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed',\n",
    "    'hour_sin','hour_cos','agent_perf_score'\n",
    "] if c in df.columns]\n",
    "\n",
    "cat_feats = [c for c in [\n",
    "    'Weather_imputed','Traffic','Vehicle','Area','Category_grp','part_of_day',\n",
    "    'distance_bucket','Traffic_Weather','Area_PartOfDay','CatTraffic','agent_experience_bucket'\n",
    "] if c in df.columns]\n",
    "\n",
    "print(\"Numeric features:\", num_feats)\n",
    "print(\"Categorical features (native):\", cat_feats)\n",
    "\n",
    "# ---------- Prepare modelling DataFrame ----------\n",
    "df_model = df.dropna(subset=['Delivery_Time']).copy()\n",
    "X = df_model[num_feats + cat_feats].copy()\n",
    "y = df_model['Delivery_Time'].copy()\n",
    "\n",
    "# convert categorical columns to pandas 'category' dtype\n",
    "for c in cat_feats:\n",
    "    if c in X.columns:\n",
    "        X[c] = X[c].astype('category')\n",
    "\n",
    "# split train/test (same random_state as before)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# further split train into train/val for early stopping\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.20, random_state=42)\n",
    "\n",
    "print(\"Train/Val/Test shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "# ---------- Numeric preprocessing: impute + scale (fit on train only) ----------\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "if len(num_feats) > 0:\n",
    "    X_train_num = pd.DataFrame(num_imputer.fit_transform(X_train[num_feats]), columns=num_feats, index=X_train.index)\n",
    "    X_train_num = pd.DataFrame(scaler.fit_transform(X_train_num), columns=num_feats, index=X_train.index)\n",
    "\n",
    "    X_val_num = pd.DataFrame(scaler.transform(pd.DataFrame(num_imputer.transform(X_val[num_feats]), columns=num_feats, index=X_val.index)),\n",
    "                             columns=num_feats, index=X_val.index)\n",
    "    X_test_num = pd.DataFrame(scaler.transform(pd.DataFrame(num_imputer.transform(X_test[num_feats]), columns=num_feats, index=X_test.index)),\n",
    "                              columns=num_feats, index=X_test.index)\n",
    "else:\n",
    "    X_train_num = pd.DataFrame(index=X_train.index)\n",
    "    X_val_num = pd.DataFrame(index=X_val.index)\n",
    "    X_test_num = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "# keep categorical columns as-is (category dtype)\n",
    "X_train_cat = X_train[cat_feats].copy()\n",
    "X_val_cat = X_val[cat_feats].copy()\n",
    "X_test_cat = X_test[cat_feats].copy()\n",
    "\n",
    "# Reconstruct final DataFrames (concatenate numeric scaled + categorical)\n",
    "X_train_proc = pd.concat([X_train_num.reset_index(drop=True), X_train_cat.reset_index(drop=True)], axis=1)\n",
    "X_val_proc = pd.concat([X_val_num.reset_index(drop=True), X_val_cat.reset_index(drop=True)], axis=1)\n",
    "X_test_proc = pd.concat([X_test_num.reset_index(drop=True), X_test_cat.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Ensure categorical dtypes preserved in final DataFrames\n",
    "for c in cat_feats:\n",
    "    if c in X_train_proc.columns:\n",
    "        X_train_proc[c] = X_train_proc[c].astype('category')\n",
    "        X_val_proc[c] = X_val_proc[c].astype('category')\n",
    "        X_test_proc[c] = X_test_proc[c].astype('category')\n",
    "\n",
    "print(\"Processed feature matrix shapes:\", X_train_proc.shape, X_val_proc.shape, X_test_proc.shape)\n",
    "\n",
    "# ---------- Load tuned params if available (from previous tuning) ----------\n",
    "tuned_params_file = 'lgbm_tuning_summary.json'\n",
    "default_params = {\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.02,\n",
    "    'n_estimators': 400,\n",
    "    'max_depth': 16,\n",
    "    'min_child_samples': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'reg_alpha': 0.0,\n",
    "    'reg_lambda': 0.0,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "if os.path.exists(tuned_params_file):\n",
    "    try:\n",
    "        with open(tuned_params_file, 'r') as f:\n",
    "            summary = json.load(f)\n",
    "        # best_params in file were saved as strings earlier  try to read lgbm_tuning_summary.json if consistent\n",
    "        if 'best_params' in summary:\n",
    "            # if structure is same as earlier cell\n",
    "            bp = summary['best_params']\n",
    "            # convert strings back to numeric where possible\n",
    "            for k, v in bp.items():\n",
    "                try:\n",
    "                    # remove regressor__ prefix if present\n",
    "                    kk = k.replace('regressor__', '')\n",
    "                    default_params[kk] = float(v) if (str(v).replace('.','',1).isdigit()) else v\n",
    "                except Exception:\n",
    "                    default_params[kk] = v\n",
    "            print(\"Loaded tuned params from\", tuned_params_file)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# finalize params (ensure ints where necessary)\n",
    "params = default_params.copy()\n",
    "params['num_leaves'] = int(params.get('num_leaves', 31))\n",
    "params['n_estimators'] = int(params.get('n_estimators', 400))\n",
    "params['max_depth'] = int(params.get('max_depth', 16))\n",
    "params['min_child_samples'] = int(params.get('min_child_samples', 5))\n",
    "\n",
    "print(\"Using LightGBM params:\", {k: params[k] for k in ['num_leaves','learning_rate','n_estimators','max_depth','min_child_samples','subsample','colsample_bytree']})\n",
    "\n",
    "# ---------- Train LGBM with categorical features specified ----------\n",
    "lgb = LGBMRegressor(**params)\n",
    "\n",
    "# Fit with early stopping using validation set. Pass categorical_feature as list of names.\n",
    "# LightGBM accepts categorical_feature names when given a pandas DataFrame\n",
    "cat_feature_list = [c for c in cat_feats if c in X_train_proc.columns]\n",
    "\n",
    "print(\"Categorical features passed to LightGBM:\", cat_feature_list)\n",
    "\n",
    "lgb.fit(\n",
    "    X_train_proc,\n",
    "    y_train,\n",
    "    eval_set=[(X_val_proc, y_val)],\n",
    "    early_stopping_rounds=50,\n",
    "    eval_metric='rmse',\n",
    "    categorical_feature=cat_feature_list,\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "# ---------- Evaluate on test set ----------\n",
    "y_pred = lgb.predict(X_test_proc)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Native-cat LightGBM test metrics -> MAE={mae:.3f}, RMSE={rmse:.3f}, R2={r2:.4f}\")\n",
    "\n",
    "# ---------- Save artifacts & log to MLflow ----------\n",
    "model_file = 'lgbm_native_cat_model.joblib'\n",
    "joblib.dump(lgb, model_file)\n",
    "\n",
    "# feature importances\n",
    "feature_names = list(X_train_proc.columns)\n",
    "importances = lgb.feature_importances_\n",
    "# align lengths (should match)\n",
    "if len(importances) != len(feature_names):\n",
    "    minlen = min(len(importances), len(feature_names))\n",
    "    feature_names = feature_names[:minlen]\n",
    "    importances = importances[:minlen]\n",
    "fi_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "fi_df = fi_df.sort_values('importance', ascending=False)\n",
    "fi_csv = 'lgbm_native_cat_feature_importance.csv'\n",
    "fi_df.to_csv(fi_csv, index=False)\n",
    "\n",
    "# pred vs actual plot\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(y_test, y_pred, s=8, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Delivery_Time (mins)'); plt.ylabel('Predicted Delivery_Time (mins)')\n",
    "plt.title('LGBM (native categorical) Predicted vs Actual')\n",
    "pfile = 'lgbm_native_cat_pred_vs_actual.png'\n",
    "plt.tight_layout(); plt.savefig(pfile); plt.close()\n",
    "\n",
    "summary = {\n",
    "    'model_file': model_file,\n",
    "    'test_mae': float(mae),\n",
    "    'test_rmse': float(rmse),\n",
    "    'test_r2': float(r2),\n",
    "    'params': params\n",
    "}\n",
    "with open('lgbm_native_cat_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# MLflow logging\n",
    "with mlflow.start_run(run_name='lgbm_native_cat'):\n",
    "    mlflow.log_params({k: params[k] for k in ['num_leaves','learning_rate','n_estimators','max_depth','min_child_samples','subsample','colsample_bytree']})\n",
    "    mlflow.log_metric('test_mae', float(mae))\n",
    "    mlflow.log_metric('test_rmse', float(rmse))\n",
    "    mlflow.log_metric('test_r2', float(r2))\n",
    "    mlflow.log_artifact(model_file)\n",
    "    mlflow.log_artifact(fi_csv)\n",
    "    mlflow.log_artifact(pfile)\n",
    "    mlflow.log_artifact('lgbm_native_cat_summary.json')\n",
    "\n",
    "print(\"\\nSaved artifacts:\")\n",
    "print(\" -\", model_file)\n",
    "print(\" -\", fi_csv)\n",
    "print(\" -\", pfile)\n",
    "print(\" - lgbm_native_cat_summary.json\")\n",
    "print(\"\\nDone. You can open MLflow UI (mlflow ui) to compare this run with previous experiments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae45a13e-6b57-4f0b-9a5f-eb100f6ab603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow experiment: lightgbm_native_cat | tracking URI: file:///C:/Users/shail_u9zs758/mlruns\n",
      "Loaded dataset shape: (43739, 35)\n",
      "Numeric features: ['distance_km', 'order_to_pickup_mins', 'Agent_Age', 'Agent_Rating_imputed', 'hour_sin', 'hour_cos']\n",
      "Categorical features (native): ['Weather_imputed', 'Traffic', 'Vehicle', 'Area', 'Category_grp', 'part_of_day', 'distance_bucket', 'Traffic_Weather', 'Area_PartOfDay', 'CatTraffic']\n",
      "Train/Val/Test shapes: (27992, 16) (6999, 16) (8748, 16)\n",
      "Processed feature matrix shapes: (27992, 16) (6999, 16) (8748, 16)\n",
      "Loaded tuned params from lgbm_tuning_summary.json\n",
      "Using LightGBM params: {'num_leaves': 31, 'learning_rate': 0.02, 'n_estimators': 400, 'max_depth': 16, 'min_child_samples': 5, 'subsample': 0.7, 'colsample_bytree': 0.7}\n",
      "Falling back to callbacks-based early stopping due to: LGBMRegressor.fit() got an unexpected keyword argument 'early_stopping_rounds'\n",
      "Callbacks-based early stopping failed too ( 'LGBMRegressor' object has no attribute 'early_stopping' ). Falling back to fit without early stopping.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LGBMRegressor.fit() got an unexpected keyword argument 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 160\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# many LightGBM versions accept early_stopping_rounds directly\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m     lgb\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    161\u001b[0m         X_train_proc,\n\u001b[0;32m    162\u001b[0m         y_train,\n\u001b[0;32m    163\u001b[0m         eval_set\u001b[38;5;241m=\u001b[39m[(X_val_proc, y_val)],\n\u001b[0;32m    164\u001b[0m         early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m    165\u001b[0m         eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    166\u001b[0m         categorical_feature\u001b[38;5;241m=\u001b[39mcat_feature_list,\n\u001b[0;32m    167\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\n\u001b[0;32m    168\u001b[0m     )\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# fallback: use callbacks API (works for versions where early_stopping_rounds not accepted)\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: LGBMRegressor.fit() got an unexpected keyword argument 'early_stopping_rounds'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 179\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalling back to callbacks-based early stopping due to:\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m    173\u001b[0m     lgb\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    174\u001b[0m         X_train_proc,\n\u001b[0;32m    175\u001b[0m         y_train,\n\u001b[0;32m    176\u001b[0m         eval_set\u001b[38;5;241m=\u001b[39m[(X_val_proc, y_val)],\n\u001b[0;32m    177\u001b[0m         eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    178\u001b[0m         categorical_feature\u001b[38;5;241m=\u001b[39mcat_feature_list,\n\u001b[1;32m--> 179\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m[lgb\u001b[38;5;241m.\u001b[39mearly_stopping(stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m), lgb\u001b[38;5;241m.\u001b[39mlog_evaluation(\u001b[38;5;241m50\u001b[39m)]\n\u001b[0;32m    180\u001b[0m     )\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e2:\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;66;03m# Last-resort: fit without early stopping\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LGBMRegressor' object has no attribute 'early_stopping'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 184\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e2:\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;66;03m# Last-resort: fit without early stopping\u001b[39;00m\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCallbacks-based early stopping failed too (\u001b[39m\u001b[38;5;124m\"\u001b[39m, e2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m). Falling back to fit without early stopping.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 184\u001b[0m         lgb\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    185\u001b[0m             X_train_proc,\n\u001b[0;32m    186\u001b[0m             y_train,\n\u001b[0;32m    187\u001b[0m             eval_set\u001b[38;5;241m=\u001b[39m[(X_val_proc, y_val)],\n\u001b[0;32m    188\u001b[0m             eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    189\u001b[0m             categorical_feature\u001b[38;5;241m=\u001b[39mcat_feature_list,\n\u001b[0;32m    190\u001b[0m             verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\n\u001b[0;32m    191\u001b[0m         )\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# ---------- Evaluate on test set ----------\u001b[39;00m\n\u001b[0;32m    194\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mpredict(X_test_proc)\n",
      "\u001b[1;31mTypeError\u001b[0m: LGBMRegressor.fit() got an unexpected keyword argument 'verbose'"
     ]
    }
   ],
   "source": [
    "# Train LightGBM using native categorical features (no OHE) + MLflow logging\n",
    "#EDITING THE SNIPPET THAT IS GIVING US ERROR, REST REMAINS THE SAME. LETS TRY!\n",
    "\n",
    "import os, json, joblib\n",
    "from pathlib import Path\n",
    "from math import sqrt\n",
    "import pandas as pd, numpy as np\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Ensure LightGBM is available\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "except Exception as e:\n",
    "    raise ImportError(\"lightgbm is not installed in this environment. Install it and re-run.\") from e\n",
    "\n",
    "# ---------- Files and MLflow setup ----------\n",
    "CLEAN_IN = 'amazon_delivery_cleaned.csv'\n",
    "if not os.path.exists(CLEAN_IN):\n",
    "    raise FileNotFoundError(f\"{CLEAN_IN} not found in working dir: {os.getcwd()}\")\n",
    "\n",
    "os.makedirs(\"mlruns\", exist_ok=True)\n",
    "mlflow.set_tracking_uri(Path(os.path.abspath(\"mlruns\")).as_uri())\n",
    "EXP_NAME = 'lightgbm_native_cat'\n",
    "mlflow.set_experiment(EXP_NAME)\n",
    "print(\"MLflow experiment:\", EXP_NAME, \"| tracking URI:\", mlflow.get_tracking_uri())\n",
    "\n",
    "# ---------- Load data and define features ----------\n",
    "df = pd.read_csv(CLEAN_IN)\n",
    "print(\"Loaded dataset shape:\", df.shape)\n",
    "\n",
    "# numeric & categorical feature lists (keep same names)\n",
    "num_feats = [c for c in [\n",
    "    'distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed',\n",
    "    'hour_sin','hour_cos','agent_perf_score'\n",
    "] if c in df.columns]\n",
    "\n",
    "cat_feats = [c for c in [\n",
    "    'Weather_imputed','Traffic','Vehicle','Area','Category_grp','part_of_day',\n",
    "    'distance_bucket','Traffic_Weather','Area_PartOfDay','CatTraffic','agent_experience_bucket'\n",
    "] if c in df.columns]\n",
    "\n",
    "print(\"Numeric features:\", num_feats)\n",
    "print(\"Categorical features (native):\", cat_feats)\n",
    "\n",
    "# ---------- Prepare modelling DataFrame ----------\n",
    "df_model = df.dropna(subset=['Delivery_Time']).copy()\n",
    "X = df_model[num_feats + cat_feats].copy()\n",
    "y = df_model['Delivery_Time'].copy()\n",
    "\n",
    "# convert categorical columns to pandas 'category' dtype\n",
    "for c in cat_feats:\n",
    "    if c in X.columns:\n",
    "        X[c] = X[c].astype('category')\n",
    "\n",
    "# split train/test (same random_state as before)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# further split train into train/val for early stopping\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.20, random_state=42)\n",
    "\n",
    "print(\"Train/Val/Test shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "# ---------- Numeric preprocessing: impute + scale (fit on train only) ----------\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "if len(num_feats) > 0:\n",
    "    X_train_num = pd.DataFrame(num_imputer.fit_transform(X_train[num_feats]), columns=num_feats, index=X_train.index)\n",
    "    X_train_num = pd.DataFrame(scaler.fit_transform(X_train_num), columns=num_feats, index=X_train.index)\n",
    "\n",
    "    X_val_num = pd.DataFrame(scaler.transform(pd.DataFrame(num_imputer.transform(X_val[num_feats]), columns=num_feats, index=X_val.index)),\n",
    "                             columns=num_feats, index=X_val.index)\n",
    "    X_test_num = pd.DataFrame(scaler.transform(pd.DataFrame(num_imputer.transform(X_test[num_feats]), columns=num_feats, index=X_test.index)),\n",
    "                              columns=num_feats, index=X_test.index)\n",
    "else:\n",
    "    X_train_num = pd.DataFrame(index=X_train.index)\n",
    "    X_val_num = pd.DataFrame(index=X_val.index)\n",
    "    X_test_num = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "# keep categorical columns as-is (category dtype)\n",
    "X_train_cat = X_train[cat_feats].copy()\n",
    "X_val_cat = X_val[cat_feats].copy()\n",
    "X_test_cat = X_test[cat_feats].copy()\n",
    "\n",
    "# Reconstruct final DataFrames (concatenate numeric scaled + categorical)\n",
    "X_train_proc = pd.concat([X_train_num.reset_index(drop=True), X_train_cat.reset_index(drop=True)], axis=1)\n",
    "X_val_proc = pd.concat([X_val_num.reset_index(drop=True), X_val_cat.reset_index(drop=True)], axis=1)\n",
    "X_test_proc = pd.concat([X_test_num.reset_index(drop=True), X_test_cat.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Ensure categorical dtypes preserved in final DataFrames\n",
    "for c in cat_feats:\n",
    "    if c in X_train_proc.columns:\n",
    "        X_train_proc[c] = X_train_proc[c].astype('category')\n",
    "        X_val_proc[c] = X_val_proc[c].astype('category')\n",
    "        X_test_proc[c] = X_test_proc[c].astype('category')\n",
    "\n",
    "print(\"Processed feature matrix shapes:\", X_train_proc.shape, X_val_proc.shape, X_test_proc.shape)\n",
    "\n",
    "# ---------- Load tuned params if available (from previous tuning) ----------\n",
    "tuned_params_file = 'lgbm_tuning_summary.json'\n",
    "default_params = {\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.02,\n",
    "    'n_estimators': 400,\n",
    "    'max_depth': 16,\n",
    "    'min_child_samples': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'reg_alpha': 0.0,\n",
    "    'reg_lambda': 0.0,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "if os.path.exists(tuned_params_file):\n",
    "    try:\n",
    "        with open(tuned_params_file, 'r') as f:\n",
    "            summary = json.load(f)\n",
    "        # best_params in file were saved as strings earlier  try to read lgbm_tuning_summary.json if consistent\n",
    "        if 'best_params' in summary:\n",
    "            # if structure is same as earlier cell\n",
    "            bp = summary['best_params']\n",
    "            # convert strings back to numeric where possible\n",
    "            for k, v in bp.items():\n",
    "                try:\n",
    "                    # remove regressor__ prefix if present\n",
    "                    kk = k.replace('regressor__', '')\n",
    "                    default_params[kk] = float(v) if (str(v).replace('.','',1).isdigit()) else v\n",
    "                except Exception:\n",
    "                    default_params[kk] = v\n",
    "            print(\"Loaded tuned params from\", tuned_params_file)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# finalize params (ensure ints where necessary)\n",
    "params = default_params.copy()\n",
    "params['num_leaves'] = int(params.get('num_leaves', 31))\n",
    "params['n_estimators'] = int(params.get('n_estimators', 400))\n",
    "params['max_depth'] = int(params.get('max_depth', 16))\n",
    "params['min_child_samples'] = int(params.get('min_child_samples', 5))\n",
    "\n",
    "print(\"Using LightGBM params:\", {k: params[k] for k in ['num_leaves','learning_rate','n_estimators','max_depth','min_child_samples','subsample','colsample_bytree']})\n",
    "\n",
    "# ---------- Train LGBM with categorical features specified ----------\n",
    "lgb = LGBMRegressor(**params)\n",
    "\n",
    "# Fit with early stopping using validation set. Pass categorical_feature as list of names.\n",
    "# LightGBM accepts categorical_feature names when given a pandas DataFrame\n",
    "# Robust LightGBM fit with early stopping  works across LightGBM versions\n",
    "cat_feature_list = [c for c in cat_feats if c in X_train_proc.columns]\n",
    "\n",
    "# Try the standard sklearn-style fit first; if it fails, use callbacks.\n",
    "try:\n",
    "    # many LightGBM versions accept early_stopping_rounds directly\n",
    "    lgb.fit(\n",
    "        X_train_proc,\n",
    "        y_train,\n",
    "        eval_set=[(X_val_proc, y_val)],\n",
    "        early_stopping_rounds=50,\n",
    "        eval_metric='rmse',\n",
    "        categorical_feature=cat_feature_list,\n",
    "        verbose=50\n",
    "    )\n",
    "except TypeError as e:\n",
    "    # fallback: use callbacks API (works for versions where early_stopping_rounds not accepted)\n",
    "    try:\n",
    "        print(\"Falling back to callbacks-based early stopping due to:\", e)\n",
    "        lgb.fit(\n",
    "            X_train_proc,\n",
    "            y_train,\n",
    "            eval_set=[(X_val_proc, y_val)],\n",
    "            eval_metric='rmse',\n",
    "            categorical_feature=cat_feature_list,\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(50)]\n",
    "        )\n",
    "    except Exception as e2:\n",
    "        # Last-resort: fit without early stopping\n",
    "        print(\"Callbacks-based early stopping failed too (\", e2, \"). Falling back to fit without early stopping.\")\n",
    "        lgb.fit(\n",
    "            X_train_proc,\n",
    "            y_train,\n",
    "            eval_set=[(X_val_proc, y_val)],\n",
    "            eval_metric='rmse',\n",
    "            categorical_feature=cat_feature_list,\n",
    "            verbose=50\n",
    "        )\n",
    "\n",
    "# ---------- Evaluate on test set ----------\n",
    "y_pred = lgb.predict(X_test_proc)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Native-cat LightGBM test metrics -> MAE={mae:.3f}, RMSE={rmse:.3f}, R2={r2:.4f}\")\n",
    "\n",
    "# ---------- Save artifacts & log to MLflow ----------\n",
    "model_file = 'lgbm_native_cat_model.joblib'\n",
    "joblib.dump(lgb, model_file)\n",
    "\n",
    "# feature importances\n",
    "feature_names = list(X_train_proc.columns)\n",
    "importances = lgb.feature_importances_\n",
    "# align lengths (should match)\n",
    "if len(importances) != len(feature_names):\n",
    "    minlen = min(len(importances), len(feature_names))\n",
    "    feature_names = feature_names[:minlen]\n",
    "    importances = importances[:minlen]\n",
    "fi_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "fi_df = fi_df.sort_values('importance', ascending=False)\n",
    "fi_csv = 'lgbm_native_cat_feature_importance.csv'\n",
    "fi_df.to_csv(fi_csv, index=False)\n",
    "\n",
    "# pred vs actual plot\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(y_test, y_pred, s=8, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Delivery_Time (mins)'); plt.ylabel('Predicted Delivery_Time (mins)')\n",
    "plt.title('LGBM (native categorical) Predicted vs Actual')\n",
    "pfile = 'lgbm_native_cat_pred_vs_actual.png'\n",
    "plt.tight_layout(); plt.savefig(pfile); plt.close()\n",
    "\n",
    "summary = {\n",
    "    'model_file': model_file,\n",
    "    'test_mae': float(mae),\n",
    "    'test_rmse': float(rmse),\n",
    "    'test_r2': float(r2),\n",
    "    'params': params\n",
    "}\n",
    "with open('lgbm_native_cat_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# MLflow logging\n",
    "with mlflow.start_run(run_name='lgbm_native_cat'):\n",
    "    mlflow.log_params({k: params[k] for k in ['num_leaves','learning_rate','n_estimators','max_depth','min_child_samples','subsample','colsample_bytree']})\n",
    "    mlflow.log_metric('test_mae', float(mae))\n",
    "    mlflow.log_metric('test_rmse', float(rmse))\n",
    "    mlflow.log_metric('test_r2', float(r2))\n",
    "    mlflow.log_artifact(model_file)\n",
    "    mlflow.log_artifact(fi_csv)\n",
    "    mlflow.log_artifact(pfile)\n",
    "    mlflow.log_artifact('lgbm_native_cat_summary.json')\n",
    "\n",
    "print(\"\\nSaved artifacts:\")\n",
    "print(\" -\", model_file)\n",
    "print(\" -\", fi_csv)\n",
    "print(\" -\", pfile)\n",
    "print(\" - lgbm_native_cat_summary.json\")\n",
    "print(\"\\nDone. You can open MLflow UI (mlflow ui) to compare this run with previous experiments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a182a29-e741-4ca6-bbe7-d4e17c067d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow experiment: lightgbm_native_cat | tracking URI: file:///C:/Users/shail_u9zs758/mlruns\n",
      "Loaded dataset shape: (43739, 35)\n",
      "Numeric features: ['distance_km', 'order_to_pickup_mins', 'Agent_Age', 'Agent_Rating_imputed', 'hour_sin', 'hour_cos']\n",
      "Categorical features (native): ['Weather_imputed', 'Traffic', 'Vehicle', 'Area', 'Category_grp', 'part_of_day', 'distance_bucket', 'Traffic_Weather', 'Area_PartOfDay', 'CatTraffic']\n",
      "Train/Val/Test shapes: (27992, 16) (6999, 16) (8748, 16)\n",
      "Processed feature matrix shapes: (27992, 16) (6999, 16) (8748, 16)\n",
      "Loaded tuned params from lgbm_tuning_summary.json\n",
      "Using LightGBM core params: {'num_leaves': 31, 'learning_rate': 0.02, 'max_depth': 16, 'min_child_samples': 5, 'subsample': 0.7, 'colsample_bytree': 0.7}\n",
      "Categorical features passed to LightGBM core API: ['Weather_imputed', 'Traffic', 'Vehicle', 'Area', 'Category_grp', 'part_of_day', 'distance_bucket', 'Traffic_Weather', 'Area_PartOfDay', 'CatTraffic']\n",
      "Starting training (lightgbm core)... this may print periodic eval messages.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'early_stopping_rounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 166\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# ------------------ train with early stopping (core API) ------------------\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training (lightgbm core)... this may print periodic eval messages.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 166\u001b[0m bst \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m    167\u001b[0m     params\u001b[38;5;241m=\u001b[39mtrain_params,\n\u001b[0;32m    168\u001b[0m     train_set\u001b[38;5;241m=\u001b[39mdtrain,\n\u001b[0;32m    169\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39mnum_boost_round,\n\u001b[0;32m    170\u001b[0m     valid_sets\u001b[38;5;241m=\u001b[39m[dtrain, dval],\n\u001b[0;32m    171\u001b[0m     valid_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    172\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m    173\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\n\u001b[0;32m    174\u001b[0m )\n\u001b[0;32m    176\u001b[0m best_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(bst\u001b[38;5;241m.\u001b[39mbest_iteration) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(bst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_iteration\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m bst\u001b[38;5;241m.\u001b[39mbest_iteration \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_boost_round\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining finished. best_iteration:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_iter)\n",
      "\u001b[1;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'early_stopping_rounds'"
     ]
    }
   ],
   "source": [
    "# Robust single-cell: Train LightGBM with native categorical features (core API) + MLflow logging\n",
    "# Replaces older lgb.fit usage and avoids early_stopping/callback issues across LightGBM versions.\n",
    "# Run this in the same working directory where amazon_delivery_cleaned.csv and mlruns exist.\n",
    "\n",
    "import os, json, joblib\n",
    "from pathlib import Path\n",
    "from math import sqrt\n",
    "import pandas as pd, numpy as np\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ------------------ ensure LightGBM is available ------------------\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    from lightgbm import LGBMRegressor  # optional, just to check import\n",
    "except Exception as e:\n",
    "    raise ImportError(\"lightgbm is not installed in this environment. Install it (pip install lightgbm) and re-run.\") from e\n",
    "\n",
    "# ------------------ file & mlflow setup ------------------\n",
    "CLEAN_IN = 'amazon_delivery_cleaned.csv'\n",
    "if not os.path.exists(CLEAN_IN):\n",
    "    raise FileNotFoundError(f\"{CLEAN_IN} not found in working dir: {os.getcwd()}\")\n",
    "\n",
    "# Windows-safe MLflow tracking URI (uses file:///...)\n",
    "os.makedirs(\"mlruns\", exist_ok=True)\n",
    "mlflow.set_tracking_uri(Path(os.path.abspath(\"mlruns\")).as_uri())\n",
    "EXP_NAME = 'lightgbm_native_cat'\n",
    "mlflow.set_experiment(EXP_NAME)\n",
    "print(\"MLflow experiment:\", EXP_NAME, \"| tracking URI:\", mlflow.get_tracking_uri())\n",
    "\n",
    "# ------------------ load dataset & feature lists ------------------\n",
    "df = pd.read_csv(CLEAN_IN)\n",
    "print(\"Loaded dataset shape:\", df.shape)\n",
    "\n",
    "num_feats = [c for c in [\n",
    "    'distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed',\n",
    "    'hour_sin','hour_cos','agent_perf_score'\n",
    "] if c in df.columns]\n",
    "\n",
    "cat_feats = [c for c in [\n",
    "    'Weather_imputed','Traffic','Vehicle','Area','Category_grp','part_of_day',\n",
    "    'distance_bucket','Traffic_Weather','Area_PartOfDay','CatTraffic','agent_experience_bucket'\n",
    "] if c in df.columns]\n",
    "\n",
    "print(\"Numeric features:\", num_feats)\n",
    "print(\"Categorical features (native):\", cat_feats)\n",
    "\n",
    "# ------------------ prepare dataframes ------------------\n",
    "df_model = df.dropna(subset=['Delivery_Time']).copy()\n",
    "X = df_model[num_feats + cat_feats].copy()\n",
    "y = df_model['Delivery_Time'].copy()\n",
    "\n",
    "# convert categorical columns to pandas 'category' dtype\n",
    "for c in cat_feats:\n",
    "    if c in X.columns:\n",
    "        X[c] = X[c].astype('category')\n",
    "\n",
    "# split (train/val/test)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.20, random_state=42)\n",
    "print(\"Train/Val/Test shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "# ------------------ numeric preprocessing (fit on train) ------------------\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "if len(num_feats) > 0:\n",
    "    X_train_num = pd.DataFrame(num_imputer.fit_transform(X_train[num_feats]), columns=num_feats, index=X_train.index)\n",
    "    X_train_num = pd.DataFrame(scaler.fit_transform(X_train_num), columns=num_feats, index=X_train.index)\n",
    "\n",
    "    X_val_num = pd.DataFrame(scaler.transform(pd.DataFrame(num_imputer.transform(X_val[num_feats]), columns=num_feats, index=X_val.index)),\n",
    "                             columns=num_feats, index=X_val.index)\n",
    "    X_test_num = pd.DataFrame(scaler.transform(pd.DataFrame(num_imputer.transform(X_test[num_feats]), columns=num_feats, index=X_test.index)),\n",
    "                              columns=num_feats, index=X_test.index)\n",
    "else:\n",
    "    # empty numeric frame\n",
    "    X_train_num = pd.DataFrame(index=X_train.index)\n",
    "    X_val_num = pd.DataFrame(index=X_val.index)\n",
    "    X_test_num = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "# categorical parts (keep as category dtype)\n",
    "X_train_cat = X_train[cat_feats].reset_index(drop=True).copy()\n",
    "X_val_cat = X_val[cat_feats].reset_index(drop=True).copy()\n",
    "X_test_cat = X_test[cat_feats].reset_index(drop=True).copy()\n",
    "\n",
    "# final processed frames (numeric scaled + categorical columns)\n",
    "X_train_proc = pd.concat([X_train_num.reset_index(drop=True), X_train_cat.reset_index(drop=True)], axis=1)\n",
    "X_val_proc = pd.concat([X_val_num.reset_index(drop=True), X_val_cat.reset_index(drop=True)], axis=1)\n",
    "X_test_proc = pd.concat([X_test_num.reset_index(drop=True), X_test_cat.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# ensure categorical dtype preserved\n",
    "for c in cat_feats:\n",
    "    if c in X_train_proc.columns:\n",
    "        X_train_proc[c] = X_train_proc[c].astype('category')\n",
    "        X_val_proc[c] = X_val_proc[c].astype('category')\n",
    "        X_test_proc[c] = X_test_proc[c].astype('category')\n",
    "\n",
    "print(\"Processed feature matrix shapes:\", X_train_proc.shape, X_val_proc.shape, X_test_proc.shape)\n",
    "\n",
    "# ------------------ load tuned params if available ------------------\n",
    "tuned_params_file = 'lgbm_tuning_summary.json'\n",
    "default_params = {\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.02,\n",
    "    'n_estimators': 400,\n",
    "    'max_depth': 16,\n",
    "    'min_child_samples': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'reg_alpha': 0.0,\n",
    "    'reg_lambda': 0.0,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "params = default_params.copy()\n",
    "if os.path.exists(tuned_params_file):\n",
    "    try:\n",
    "        with open(tuned_params_file, 'r') as f:\n",
    "            summ = json.load(f)\n",
    "        # older file saved best_params as strings under 'best_params'  handle both possibilities\n",
    "        if isinstance(summ, dict) and 'best_params' in summ and isinstance(summ['best_params'], dict):\n",
    "            for k, v in summ['best_params'].items():\n",
    "                kk = k.replace('regressor__', '')\n",
    "                # attempt numeric conversion\n",
    "                try:\n",
    "                    params[kk] = float(v) if (isinstance(v, str) and v.replace('.', '', 1).isdigit()) else v\n",
    "                except Exception:\n",
    "                    params[kk] = v\n",
    "            print(\"Loaded tuned params from\", tuned_params_file)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# coerce types for core API\n",
    "train_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': int(params.get('num_leaves', 31)),\n",
    "    'learning_rate': float(params.get('learning_rate', 0.02)),\n",
    "    'max_depth': int(params.get('max_depth', 16)),\n",
    "    'min_child_samples': int(params.get('min_child_samples', 5)),\n",
    "    'subsample': float(params.get('subsample', 0.7)),\n",
    "    'colsample_bytree': float(params.get('colsample_bytree', 0.7)),\n",
    "    'reg_alpha': float(params.get('reg_alpha', 0.0)),\n",
    "    'reg_lambda': float(params.get('reg_lambda', 0.0)),\n",
    "    'verbosity': -1,\n",
    "    # 'force_row_wise': True  # optional, can enable if desired\n",
    "}\n",
    "\n",
    "num_boost_round = int(params.get('n_estimators', 400))\n",
    "print(\"Using LightGBM core params:\", {k: train_params[k] for k in ['num_leaves','learning_rate','max_depth','min_child_samples','subsample','colsample_bytree']})\n",
    "\n",
    "# ------------------ prepare lightgbm Datasets ------------------\n",
    "cat_feature_list = [c for c in cat_feats if c in X_train_proc.columns]\n",
    "print(\"Categorical features passed to LightGBM core API:\", cat_feature_list)\n",
    "\n",
    "dtrain = lgb.Dataset(X_train_proc, label=y_train.reset_index(drop=True), categorical_feature=cat_feature_list, free_raw_data=False)\n",
    "dval = lgb.Dataset(X_val_proc, label=y_val.reset_index(drop=True), categorical_feature=cat_feature_list, reference=dtrain, free_raw_data=False)\n",
    "\n",
    "# ------------------ train with early stopping (core API) ------------------\n",
    "print(\"Starting training (lightgbm core)... this may print periodic eval messages.\")\n",
    "bst = lgb.train(\n",
    "    params=train_params,\n",
    "    train_set=dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    valid_sets=[dtrain, dval],\n",
    "    valid_names=['train','val'],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=50\n",
    ")\n",
    "\n",
    "best_iter = int(bst.best_iteration) if hasattr(bst, 'best_iteration') and bst.best_iteration is not None else num_boost_round\n",
    "print(\"Training finished. best_iteration:\", best_iter)\n",
    "\n",
    "# ------------------ predict & evaluate ------------------\n",
    "y_pred = bst.predict(X_test_proc, num_iteration=best_iter)\n",
    "mae = mean_absolute_error(y_test.reset_index(drop=True), y_pred)\n",
    "rmse = sqrt(mean_squared_error(y_test.reset_index(drop=True), y_pred))\n",
    "r2 = r2_score(y_test.reset_index(drop=True), y_pred)\n",
    "print(f\"Native-cat LightGBM (core) test metrics -> MAE={mae:.3f}, RMSE={rmse:.3f}, R2={r2:.4f}\")\n",
    "\n",
    "# ------------------ save artifacts ------------------\n",
    "model_txt = 'lgbm_native_cat_model.txt'\n",
    "model_joblib = 'lgbm_native_cat_model_booster.joblib'\n",
    "bst.save_model(model_txt)\n",
    "joblib.dump(bst, model_joblib)\n",
    "print(\"Saved model:\", model_txt, model_joblib)\n",
    "\n",
    "# feature importances (gain)\n",
    "feature_names = list(X_train_proc.columns)\n",
    "importances = bst.feature_importance(importance_type='gain')\n",
    "if len(importances) != len(feature_names):\n",
    "    minlen = min(len(importances), len(feature_names))\n",
    "    feature_names = feature_names[:minlen]\n",
    "    importances = importances[:minlen]\n",
    "fi_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "fi_df = fi_df.sort_values('importance', ascending=False)\n",
    "fi_csv = 'lgbm_native_cat_feature_importance.csv'\n",
    "fi_df.to_csv(fi_csv, index=False)\n",
    "print(\"Saved feature importance to:\", fi_csv)\n",
    "\n",
    "# pred vs actual plot\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(y_test.reset_index(drop=True), y_pred, s=8, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Delivery_Time (mins)'); plt.ylabel('Predicted Delivery_Time (mins)')\n",
    "plt.title('LGBM (native categorical, core API) Predicted vs Actual')\n",
    "pfile = 'lgbm_native_cat_pred_vs_actual.png'\n",
    "plt.tight_layout(); plt.savefig(pfile); plt.close()\n",
    "print(\"Saved pred vs actual plot:\", pfile)\n",
    "\n",
    "# summary JSON\n",
    "summary = {\n",
    "    'model_txt': model_txt,\n",
    "    'model_joblib': model_joblib,\n",
    "    'test_mae': float(mae),\n",
    "    'test_rmse': float(rmse),\n",
    "    'test_r2': float(r2),\n",
    "    'best_iteration': best_iter,\n",
    "    'params': train_params\n",
    "}\n",
    "with open('lgbm_native_cat_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(\"Saved summary json: lgbm_native_cat_summary.json\")\n",
    "\n",
    "# ------------------ MLflow logging (single run) ------------------\n",
    "with mlflow.start_run(run_name='lgbm_native_cat_core'):\n",
    "    # log params (select subset)\n",
    "    mlflow.log_params({k: train_params[k] for k in ['num_leaves','learning_rate','max_depth','min_child_samples','subsample','colsample_bytree']})\n",
    "    mlflow.log_metric('test_mae', float(mae))\n",
    "    mlflow.log_metric('test_rmse', float(rmse))\n",
    "    mlflow.log_metric('test_r2', float(r2))\n",
    "    mlflow.log_param('best_iteration', best_iter)\n",
    "    # artifacts\n",
    "    mlflow.log_artifact(model_txt)\n",
    "    mlflow.log_artifact(model_joblib)\n",
    "    mlflow.log_artifact(fi_csv)\n",
    "    mlflow.log_artifact(pfile)\n",
    "    mlflow.log_artifact('lgbm_native_cat_summary.json')\n",
    "\n",
    "print(\"\\nLogged metrics & artifacts to MLflow. Done.\")\n",
    "print(\"You can now inspect 'lgbm_native_cat_summary.json' and 'lgbm_native_cat_feature_importance.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bcc718c-2846-4db0-8cfb-f35739b35095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training (lightgbm core) with robust compatibility...\n",
      "early_stopping_rounds not accepted (TypeError): train() got an unexpected keyword argument 'early_stopping_rounds'\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 38.298\tval's rmse: 39.0589\n",
      "[100]\ttrain's rmse: 34.8003\tval's rmse: 35.6435\n",
      "[150]\ttrain's rmse: 33.707\tval's rmse: 34.7866\n",
      "[200]\ttrain's rmse: 33.1875\tval's rmse: 34.5297\n",
      "[250]\ttrain's rmse: 32.8692\tval's rmse: 34.4639\n",
      "[300]\ttrain's rmse: 32.6115\tval's rmse: 34.4488\n",
      "[350]\ttrain's rmse: 32.4085\tval's rmse: 34.4418\n",
      "Early stopping, best iteration is:\n",
      "[348]\ttrain's rmse: 32.4163\tval's rmse: 34.4409\n",
      "Training finished using callbacks API.\n",
      "Best iteration selected: 348\n",
      "Native-cat LightGBM (core) test metrics -> MAE=23.675, RMSE=33.783, R2=0.5716\n",
      "Saved model files: lgbm_native_cat_model.txt lgbm_native_cat_model_booster.joblib\n",
      "Saved feature importance to: lgbm_native_cat_feature_importance.csv\n",
      "Saved pred vs actual plot: lgbm_native_cat_pred_vs_actual.png\n",
      "Saved summary json: lgbm_native_cat_summary.json\n",
      "Logged metrics & artifacts to MLflow. Done.\n"
     ]
    }
   ],
   "source": [
    "# ---------- Robust training block for LightGBM core (tries multiple early-stopping APIs) ----------\n",
    "print(\"Starting training (lightgbm core) with robust compatibility...\")\n",
    "\n",
    "bst = None\n",
    "try:\n",
    "    # 1) Try the common signature with early_stopping_rounds (works on many versions)\n",
    "    bst = lgb.train(\n",
    "        params=train_params,\n",
    "        train_set=dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        valid_sets=[dtrain, dval],\n",
    "        valid_names=['train','val'],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=50\n",
    "    )\n",
    "    print(\"Training finished using early_stopping_rounds parameter.\")\n",
    "except TypeError as e1:\n",
    "    print(\"early_stopping_rounds not accepted (TypeError):\", e1)\n",
    "    # 2) Try callbacks API if available\n",
    "    try:\n",
    "        callbacks = []\n",
    "        if hasattr(lgb, 'early_stopping'):\n",
    "            callbacks.append(lgb.early_stopping(stopping_rounds=50))\n",
    "        if hasattr(lgb, 'log_evaluation'):\n",
    "            callbacks.append(lgb.log_evaluation(period=50))\n",
    "        if callbacks:\n",
    "            bst = lgb.train(\n",
    "                params=train_params,\n",
    "                train_set=dtrain,\n",
    "                num_boost_round=num_boost_round,\n",
    "                valid_sets=[dtrain, dval],\n",
    "                valid_names=['train','val'],\n",
    "                callbacks=callbacks\n",
    "            )\n",
    "            print(\"Training finished using callbacks API.\")\n",
    "        else:\n",
    "            raise RuntimeError(\"No callbacks (early_stopping/log_evaluation) available in this LightGBM.\")\n",
    "    except Exception as e2:\n",
    "        print(\"Callbacks-based training failed or not available:\", e2)\n",
    "        # 3) Last-resort: train without early stopping (quiet if possible)\n",
    "        try:\n",
    "            bst = lgb.train(\n",
    "                params=train_params,\n",
    "                train_set=dtrain,\n",
    "                num_boost_round=num_boost_round,\n",
    "                valid_sets=[dtrain, dval],\n",
    "                valid_names=['train','val'],\n",
    "                verbose_eval=False\n",
    "            )\n",
    "            print(\"Training finished without early stopping (fallback).\")\n",
    "        except TypeError as e3:\n",
    "            # Some very old versions might even dislike verbose_eval kw  call simplest signature\n",
    "            print(\"Fallback with verbose_eval failed:\", e3)\n",
    "            bst = lgb.train(\n",
    "                params=train_params,\n",
    "                train_set=dtrain,\n",
    "                num_boost_round=num_boost_round,\n",
    "                valid_sets=[dtrain, dval],\n",
    "                valid_names=['train','val']\n",
    "            )\n",
    "            print(\"Training finished with minimal call (final fallback).\")\n",
    "\n",
    "# Ensure bst is not None\n",
    "if bst is None:\n",
    "    raise RuntimeError(\"LightGBM training failed in all fallback attempts.\")\n",
    "\n",
    "# Determine best iteration if present\n",
    "best_iter = None\n",
    "try:\n",
    "    if hasattr(bst, 'best_iteration') and bst.best_iteration is not None:\n",
    "        best_iter = int(bst.best_iteration)\n",
    "    elif hasattr(bst, 'best_ntree_limit') and bst.best_ntree_limit is not None:\n",
    "        best_iter = int(bst.best_ntree_limit)\n",
    "    else:\n",
    "        best_iter = num_boost_round\n",
    "except Exception:\n",
    "    best_iter = num_boost_round\n",
    "\n",
    "print(\"Best iteration selected:\", best_iter)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = bst.predict(X_test_proc, num_iteration=best_iter)\n",
    "mae = mean_absolute_error(y_test.reset_index(drop=True), y_pred)\n",
    "rmse = sqrt(mean_squared_error(y_test.reset_index(drop=True), y_pred))\n",
    "r2 = r2_score(y_test.reset_index(drop=True), y_pred)\n",
    "print(f\"Native-cat LightGBM (core) test metrics -> MAE={mae:.3f}, RMSE={rmse:.3f}, R2={r2:.4f}\")\n",
    "\n",
    "# Save model artifacts\n",
    "model_txt = 'lgbm_native_cat_model.txt'\n",
    "model_joblib = 'lgbm_native_cat_model_booster.joblib'\n",
    "try:\n",
    "    bst.save_model(model_txt)\n",
    "except Exception as e:\n",
    "    print(\"bst.save_model failed:\", e)\n",
    "joblib.dump(bst, model_joblib)\n",
    "print(\"Saved model files:\", model_txt, model_joblib)\n",
    "\n",
    "# Feature importance (gain if available; fallback to split)\n",
    "try:\n",
    "    importances = bst.feature_importance(importance_type='gain')\n",
    "except Exception:\n",
    "    try:\n",
    "        importances = bst.feature_importance(importance_type='split')\n",
    "    except Exception:\n",
    "        importances = bst.feature_importance()\n",
    "\n",
    "feature_names = list(X_train_proc.columns)\n",
    "if len(importances) != len(feature_names):\n",
    "    minlen = min(len(importances), len(feature_names))\n",
    "    feature_names = feature_names[:minlen]\n",
    "    importances = importances[:minlen]\n",
    "fi_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "fi_df = fi_df.sort_values('importance', ascending=False)\n",
    "fi_csv = 'lgbm_native_cat_feature_importance.csv'\n",
    "fi_df.to_csv(fi_csv, index=False)\n",
    "print(\"Saved feature importance to:\", fi_csv)\n",
    "\n",
    "# Pred vs actual plot\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(y_test.reset_index(drop=True), y_pred, s=8, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Delivery_Time (mins)'); plt.ylabel('Predicted Delivery_Time (mins)')\n",
    "plt.title('LGBM (native categorical, core API) Predicted vs Actual')\n",
    "pfile = 'lgbm_native_cat_pred_vs_actual.png'\n",
    "plt.tight_layout(); plt.savefig(pfile); plt.close()\n",
    "print(\"Saved pred vs actual plot:\", pfile)\n",
    "\n",
    "# Summary JSON\n",
    "summary = {\n",
    "    'model_txt': model_txt,\n",
    "    'model_joblib': model_joblib,\n",
    "    'test_mae': float(mae),\n",
    "    'test_rmse': float(rmse),\n",
    "    'test_r2': float(r2),\n",
    "    'best_iteration': int(best_iter),\n",
    "    'params': train_params\n",
    "}\n",
    "with open('lgbm_native_cat_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(\"Saved summary json: lgbm_native_cat_summary.json\")\n",
    "\n",
    "# MLflow logging (single run)\n",
    "with mlflow.start_run(run_name='lgbm_native_cat_core'):\n",
    "    mlflow.log_params({k: train_params[k] for k in ['num_leaves','learning_rate','max_depth','min_child_samples','subsample','colsample_bytree']})\n",
    "    mlflow.log_metric('test_mae', float(mae))\n",
    "    mlflow.log_metric('test_rmse', float(rmse))\n",
    "    mlflow.log_metric('test_r2', float(r2))\n",
    "    mlflow.log_param('best_iteration', best_iter)\n",
    "    for artifact in [model_txt, model_joblib, fi_csv, pfile, 'lgbm_native_cat_summary.json']:\n",
    "        if os.path.exists(artifact):\n",
    "            mlflow.log_artifact(artifact)\n",
    "\n",
    "print(\"Logged metrics & artifacts to MLflow. Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4fed9b-19f6-4765-8d8f-c06d54d3a734",
   "metadata": {},
   "source": [
    "## LightGBM (native categorical)  Final Training Run\n",
    "\n",
    "**Training details**\n",
    "- Trained with LightGBM core API (native categorical features; early stopping).\n",
    "- Best iteration: **348**.\n",
    "\n",
    "**Test performance**\n",
    "- **MAE** = **23.675** minutes  \n",
    "- **RMSE** = **33.783** minutes  \n",
    "- **R** = **0.5716**\n",
    "\n",
    "**Artifacts**\n",
    "- `lgbm_native_cat_model.txt`  \n",
    "- `lgbm_native_cat_model_booster.joblib`  \n",
    "- `lgbm_native_cat_feature_importance.csv`  \n",
    "- `lgbm_native_cat_pred_vs_actual.png`  \n",
    "- `lgbm_native_cat_summary.json`  \n",
    "\n",
    "**Comparison (selected models)**\n",
    "- Baseline Lasso: MAE  26.20, RMSE  33.27, R  0.585  \n",
    "- LightGBM (untuned, OHE): MAE  24.03, RMSE  34.21, R  0.561  \n",
    "- LightGBM (tuned, OHE): MAE = 23.73, RMSE = 33.76, R = 0.572  \n",
    "- RandomForest (post-FE): MAE  24.98, RMSE  35.46, R  0.528  \n",
    "- **LightGBM (native categorical)**: **MAE = 23.675**, RMSE = 33.783, R = 0.5716"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd0aa218-2efa-47e5-9244-e6836f7d506f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared X_test_proc shape: (8748, 16)\n",
      "Computing SHAP values (this may take some time)...\n",
      "SHAP array shape: (8748, 16)\n",
      "Saved top20 SHAP to: shap_native_outputs\\shap_native_top20.csv\n",
      "Saved SHAP summary plot to: shap_native_outputs\\shap_native_summary.png\n",
      "Saved dependence plot for Agent_Age -> shap_native_outputs\\shap_native_dependence_Agent_Age.png\n",
      "Saved dependence plot for Traffic_Weather -> shap_native_outputs\\shap_native_dependence_Traffic_Weather.png\n",
      "Saved dependence plot for Agent_Rating_imputed -> shap_native_outputs\\shap_native_dependence_Agent_Rating_imputed.png\n",
      "Saved sample SHAP CSV to: shap_native_outputs\\shap_native_sample_values.csv\n",
      "Saved compressed SHAP array to: shap_native_outputs\\shap_native_full.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/26 20:51:51 INFO mlflow.tracking.fluent: Experiment with name 'explainability_native' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SHAP run complete. Artifacts in: shap_native_outputs\n",
      "Top 20 features:\n",
      "                  feature  mean_abs_shap\n",
      "0              Agent_Age      13.011072\n",
      "1        Traffic_Weather      12.420306\n",
      "2   Agent_Rating_imputed      10.448820\n",
      "3            distance_km       9.822288\n",
      "4                Vehicle       5.470500\n",
      "5             CatTraffic       4.773344\n",
      "6        Weather_imputed       3.310262\n",
      "7           Category_grp       1.712909\n",
      "8         Area_PartOfDay       1.633117\n",
      "9                Traffic       1.442774\n",
      "10       distance_bucket       1.319787\n",
      "11                  Area       0.594170\n",
      "12              hour_sin       0.331499\n",
      "13  order_to_pickup_mins       0.238520\n",
      "14              hour_cos       0.216551\n",
      "15           part_of_day       0.022093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SHAP for native-categorical LightGBM booster\n",
    "\n",
    "import os, sys, subprocess, joblib, json\n",
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# install shap if missing\n",
    "try:\n",
    "    import shap\n",
    "except Exception:\n",
    "    print(\"Installing shap into current kernel...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"shap\"])\n",
    "    import shap\n",
    "\n",
    "# load mlflow\n",
    "import mlflow\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# check files\n",
    "CLEAN_IN = 'amazon_delivery_cleaned.csv'\n",
    "BOOSTER_JOBLIB = 'lgbm_native_cat_model_booster.joblib'\n",
    "OUT_DIR = 'shap_native_outputs'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(CLEAN_IN):\n",
    "    raise FileNotFoundError(f\"{CLEAN_IN} not found\")\n",
    "\n",
    "if not os.path.exists(BOOSTER_JOBLIB):\n",
    "    raise FileNotFoundError(f\"{BOOSTER_JOBLIB} not found  run native LGBM training first.\")\n",
    "\n",
    "# load dataset and reconstruct preprocessing (same as training cell)\n",
    "df = pd.read_csv(CLEAN_IN)\n",
    "num_feats = [c for c in [\n",
    "    'distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed',\n",
    "    'hour_sin','hour_cos','agent_perf_score'\n",
    "] if c in df.columns]\n",
    "\n",
    "cat_feats = [c for c in [\n",
    "    'Weather_imputed','Traffic','Vehicle','Area','Category_grp','part_of_day',\n",
    "    'distance_bucket','Traffic_Weather','Area_PartOfDay','CatTraffic','agent_experience_bucket'\n",
    "] if c in df.columns]\n",
    "\n",
    "df_model = df.dropna(subset=['Delivery_Time']).copy()\n",
    "X = df_model[num_feats + cat_feats].copy()\n",
    "y = df_model['Delivery_Time'].copy()\n",
    "\n",
    "# convert categorical columns to pandas 'category' dtype\n",
    "for c in cat_feats:\n",
    "    if c in X.columns:\n",
    "        X[c] = X[c].astype('category')\n",
    "\n",
    "# same splits used during training\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.20, random_state=42)\n",
    "\n",
    "# numeric preprocessing fit on train\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "if len(num_feats) > 0:\n",
    "    X_train_num = pd.DataFrame(num_imputer.fit_transform(X_train[num_feats]), columns=num_feats, index=X_train.index)\n",
    "    X_train_num = pd.DataFrame(scaler.fit_transform(X_train_num), columns=num_feats, index=X_train.index)\n",
    "    X_test_num = pd.DataFrame(scaler.transform(pd.DataFrame(num_imputer.transform(X_test[num_feats]), columns=num_feats, index=X_test.index)), columns=num_feats, index=X_test.index)\n",
    "else:\n",
    "    X_train_num = pd.DataFrame(index=X_train.index)\n",
    "    X_test_num = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "X_test_cat = X_test[cat_feats].reset_index(drop=True).copy()\n",
    "X_test_proc = pd.concat([X_test_num.reset_index(drop=True), X_test_cat.reset_index(drop=True)], axis=1)\n",
    "for c in cat_feats:\n",
    "    if c in X_test_proc.columns:\n",
    "        X_test_proc[c] = X_test_proc[c].astype('category')\n",
    "\n",
    "print(\"Prepared X_test_proc shape:\", X_test_proc.shape)\n",
    "\n",
    "# load booster\n",
    "bst = joblib.load(BOOSTER_JOBLIB)\n",
    "# shap TreeExplainer\n",
    "explainer = shap.TreeExplainer(bst)\n",
    "\n",
    "# compute shap values (may take a bit)\n",
    "print(\"Computing SHAP values (this may take some time)...\")\n",
    "# shap accepts DataFrame; but for older shap versions, convert to numpy if needed\n",
    "try:\n",
    "    shap_vals = explainer.shap_values(X_test_proc)\n",
    "except Exception as e:\n",
    "    # fallback to transformed numpy matrix (convert categorical to codes)\n",
    "    print(\"TreeExplainer failed on DataFrame, converting categories to codes and trying again:\", e)\n",
    "    X_temp = X_test_proc.copy()\n",
    "    for c in cat_feats:\n",
    "        if c in X_temp.columns and str(X_temp[c].dtype).startswith('category'):\n",
    "            X_temp[c] = X_temp[c].cat.codes\n",
    "    shap_vals = explainer.shap_values(X_temp)\n",
    "\n",
    "shap_arr = np.array(shap_vals)\n",
    "if shap_arr.ndim == 3 and shap_arr.shape[0] == 1:\n",
    "    shap_arr = shap_arr[0]\n",
    "print(\"SHAP array shape:\", shap_arr.shape)\n",
    "\n",
    "# feature names (same order as X_test_proc columns)\n",
    "feature_names = list(X_test_proc.columns)\n",
    "\n",
    "# global importance (mean abs)\n",
    "mean_abs = np.abs(shap_arr).mean(axis=0)\n",
    "shap_df = pd.DataFrame({'feature': feature_names, 'mean_abs_shap': mean_abs})\n",
    "shap_df = shap_df.sort_values('mean_abs_shap', ascending=False).reset_index(drop=True)\n",
    "top20 = shap_df.head(20)\n",
    "top20_csv = os.path.join(OUT_DIR, 'shap_native_top20.csv')\n",
    "top20.to_csv(top20_csv, index=False)\n",
    "print(\"Saved top20 SHAP to:\", top20_csv)\n",
    "\n",
    "# summary bar plot\n",
    "plt.figure(figsize=(10,8))\n",
    "# shap.summary_plot with plot_type='bar' supports numpy arrays and feature_names\n",
    "shap.summary_plot(shap_arr, features=X_test_proc, feature_names=feature_names, show=False, plot_type=\"bar\")\n",
    "plt.tight_layout()\n",
    "summary_png = os.path.join(OUT_DIR, 'shap_native_summary.png')\n",
    "plt.savefig(summary_png, dpi=200)\n",
    "plt.close()\n",
    "print(\"Saved SHAP summary plot to:\", summary_png)\n",
    "\n",
    "# dependence plots for top 3\n",
    "top_feats = top20['feature'].tolist()[:3]\n",
    "for feat in top_feats:\n",
    "    try:\n",
    "        idx = feature_names.index(feat)\n",
    "        plt.figure(figsize=(8,6))\n",
    "        shap.dependence_plot(idx, shap_arr, X_test_proc, feature_names=feature_names, show=False)\n",
    "        dep_png = os.path.join(OUT_DIR, f\"shap_native_dependence_{feat.replace(' ','_').replace(':','_')}.png\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dep_png, dpi=200)\n",
    "        plt.close()\n",
    "        print(\"Saved dependence plot for\", feat, \"->\", dep_png)\n",
    "    except Exception as e:\n",
    "        print(\"Could not create dependence plot for\", feat, \":\", e)\n",
    "\n",
    "# save sample shap values (first 200)\n",
    "N = min(200, shap_arr.shape[0])\n",
    "sample_shap = pd.DataFrame(shap_arr[:N, :], columns=feature_names)\n",
    "sample_shap.insert(0, 'row_index', range(N))\n",
    "sample_csv = os.path.join(OUT_DIR, 'shap_native_sample_values.csv')\n",
    "sample_shap.to_csv(sample_csv, index=False)\n",
    "print(\"Saved sample SHAP CSV to:\", sample_csv)\n",
    "\n",
    "# save compressed full shap\n",
    "full_npz = os.path.join(OUT_DIR, 'shap_native_full.npz')\n",
    "np.savez_compressed(full_npz, shap=shap_arr)\n",
    "print(\"Saved compressed SHAP array to:\", full_npz)\n",
    "\n",
    "# log to MLflow (explainability_native)\n",
    "os.makedirs(\"mlruns\", exist_ok=True)\n",
    "mlflow.set_tracking_uri(Path(os.path.abspath(\"mlruns\")).as_uri())\n",
    "mlflow.set_experiment('explainability_native')\n",
    "with mlflow.start_run(run_name='shap_native'):\n",
    "    for f in [summary_png, top20_csv, sample_csv, full_npz]:\n",
    "        if os.path.exists(f):\n",
    "            mlflow.log_artifact(f)\n",
    "    # dependence plots\n",
    "    for feat in top_feats:\n",
    "        dep_png = os.path.join(OUT_DIR, f\"shap_native_dependence_{feat.replace(' ','_').replace(':','_')}.png\")\n",
    "        if os.path.exists(dep_png):\n",
    "            mlflow.log_artifact(dep_png)\n",
    "    # small json summary\n",
    "    expl = {'n_test': int(X_test_proc.shape[0]), 'n_features': int(X_test_proc.shape[1]), 'top20': top20['feature'].tolist()}\n",
    "    with open(os.path.join(OUT_DIR, 'shap_native_summary.json'), 'w') as f:\n",
    "        json.dump(expl, f, indent=2)\n",
    "    mlflow.log_artifact(os.path.join(OUT_DIR, 'shap_native_summary.json'))\n",
    "\n",
    "print(\"\\nSHAP run complete. Artifacts in:\", OUT_DIR)\n",
    "print(\"Top 20 features:\\n\", top20.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a451c06-1f51-4edd-b0f2-e3429a84c32a",
   "metadata": {},
   "source": [
    "## SHAP Explainability  Native-categorical LightGBM\n",
    "\n",
    "**Artifacts**: `shap_native_outputs/shap_native_top20.csv`, `shap_native_summary.png`, `shap_native_dependence_<feat>.png`, `shap_native_sample_values.csv`\n",
    "\n",
    "### Top influential features (mean |SHAP|)\n",
    "1. Agent_Age  \n",
    "2. Traffic_Weather  \n",
    "3. Agent_Rating_imputed  \n",
    "4. distance_km  \n",
    "5. Vehicle  \n",
    "6. CatTraffic  \n",
    "7. Weather_imputed  \n",
    "8. Category_grp  \n",
    "9. Area_PartOfDay  \n",
    "10. Traffic  \n",
    "11. distance_bucket  \n",
    "12. Area  \n",
    "13. hour_sin  \n",
    "14. order_to_pickup_mins  \n",
    "15. hour_cos  \n",
    "16. part_of_day\n",
    "\n",
    "### Key insights\n",
    "- Agent-level signals (age, rating) are the strongest predictors  consider adding agent-history features.  \n",
    "- Traffic  Weather interactions are highly predictive  the engineered interaction is effective.  \n",
    "- Distance and vehicle type remain important as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86ad8edd-d074-40f5-a3da-b15c9f9e3be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/26 21:00:00 INFO mlflow.tracking.fluent: Experiment with name 'lightgbm_optuna_native' does not exist. Creating a new experiment.\n",
      "[I 2025-09-26 21:00:00,677] A new study created in memory with name: no-name-459c250c-6b44-4f45-924f-2d942752101d\n",
      "C:\\Users\\shail_u9zs758\\AppData\\Local\\Temp\\ipykernel_22756\\611970651.py:96: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
      "[W 2025-09-26 21:00:00,719] Trial 0 failed with parameters: {'num_leaves': 106, 'learning_rate': 0.0862735828664018, 'min_child_samples': 75, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.4936111842654619, 'reg_alpha': 0.15599452033620265, 'reg_lambda': 0.05808361216819946, 'max_depth': 22} because of the following error: TypeError(\"train() got an unexpected keyword argument 'early_stopping_rounds'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shail_u9zs758\\AppData\\Roaming\\Python\\Python313\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\shail_u9zs758\\AppData\\Local\\Temp\\ipykernel_22756\\611970651.py\", line 109, in objective\n",
      "    bst = lgb.train(\n",
      "        params=params,\n",
      "    ...<5 lines>...\n",
      "        verbose_eval=False\n",
      "    )\n",
      "TypeError: train() got an unexpected keyword argument 'early_stopping_rounds'\n",
      "[W 2025-09-26 21:00:00,862] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow experiment: lightgbm_optuna_native\n",
      "Starting Optuna study with n_trials = 40\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'early_stopping_rounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 130\u001b[0m\n\u001b[0;32m    128\u001b[0m     study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39mn_trials, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;241m*\u001b[39mtimeout_minutes)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39mn_trials)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# save study & results\u001b[39;00m\n\u001b[0;32m    133\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(study, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUT_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptuna_study.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\optuna\\study\\study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 490\u001b[0m     _optimize(\n\u001b[0;32m    491\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    492\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    493\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    494\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    495\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    496\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    497\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    498\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    499\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    500\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         _optimize_sequential(\n\u001b[0;32m     64\u001b[0m             study,\n\u001b[0;32m     65\u001b[0m             func,\n\u001b[0;32m     66\u001b[0m             n_trials,\n\u001b[0;32m     67\u001b[0m             timeout,\n\u001b[0;32m     68\u001b[0m             catch,\n\u001b[0;32m     69\u001b[0m             callbacks,\n\u001b[0;32m     70\u001b[0m             gc_after_trial,\n\u001b[0;32m     71\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     72\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     73\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     74\u001b[0m         )\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\optuna\\study\\_optimize.py:258\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    254\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    257\u001b[0m ):\n\u001b[1;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\optuna\\study\\_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[22], line 109\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m    106\u001b[0m num_boost_round \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m800\u001b[39m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m bst \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m    110\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    111\u001b[0m     train_set\u001b[38;5;241m=\u001b[39mdtrain,\n\u001b[0;32m    112\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39mnum_boost_round,\n\u001b[0;32m    113\u001b[0m     valid_sets\u001b[38;5;241m=\u001b[39m[dtrain, dval],\n\u001b[0;32m    114\u001b[0m     valid_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    115\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m    116\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    117\u001b[0m )\n\u001b[0;32m    118\u001b[0m best_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(bst\u001b[38;5;241m.\u001b[39mbest_iteration) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(bst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_iteration\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m bst\u001b[38;5;241m.\u001b[39mbest_iteration \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_boost_round\n\u001b[0;32m    119\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m bst\u001b[38;5;241m.\u001b[39mpredict(X_val_proc, num_iteration\u001b[38;5;241m=\u001b[39mbest_iter)\n",
      "\u001b[1;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'early_stopping_rounds'"
     ]
    }
   ],
   "source": [
    "# Optuna hyperparameter tuning for LightGBM (native categorical)\n",
    "\n",
    "import os, sys, subprocess, joblib, json\n",
    "from pathlib import Path\n",
    "from math import sqrt\n",
    "import pandas as pd, numpy as np\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ensure optuna installed\n",
    "try:\n",
    "    import optuna\n",
    "except Exception:\n",
    "    print(\"Installing optuna...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"optuna\"])\n",
    "    import optuna\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ---------- config ----------\n",
    "CLEAN_IN = 'amazon_delivery_cleaned.csv'\n",
    "OUT_DIR = 'optuna_native_outputs'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "n_trials = 40   \n",
    "timeout_minutes = None  \n",
    "\n",
    "# ---------- load data & preprocessing (same as native training) ----------\n",
    "df = pd.read_csv(CLEAN_IN)\n",
    "num_feats = [c for c in [\n",
    "    'distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed',\n",
    "    'hour_sin','hour_cos','agent_perf_score'\n",
    "] if c in df.columns]\n",
    "\n",
    "cat_feats = [c for c in [\n",
    "    'Weather_imputed','Traffic','Vehicle','Area','Category_grp','part_of_day',\n",
    "    'distance_bucket','Traffic_Weather','Area_PartOfDay','CatTraffic','agent_experience_bucket'\n",
    "] if c in df.columns]\n",
    "\n",
    "df_model = df.dropna(subset=['Delivery_Time']).copy()\n",
    "X = df_model[num_feats + cat_feats].copy()\n",
    "y = df_model['Delivery_Time'].copy()\n",
    "\n",
    "for c in cat_feats:\n",
    "    if c in X.columns:\n",
    "        X[c] = X[c].astype('category')\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.20, random_state=42)\n",
    "\n",
    "# numeric preprocess\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "if len(num_feats) > 0:\n",
    "    X_train_num = pd.DataFrame(num_imputer.fit_transform(X_train[num_feats]), columns=num_feats, index=X_train.index)\n",
    "    X_train_num = pd.DataFrame(scaler.fit_transform(X_train_num), columns=num_feats, index=X_train.index)\n",
    "    X_val_num = pd.DataFrame(scaler.transform(pd.DataFrame(num_imputer.transform(X_val[num_feats]), columns=num_feats, index=X_val.index)), columns=num_feats, index=X_val.index)\n",
    "    X_test_num = pd.DataFrame(scaler.transform(pd.DataFrame(num_imputer.transform(X_test[num_feats]), columns=num_feats, index=X_test.index)), columns=num_feats, index=X_test.index)\n",
    "else:\n",
    "    X_train_num = pd.DataFrame(index=X_train.index)\n",
    "    X_val_num = pd.DataFrame(index=X_val.index)\n",
    "    X_test_num = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "X_train_proc = pd.concat([X_train_num.reset_index(drop=True), X_train[cat_feats].reset_index(drop=True)], axis=1)\n",
    "X_val_proc = pd.concat([X_val_num.reset_index(drop=True), X_val[cat_feats].reset_index(drop=True)], axis=1)\n",
    "X_test_proc = pd.concat([X_test_num.reset_index(drop=True), X_test[cat_feats].reset_index(drop=True)], axis=1)\n",
    "\n",
    "for c in cat_feats:\n",
    "    if c in X_train_proc.columns:\n",
    "        X_train_proc[c] = X_train_proc[c].astype('category')\n",
    "        X_val_proc[c] = X_val_proc[c].astype('category')\n",
    "        X_test_proc[c] = X_test_proc[c].astype('category')\n",
    "\n",
    "dtrain = lgb.Dataset(X_train_proc, label=y_train.reset_index(drop=True), categorical_feature=[c for c in cat_feats if c in X_train_proc.columns], free_raw_data=False)\n",
    "dval = lgb.Dataset(X_val_proc, label=y_val.reset_index(drop=True), categorical_feature=[c for c in cat_feats if c in X_train_proc.columns], reference=dtrain, free_raw_data=False)\n",
    "\n",
    "# mlflow experiment\n",
    "os.makedirs(\"mlruns\", exist_ok=True)\n",
    "mlflow.set_tracking_uri(Path(os.path.abspath(\"mlruns\")).as_uri())\n",
    "EXP_NAME = 'lightgbm_optuna_native'\n",
    "mlflow.set_experiment(EXP_NAME)\n",
    "print(\"MLflow experiment:\", EXP_NAME)\n",
    "\n",
    "# objective\n",
    "def objective(trial):\n",
    "    # search space (reasonable ranges)\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 16, 256),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 24),\n",
    "        'verbosity': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    num_boost_round = 800\n",
    "\n",
    "    # train\n",
    "    bst = lgb.train(\n",
    "        params=params,\n",
    "        train_set=dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        valid_sets=[dtrain, dval],\n",
    "        valid_names=['train','val'],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    best_iter = int(bst.best_iteration) if hasattr(bst, 'best_iteration') and bst.best_iteration is not None else num_boost_round\n",
    "    y_pred = bst.predict(X_val_proc, num_iteration=best_iter)\n",
    "    rmse = mean_squared_error(y_val.reset_index(drop=True), y_pred, squared=False) if hasattr(mean_squared_error, '__call__') else np.sqrt(mean_squared_error(y_val.reset_index(drop=True), y_pred))\n",
    "    # objective is validation RMSE\n",
    "    return float(rmse)\n",
    "\n",
    "# create study\n",
    "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "print(\"Starting Optuna study with n_trials =\", n_trials)\n",
    "if timeout_minutes:\n",
    "    study.optimize(objective, n_trials=n_trials, timeout=60*timeout_minutes)\n",
    "else:\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "# save study & results\n",
    "joblib.dump(study, os.path.join(OUT_DIR, 'optuna_study.pkl'))\n",
    "trials_df = study.trials_dataframe()\n",
    "trials_csv = os.path.join(OUT_DIR, 'optuna_trials.csv')\n",
    "trials_df.to_csv(trials_csv, index=False)\n",
    "print(\"Saved Optuna trials to:\", trials_csv)\n",
    "\n",
    "# best params -> retrain on train+val, evaluate on test\n",
    "best = study.best_params\n",
    "best_params = {\n",
    "    'objective':'regression',\n",
    "    'metric':'rmse',\n",
    "    'num_leaves': int(best['num_leaves']),\n",
    "    'learning_rate': float(best['learning_rate']),\n",
    "    'min_child_samples': int(best['min_child_samples']),\n",
    "    'subsample': float(best['subsample']),\n",
    "    'colsample_bytree': float(best['colsample_bytree']),\n",
    "    'reg_alpha': float(best['reg_alpha']),\n",
    "    'reg_lambda': float(best['reg_lambda']),\n",
    "    'max_depth': int(best['max_depth']),\n",
    "    'verbosity': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# retrain on train+val\n",
    "dtrain_full = lgb.Dataset(pd.concat([X_train_proc, X_val_proc], axis=0, ignore_index=True),\n",
    "                          label=pd.concat([y_train.reset_index(drop=True), y_val.reset_index(drop=True)], axis=0, ignore_index=True),\n",
    "                          categorical_feature=[c for c in cat_feats if c in X_train_proc.columns], free_raw_data=False)\n",
    "\n",
    "bst_best = lgb.train(\n",
    "    params=best_params,\n",
    "    train_set=dtrain_full,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[dtrain_full],\n",
    "    valid_names=['train_full'],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=False\n",
    ")\n",
    "best_iter = int(bst_best.best_iteration) if hasattr(bst_best, 'best_iteration') and bst_best.best_iteration is not None else 1000\n",
    "\n",
    "y_pred_test = bst_best.predict(X_test_proc, num_iteration=best_iter)\n",
    "test_mae = mean_absolute_error(y_test.reset_index(drop=True), y_pred_test)\n",
    "test_rmse = mean_squared_error(y_test.reset_index(drop=True), y_pred_test, squared=False) if hasattr(mean_squared_error, '__call__') else np.sqrt(mean_squared_error(y_test.reset_index(drop=True), y_pred_test))\n",
    "test_r2 = r2_score(y_test.reset_index(drop=True), y_pred_test)\n",
    "\n",
    "print(\"Optuna best params:\", best_params)\n",
    "print(f\"Test metrics -> MAE={test_mae:.3f}, RMSE={test_rmse:.3f}, R2={test_r2:.4f}\")\n",
    "\n",
    "# save best model\n",
    "best_model_txt = os.path.join(OUT_DIR, 'lgbm_optuna_best_model.txt')\n",
    "best_model_joblib = os.path.join(OUT_DIR, 'lgbm_optuna_best_model.pkl')\n",
    "bst_best.save_model(best_model_txt)\n",
    "joblib.dump(bst_best, best_model_joblib)\n",
    "\n",
    "# save summary and log to mlflow\n",
    "summary = {'best_params': best_params, 'test_mae': float(test_mae), 'test_rmse': float(test_rmse), 'test_r2': float(test_r2), 'best_iteration': int(best_iter)}\n",
    "with open(os.path.join(OUT_DIR, 'lgbm_optuna_summary.json'), 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# MLflow logging\n",
    "with mlflow.start_run(run_name='lgbm_optuna_native'):\n",
    "    mlflow.log_params({k: best_params[k] for k in ['num_leaves','learning_rate','max_depth','min_child_samples','subsample','colsample_bytree']})\n",
    "    mlflow.log_metric('test_mae', float(test_mae))\n",
    "    mlflow.log_metric('test_rmse', float(test_rmse))\n",
    "    mlflow.log_metric('test_r2', float(test_r2))\n",
    "    mlflow.log_artifact(best_model_txt)\n",
    "    mlflow.log_artifact(best_model_joblib)\n",
    "    mlflow.log_artifact(trials_csv)\n",
    "    mlflow.log_artifact(os.path.join(OUT_DIR, 'lgbm_optuna_summary.json'))\n",
    "\n",
    "print(\"Optuna tuning complete. Artifacts saved to\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19683d78-f5ae-4479-a861-55f0ced1314a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 21:16:46,726] A new study created in memory with name: no-name-e540d336-858c-4111-b5eb-0a78ee796baa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow experiment: lightgbm_optuna_native\n",
      "Starting Optuna study with n_trials = 40\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 32.3511\tval's rmse: 34.9283\n",
      "[100]\ttrain's rmse: 30.7572\tval's rmse: 34.8818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 21:26:23,357] Trial 0 finished with value: 34.80557353020582 and parameters: {'num_leaves': 106, 'learning_rate': 0.0862735828664018, 'min_child_samples': 75, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.4936111842654619, 'reg_alpha': 0.15599452033620265, 'reg_lambda': 0.05808361216819946, 'max_depth': 22}. Best is trial 0 with value: 34.80557353020582.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[64]\ttrain's rmse: 31.7709\tval's rmse: 34.8056\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 33.3163\tval's rmse: 35.0545\n",
      "[100]\ttrain's rmse: 31.8958\tval's rmse: 34.5789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 21:35:28,264] Trial 1 finished with value: 34.571906657672606 and parameters: {'num_leaves': 160, 'learning_rate': 0.04170553216181044, 'min_child_samples': 6, 'subsample': 0.9849549260809971, 'colsample_bytree': 0.899465584480253, 'reg_alpha': 0.21233911067827616, 'reg_lambda': 0.18182496720710062, 'max_depth': 7}. Best is trial 1 with value: 34.571906657672606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\ttrain's rmse: 32.0248\tval's rmse: 34.5719\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 36.1538\tval's rmse: 37.3979\n",
      "[100]\ttrain's rmse: 33.136\tval's rmse: 35.0025\n",
      "[150]\ttrain's rmse: 32.1033\tval's rmse: 34.6096\n",
      "[200]\ttrain's rmse: 31.5421\tval's rmse: 34.594\n",
      "Early stopping, best iteration is:\n",
      "[171]\ttrain's rmse: 31.8334\tval's rmse: 34.5797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 21:49:52,392] Trial 2 finished with value: 34.57973230307072 and parameters: {'num_leaves': 89, 'learning_rate': 0.02408207265453543, 'min_child_samples': 46, 'subsample': 0.645614570099021, 'colsample_bytree': 0.7671117368334277, 'reg_alpha': 0.13949386065204183, 'reg_lambda': 0.29214464853521815, 'max_depth': 11}. Best is trial 1 with value: 34.571906657672606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 33.0369\tval's rmse: 34.8029\n",
      "[100]\ttrain's rmse: 31.9051\tval's rmse: 34.5575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 21:57:21,310] Trial 3 finished with value: 34.548908363658704 and parameters: {'num_leaves': 125, 'learning_rate': 0.05254210669345883, 'min_child_samples': 24, 'subsample': 0.7571172192068059, 'colsample_bytree': 0.7554487413172255, 'reg_alpha': 0.046450412719997725, 'reg_lambda': 0.6075448519014384, 'max_depth': 7}. Best is trial 3 with value: 34.548908363658704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[82]\ttrain's rmse: 32.2077\tval's rmse: 34.5489\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 33.5017\tval's rmse: 34.7325\n",
      "[100]\ttrain's rmse: 32.6214\tval's rmse: 34.5611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 22:00:27,791] Trial 4 finished with value: 34.55213602312847 and parameters: {'num_leaves': 31, 'learning_rate': 0.08580222514877409, 'min_child_samples': 97, 'subsample': 0.9041986740582306, 'colsample_bytree': 0.5827682615040224, 'reg_alpha': 0.09767211400638387, 'reg_lambda': 0.6842330265121569, 'max_depth': 13}. Best is trial 3 with value: 34.548908363658704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[73]\ttrain's rmse: 32.9714\tval's rmse: 34.5521\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 38.2905\tval's rmse: 39.1878\n",
      "[100]\ttrain's rmse: 34.6189\tval's rmse: 35.7672\n",
      "[150]\ttrain's rmse: 33.3986\tval's rmse: 34.8679\n",
      "[200]\ttrain's rmse: 32.7966\tval's rmse: 34.6099\n",
      "[250]\ttrain's rmse: 32.3844\tval's rmse: 34.5233\n",
      "[300]\ttrain's rmse: 32.0764\tval's rmse: 34.5005\n",
      "[350]\ttrain's rmse: 31.8224\tval's rmse: 34.4997\n",
      "Early stopping, best iteration is:\n",
      "[312]\ttrain's rmse: 32.0105\tval's rmse: 34.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 22:10:26,312] Trial 5 finished with value: 34.49395398068081 and parameters: {'num_leaves': 45, 'learning_rate': 0.022039920190846215, 'min_child_samples': 8, 'subsample': 0.954660201039391, 'colsample_bytree': 0.5552679889600102, 'reg_alpha': 0.662522284353982, 'reg_lambda': 0.31171107608941095, 'max_depth': 14}. Best is trial 5 with value: 34.49395398068081.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 42.4204\tval's rmse: 43.3656\n",
      "[100]\ttrain's rmse: 37.5022\tval's rmse: 38.6645\n",
      "[150]\ttrain's rmse: 35.033\tval's rmse: 36.4513\n",
      "[200]\ttrain's rmse: 33.7297\tval's rmse: 35.44\n",
      "[250]\ttrain's rmse: 33.0027\tval's rmse: 35.022\n",
      "[300]\ttrain's rmse: 32.5361\tval's rmse: 34.8472\n",
      "[350]\ttrain's rmse: 32.1739\tval's rmse: 34.7872\n",
      "[400]\ttrain's rmse: 31.8442\tval's rmse: 34.7688\n",
      "Early stopping, best iteration is:\n",
      "[392]\ttrain's rmse: 31.8943\tval's rmse: 34.7674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 22:52:06,179] Trial 6 finished with value: 34.76739138766757 and parameters: {'num_leaves': 147, 'learning_rate': 0.008699037355645861, 'min_child_samples': 98, 'subsample': 0.8875664116805573, 'colsample_bytree': 0.9636993649385135, 'reg_alpha': 0.8948273504276488, 'reg_lambda': 0.5978999788110851, 'max_depth': 23}. Best is trial 5 with value: 34.49395398068081.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 43.8812\tval's rmse: 44.6664\n",
      "[100]\ttrain's rmse: 39.3542\tval's rmse: 40.1645\n",
      "[150]\ttrain's rmse: 36.8334\tval's rmse: 37.6793\n",
      "[200]\ttrain's rmse: 35.3559\tval's rmse: 36.263\n",
      "[250]\ttrain's rmse: 34.4496\tval's rmse: 35.4539\n",
      "[300]\ttrain's rmse: 33.8804\tval's rmse: 35.0061\n",
      "[350]\ttrain's rmse: 33.5109\tval's rmse: 34.766\n",
      "[400]\ttrain's rmse: 33.2301\tval's rmse: 34.6133\n",
      "[450]\ttrain's rmse: 33.0199\tval's rmse: 34.5327\n",
      "[500]\ttrain's rmse: 32.8573\tval's rmse: 34.4988\n",
      "[550]\ttrain's rmse: 32.7159\tval's rmse: 34.4785\n",
      "[600]\ttrain's rmse: 32.5917\tval's rmse: 34.4733\n",
      "[650]\ttrain's rmse: 32.484\tval's rmse: 34.4711\n",
      "[700]\ttrain's rmse: 32.3872\tval's rmse: 34.4659\n",
      "Early stopping, best iteration is:\n",
      "[697]\ttrain's rmse: 32.3927\tval's rmse: 34.4649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 23:14:26,710] Trial 7 finished with value: 34.464917712505624 and parameters: {'num_leaves': 37, 'learning_rate': 0.008993931736681457, 'min_child_samples': 9, 'subsample': 0.6626651653816322, 'colsample_bytree': 0.6332063738136893, 'reg_alpha': 0.2713490317738959, 'reg_lambda': 0.8287375091519293, 'max_depth': 11}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 38.1568\tval's rmse: 39.2751\n",
      "[100]\ttrain's rmse: 34.4749\tval's rmse: 36.0373\n",
      "[150]\ttrain's rmse: 33.1444\tval's rmse: 35.1386\n",
      "[200]\ttrain's rmse: 32.4226\tval's rmse: 34.8516\n",
      "[250]\ttrain's rmse: 31.931\tval's rmse: 34.7605\n",
      "[300]\ttrain's rmse: 31.5497\tval's rmse: 34.7408\n",
      "Early stopping, best iteration is:\n",
      "[291]\ttrain's rmse: 31.607\tval's rmse: 34.7364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 23:35:15,133] Trial 8 finished with value: 34.73639599355721 and parameters: {'num_leaves': 83, 'learning_rate': 0.025411709798607296, 'min_child_samples': 18, 'subsample': 0.9010984903770198, 'colsample_bytree': 0.44473038620786254, 'reg_alpha': 0.9868869366005173, 'reg_lambda': 0.7722447692966574, 'max_depth': 8}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 34.2662\tval's rmse: 35.0219\n",
      "[100]\ttrain's rmse: 33.389\tval's rmse: 34.5329\n",
      "[150]\ttrain's rmse: 33.0947\tval's rmse: 34.5366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-26 23:37:18,020] Trial 9 finished with value: 34.51634028811158 and parameters: {'num_leaves': 17, 'learning_rate': 0.057532041236250865, 'min_child_samples': 72, 'subsample': 0.8645035840204937, 'colsample_bytree': 0.8627622080115674, 'reg_alpha': 0.07404465173409036, 'reg_lambda': 0.3584657285442726, 'max_depth': 6}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[131]\ttrain's rmse: 33.193\tval's rmse: 34.5163\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 46.4572\tval's rmse: 47.4466\n",
      "[100]\ttrain's rmse: 42.4895\tval's rmse: 43.7233\n",
      "[150]\ttrain's rmse: 39.6231\tval's rmse: 41.1001\n",
      "[200]\ttrain's rmse: 37.4654\tval's rmse: 39.1936\n",
      "[250]\ttrain's rmse: 35.8459\tval's rmse: 37.8313\n",
      "[300]\ttrain's rmse: 34.5914\tval's rmse: 36.8431\n",
      "[350]\ttrain's rmse: 33.6797\tval's rmse: 36.1947\n",
      "[400]\ttrain's rmse: 32.9348\tval's rmse: 35.7177\n",
      "[450]\ttrain's rmse: 32.3308\tval's rmse: 35.3878\n",
      "[500]\ttrain's rmse: 31.8728\tval's rmse: 35.1825\n",
      "[550]\ttrain's rmse: 31.4812\tval's rmse: 35.0354\n",
      "[600]\ttrain's rmse: 31.1412\tval's rmse: 34.9448\n",
      "[650]\ttrain's rmse: 30.8491\tval's rmse: 34.9028\n",
      "[700]\ttrain's rmse: 30.5837\tval's rmse: 34.8669\n",
      "[750]\ttrain's rmse: 30.3262\tval's rmse: 34.8436\n",
      "[800]\ttrain's rmse: 30.0913\tval's rmse: 34.8367\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttrain's rmse: 30.0913\tval's rmse: 34.8367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 01:59:54,369] Trial 10 finished with value: 34.83670217923643 and parameters: {'num_leaves': 243, 'learning_rate': 0.005090641565719821, 'min_child_samples': 40, 'subsample': 0.5089809378074099, 'colsample_bytree': 0.6522424049106386, 'reg_alpha': 0.3802929602518106, 'reg_lambda': 0.9709367151705007, 'max_depth': 18}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 41.9365\tval's rmse: 42.8365\n",
      "[100]\ttrain's rmse: 37.2655\tval's rmse: 38.3314\n",
      "[150]\ttrain's rmse: 35.0667\tval's rmse: 36.3177\n",
      "[200]\ttrain's rmse: 33.8762\tval's rmse: 35.3984\n",
      "[250]\ttrain's rmse: 33.1474\tval's rmse: 34.9226\n",
      "[300]\ttrain's rmse: 32.6627\tval's rmse: 34.6783\n",
      "[350]\ttrain's rmse: 32.3258\tval's rmse: 34.5821\n",
      "[400]\ttrain's rmse: 32.0375\tval's rmse: 34.5391\n",
      "[450]\ttrain's rmse: 31.7977\tval's rmse: 34.5219\n",
      "[500]\ttrain's rmse: 31.589\tval's rmse: 34.5219\n",
      "Early stopping, best iteration is:\n",
      "[477]\ttrain's rmse: 31.684\tval's rmse: 34.5168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 02:26:10,783] Trial 11 finished with value: 34.516820817811116 and parameters: {'num_leaves': 59, 'learning_rate': 0.012503564240318149, 'min_child_samples': 6, 'subsample': 0.6480436065939664, 'colsample_bytree': 0.5715125850670596, 'reg_alpha': 0.6854618550454727, 'reg_lambda': 0.4304137118393218, 'max_depth': 17}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 41.1094\tval's rmse: 41.9818\n",
      "[100]\ttrain's rmse: 36.5383\tval's rmse: 37.5469\n",
      "[150]\ttrain's rmse: 34.5787\tval's rmse: 35.7789\n",
      "[200]\ttrain's rmse: 33.5937\tval's rmse: 35.0361\n",
      "[250]\ttrain's rmse: 33.0218\tval's rmse: 34.7149\n",
      "[300]\ttrain's rmse: 32.6504\tval's rmse: 34.579\n",
      "[350]\ttrain's rmse: 32.3834\tval's rmse: 34.5421\n",
      "[400]\ttrain's rmse: 32.1579\tval's rmse: 34.5262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 02:45:12,879] Trial 12 finished with value: 34.52287723006604 and parameters: {'num_leaves': 54, 'learning_rate': 0.013484315177328178, 'min_child_samples': 30, 'subsample': 0.6071858177994055, 'colsample_bytree': 0.6506079234532127, 'reg_alpha': 0.5277788930300319, 'reg_lambda': 0.9942502322437741, 'max_depth': 16}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[381]\ttrain's rmse: 32.2336\tval's rmse: 34.5229\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 46.6787\tval's rmse: 47.6732\n",
      "[100]\ttrain's rmse: 42.8723\tval's rmse: 44.0955\n",
      "[150]\ttrain's rmse: 40.0679\tval's rmse: 41.5197\n",
      "[200]\ttrain's rmse: 37.9549\tval's rmse: 39.6575\n",
      "[250]\ttrain's rmse: 36.3526\tval's rmse: 38.3046\n",
      "[300]\ttrain's rmse: 35.1055\tval's rmse: 37.3052\n",
      "[350]\ttrain's rmse: 34.1829\tval's rmse: 36.6188\n",
      "[400]\ttrain's rmse: 33.4134\tval's rmse: 36.0985\n",
      "[450]\ttrain's rmse: 32.7589\tval's rmse: 35.6991\n",
      "[500]\ttrain's rmse: 32.2852\tval's rmse: 35.4482\n",
      "[550]\ttrain's rmse: 31.881\tval's rmse: 35.2552\n",
      "[600]\ttrain's rmse: 31.5317\tval's rmse: 35.1147\n",
      "[650]\ttrain's rmse: 31.2435\tval's rmse: 35.0358\n",
      "[700]\ttrain's rmse: 30.9722\tval's rmse: 34.966\n",
      "[750]\ttrain's rmse: 30.7159\tval's rmse: 34.9104\n",
      "[800]\ttrain's rmse: 30.4844\tval's rmse: 34.8816\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttrain's rmse: 30.4844\tval's rmse: 34.8816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 18:13:53,297] Trial 13 finished with value: 34.881590830207394 and parameters: {'num_leaves': 193, 'learning_rate': 0.005529250273153126, 'min_child_samples': 16, 'subsample': 0.9980082658737176, 'colsample_bytree': 0.5273311223733237, 'reg_alpha': 0.3939658775173549, 'reg_lambda': 0.8186654304763922, 'max_depth': 11}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 41.427\tval's rmse: 42.2909\n",
      "[100]\ttrain's rmse: 37.0471\tval's rmse: 38.0793\n",
      "[150]\ttrain's rmse: 35.0874\tval's rmse: 36.3182\n",
      "[200]\ttrain's rmse: 34.0173\tval's rmse: 35.4772\n",
      "[250]\ttrain's rmse: 33.3912\tval's rmse: 35.0651\n",
      "[300]\ttrain's rmse: 32.9682\tval's rmse: 34.8702\n",
      "[350]\ttrain's rmse: 32.665\tval's rmse: 34.7681\n",
      "[400]\ttrain's rmse: 32.4105\tval's rmse: 34.7177\n",
      "[450]\ttrain's rmse: 32.1784\tval's rmse: 34.6837\n",
      "[500]\ttrain's rmse: 32.0029\tval's rmse: 34.6812\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttrain's rmse: 32.0683\tval's rmse: 34.6759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 18:32:04,149] Trial 14 finished with value: 34.67592518862266 and parameters: {'num_leaves': 54, 'learning_rate': 0.015920853929700354, 'min_child_samples': 34, 'subsample': 0.7187896466361348, 'colsample_bytree': 0.40788418943068505, 'reg_alpha': 0.7016086371955633, 'reg_lambda': 0.4826583456299787, 'max_depth': 13}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 45.2816\tval's rmse: 46.0231\n",
      "[100]\ttrain's rmse: 41.2285\tval's rmse: 41.94\n",
      "[150]\ttrain's rmse: 38.7515\tval's rmse: 39.4244\n",
      "[200]\ttrain's rmse: 37.1711\tval's rmse: 37.8076\n",
      "[250]\ttrain's rmse: 36.0862\tval's rmse: 36.7071\n",
      "[300]\ttrain's rmse: 35.3676\tval's rmse: 35.9861\n",
      "[350]\ttrain's rmse: 34.9052\tval's rmse: 35.5442\n",
      "[400]\ttrain's rmse: 34.5876\tval's rmse: 35.2545\n",
      "[450]\ttrain's rmse: 34.3514\tval's rmse: 35.0552\n",
      "[500]\ttrain's rmse: 34.1781\tval's rmse: 34.9283\n",
      "[550]\ttrain's rmse: 34.0343\tval's rmse: 34.8222\n",
      "[600]\ttrain's rmse: 33.923\tval's rmse: 34.7511\n",
      "[650]\ttrain's rmse: 33.8418\tval's rmse: 34.7074\n",
      "[700]\ttrain's rmse: 33.7776\tval's rmse: 34.677\n",
      "[750]\ttrain's rmse: 33.721\tval's rmse: 34.6509\n",
      "[800]\ttrain's rmse: 33.6748\tval's rmse: 34.636\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[799]\ttrain's rmse: 33.6758\tval's rmse: 34.6359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 18:40:30,707] Trial 15 finished with value: 34.6358862707777 and parameters: {'num_leaves': 24, 'learning_rate': 0.0078383706720137, 'min_child_samples': 58, 'subsample': 0.5827781406926889, 'colsample_bytree': 0.696666871831699, 'reg_alpha': 0.6054469232505305, 'reg_lambda': 0.19449835159756046, 'max_depth': 4}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 35.6211\tval's rmse: 36.9151\n",
      "[100]\ttrain's rmse: 32.9848\tval's rmse: 34.9406\n",
      "[150]\ttrain's rmse: 32.0944\tval's rmse: 34.6884\n",
      "[200]\ttrain's rmse: 31.5466\tval's rmse: 34.682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 18:53:35,216] Trial 16 finished with value: 34.66336163887999 and parameters: {'num_leaves': 76, 'learning_rate': 0.03286723317669127, 'min_child_samples': 55, 'subsample': 0.7029569373499185, 'colsample_bytree': 0.5931045474920172, 'reg_alpha': 0.29199716813145365, 'reg_lambda': 0.004740119653089625, 'max_depth': 20}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[174]\ttrain's rmse: 31.801\tval's rmse: 34.6634\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 37.6969\tval's rmse: 39.0237\n",
      "[100]\ttrain's rmse: 33.6534\tval's rmse: 35.6109\n",
      "[150]\ttrain's rmse: 32.1441\tval's rmse: 34.7859\n",
      "[200]\ttrain's rmse: 31.3356\tval's rmse: 34.6144\n",
      "[250]\ttrain's rmse: 30.7771\tval's rmse: 34.6068\n",
      "Early stopping, best iteration is:\n",
      "[243]\ttrain's rmse: 30.8503\tval's rmse: 34.6037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:21:08,820] Trial 17 finished with value: 34.603672761771115 and parameters: {'num_leaves': 113, 'learning_rate': 0.018430103773582795, 'min_child_samples': 14, 'subsample': 0.822736357875829, 'colsample_bytree': 0.7715797489325291, 'reg_alpha': 0.8205963871605761, 'reg_lambda': 0.8399289384445635, 'max_depth': 11}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 44.4625\tval's rmse: 45.5587\n",
      "[100]\ttrain's rmse: 39.8623\tval's rmse: 41.3013\n",
      "[150]\ttrain's rmse: 36.9656\tval's rmse: 38.7392\n",
      "[200]\ttrain's rmse: 35.0537\tval's rmse: 37.2009\n",
      "[250]\ttrain's rmse: 33.7578\tval's rmse: 36.2596\n",
      "[300]\ttrain's rmse: 32.8203\tval's rmse: 35.6837\n",
      "[350]\ttrain's rmse: 32.1511\tval's rmse: 35.3457\n",
      "[400]\ttrain's rmse: 31.5879\tval's rmse: 35.1261\n",
      "[450]\ttrain's rmse: 31.1114\tval's rmse: 34.9825\n",
      "[500]\ttrain's rmse: 30.7484\tval's rmse: 34.9141\n",
      "[550]\ttrain's rmse: 30.4223\tval's rmse: 34.8787\n",
      "[600]\ttrain's rmse: 30.1263\tval's rmse: 34.8578\n",
      "[650]\ttrain's rmse: 29.8673\tval's rmse: 34.8586\n",
      "Early stopping, best iteration is:\n",
      "[604]\ttrain's rmse: 30.1028\tval's rmse: 34.8559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:38:19,078] Trial 18 finished with value: 34.855911836880374 and parameters: {'num_leaves': 184, 'learning_rate': 0.008580210852256218, 'min_child_samples': 25, 'subsample': 0.5112491815548914, 'colsample_bytree': 0.48632221874006965, 'reg_alpha': 0.40316843373983646, 'reg_lambda': 0.5618977186941465, 'max_depth': 14}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 42.2456\tval's rmse: 43.0735\n",
      "[100]\ttrain's rmse: 37.5819\tval's rmse: 38.4895\n",
      "[150]\ttrain's rmse: 35.3723\tval's rmse: 36.3965\n",
      "[200]\ttrain's rmse: 34.2085\tval's rmse: 35.3818\n",
      "[250]\ttrain's rmse: 33.5722\tval's rmse: 34.9164\n",
      "[300]\ttrain's rmse: 33.172\tval's rmse: 34.6891\n",
      "[350]\ttrain's rmse: 32.9008\tval's rmse: 34.5928\n",
      "[400]\ttrain's rmse: 32.6828\tval's rmse: 34.5496\n",
      "[450]\ttrain's rmse: 32.5108\tval's rmse: 34.5387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:38:47,161] Trial 19 finished with value: 34.53648093071925 and parameters: {'num_leaves': 50, 'learning_rate': 0.011028932330792579, 'min_child_samples': 67, 'subsample': 0.9513285743576702, 'colsample_bytree': 0.6664680325005281, 'reg_alpha': 0.5014570154223665, 'reg_lambda': 0.28794207211359296, 'max_depth': 9}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[438]\ttrain's rmse: 32.5483\tval's rmse: 34.5365\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 34.4557\tval's rmse: 37.1944\n",
      "[100]\ttrain's rmse: 30.5198\tval's rmse: 35.1187\n",
      "[150]\ttrain's rmse: 28.7725\tval's rmse: 34.8555\n",
      "[200]\ttrain's rmse: 27.5306\tval's rmse: 34.8869\n",
      "Early stopping, best iteration is:\n",
      "[167]\ttrain's rmse: 28.2995\tval's rmse: 34.8415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:38:50,377] Trial 20 finished with value: 34.84151197687956 and parameters: {'num_leaves': 227, 'learning_rate': 0.030831277758406536, 'min_child_samples': 5, 'subsample': 0.7967970372017401, 'colsample_bytree': 0.5528237910681919, 'reg_alpha': 0.3028556477512502, 'reg_lambda': 0.7285343080244533, 'max_depth': 15}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 34.0666\tval's rmse: 34.8841\n",
      "[100]\ttrain's rmse: 33.2213\tval's rmse: 34.5389\n",
      "[150]\ttrain's rmse: 32.8982\tval's rmse: 34.5491\n",
      "Early stopping, best iteration is:\n",
      "[101]\ttrain's rmse: 33.2121\tval's rmse: 34.5388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:38:51,095] Trial 21 finished with value: 34.53876462452085 and parameters: {'num_leaves': 19, 'learning_rate': 0.06057696701459514, 'min_child_samples': 83, 'subsample': 0.8576175022258706, 'colsample_bytree': 0.8777376782965068, 'reg_alpha': 0.0022318710364339495, 'reg_lambda': 0.40416875423616255, 'max_depth': 10}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 34.8221\tval's rmse: 35.5074\n",
      "[100]\ttrain's rmse: 33.769\tval's rmse: 34.6796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:38:51,497] Trial 22 finished with value: 34.6077804902241 and parameters: {'num_leaves': 31, 'learning_rate': 0.05481450572801298, 'min_child_samples': 64, 'subsample': 0.9345096954319009, 'colsample_bytree': 0.8391501656697284, 'reg_alpha': 0.24256004021133737, 'reg_lambda': 0.34081622756561514, 'max_depth': 4}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\ttrain's rmse: 33.4907\tval's rmse: 34.6104\n",
      "[200]\ttrain's rmse: 33.3201\tval's rmse: 34.6255\n",
      "Early stopping, best iteration is:\n",
      "[161]\ttrain's rmse: 33.446\tval's rmse: 34.6078\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 37.1958\tval's rmse: 37.9096\n",
      "[100]\ttrain's rmse: 34.3166\tval's rmse: 35.2172\n",
      "[150]\ttrain's rmse: 33.5007\tval's rmse: 34.7023\n",
      "[200]\ttrain's rmse: 33.1506\tval's rmse: 34.5967\n",
      "[250]\ttrain's rmse: 32.9205\tval's rmse: 34.5859\n",
      "Early stopping, best iteration is:\n",
      "[226]\ttrain's rmse: 33.0254\tval's rmse: 34.5792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:38:53,842] Trial 23 finished with value: 34.579150602334494 and parameters: {'num_leaves': 40, 'learning_rate': 0.02101197502088196, 'min_child_samples': 78, 'subsample': 0.857320706512187, 'colsample_bytree': 0.9770309735759881, 'reg_alpha': 0.6787684733696933, 'reg_lambda': 0.16206852947364736, 'max_depth': 6}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 34.3538\tval's rmse: 35.7537\n",
      "[100]\ttrain's rmse: 32.375\tval's rmse: 34.6673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:38:54,882] Trial 24 finished with value: 34.62369439054189 and parameters: {'num_leaves': 70, 'learning_rate': 0.04068745432974507, 'min_child_samples': 45, 'subsample': 0.9494929777252146, 'colsample_bytree': 0.6191631721858419, 'reg_alpha': 0.5781972071431801, 'reg_lambda': 0.3989089622601746, 'max_depth': 19}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\ttrain's rmse: 31.6269\tval's rmse: 34.6375\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttrain's rmse: 31.8371\tval's rmse: 34.6237\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 45.6791\tval's rmse: 46.4393\n",
      "[100]\ttrain's rmse: 41.6023\tval's rmse: 42.3419\n",
      "[150]\ttrain's rmse: 39.0027\tval's rmse: 39.717\n",
      "[200]\ttrain's rmse: 37.2548\tval's rmse: 37.9499\n",
      "[250]\ttrain's rmse: 36.12\tval's rmse: 36.8027\n",
      "[300]\ttrain's rmse: 35.3378\tval's rmse: 36.0311\n",
      "[350]\ttrain's rmse: 34.8249\tval's rmse: 35.5463\n",
      "[400]\ttrain's rmse: 34.4551\tval's rmse: 35.2108\n",
      "[450]\ttrain's rmse: 34.1966\tval's rmse: 34.997\n",
      "[500]\ttrain's rmse: 34.0043\tval's rmse: 34.8525\n",
      "[550]\ttrain's rmse: 33.8517\tval's rmse: 34.7518\n",
      "[600]\ttrain's rmse: 33.7236\tval's rmse: 34.6794\n",
      "[650]\ttrain's rmse: 33.6162\tval's rmse: 34.6225\n",
      "[700]\ttrain's rmse: 33.5198\tval's rmse: 34.5794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:38:58,291] Trial 25 finished with value: 34.53962697307259 and parameters: {'num_leaves': 20, 'learning_rate': 0.00673465198970211, 'min_child_samples': 85, 'subsample': 0.7415125182413653, 'colsample_bytree': 0.7018546729209786, 'reg_alpha': 0.7600945885907388, 'reg_lambda': 0.5209454885482762, 'max_depth': 13}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[750]\ttrain's rmse: 33.4409\tval's rmse: 34.5558\n",
      "[800]\ttrain's rmse: 33.3704\tval's rmse: 34.5396\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[800]\ttrain's rmse: 33.3704\tval's rmse: 34.5396\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 33.7281\tval's rmse: 34.7116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:38:59,286] Trial 26 finished with value: 34.563975362094716 and parameters: {'num_leaves': 98, 'learning_rate': 0.07142133957511557, 'min_child_samples': 65, 'subsample': 0.687720099952898, 'colsample_bytree': 0.7252629605579161, 'reg_alpha': 0.4283887434942813, 'reg_lambda': 0.8923970452006192, 'max_depth': 5}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttrain's rmse: 33.0803\tval's rmse: 34.5811\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttrain's rmse: 33.1401\tval's rmse: 34.564\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 38.4599\tval's rmse: 39.4467\n",
      "[100]\ttrain's rmse: 34.492\tval's rmse: 35.7804\n",
      "[150]\ttrain's rmse: 33.1217\tval's rmse: 34.788\n",
      "[200]\ttrain's rmse: 32.4544\tval's rmse: 34.5447\n",
      "[250]\ttrain's rmse: 32.0291\tval's rmse: 34.5146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:39:01,300] Trial 27 finished with value: 34.511929843414954 and parameters: {'num_leaves': 67, 'learning_rate': 0.016883303554045943, 'min_child_samples': 13, 'subsample': 0.8370866790905461, 'colsample_bytree': 0.8037008040896492, 'reg_alpha': 0.08224202724824858, 'reg_lambda': 0.24374358252999326, 'max_depth': 9}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttrain's rmse: 31.7082\tval's rmse: 34.5299\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttrain's rmse: 31.9813\tval's rmse: 34.5119\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 38.7072\tval's rmse: 39.6508\n",
      "[100]\ttrain's rmse: 34.6962\tval's rmse: 35.8935\n",
      "[150]\ttrain's rmse: 33.3039\tval's rmse: 34.8215\n",
      "[200]\ttrain's rmse: 32.6476\tval's rmse: 34.5447\n",
      "[250]\ttrain's rmse: 32.2324\tval's rmse: 34.4919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:39:03,305] Trial 28 finished with value: 34.48368963819199 and parameters: {'num_leaves': 61, 'learning_rate': 0.016454419902537702, 'min_child_samples': 13, 'subsample': 0.7710348372545968, 'colsample_bytree': 0.799104777655568, 'reg_alpha': 0.2055802655856354, 'reg_lambda': 0.24453624014607778, 'max_depth': 9}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttrain's rmse: 31.9133\tval's rmse: 34.4955\n",
      "Early stopping, best iteration is:\n",
      "[259]\ttrain's rmse: 32.1629\tval's rmse: 34.4837\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 43.3439\tval's rmse: 44.3416\n",
      "[100]\ttrain's rmse: 38.6638\tval's rmse: 39.9187\n",
      "[150]\ttrain's rmse: 36.035\tval's rmse: 37.5579\n",
      "[200]\ttrain's rmse: 34.4519\tval's rmse: 36.2794\n",
      "[250]\ttrain's rmse: 33.4538\tval's rmse: 35.5597\n",
      "[300]\ttrain's rmse: 32.7663\tval's rmse: 35.1552\n",
      "[350]\ttrain's rmse: 32.2845\tval's rmse: 34.9442\n",
      "[400]\ttrain's rmse: 31.8859\tval's rmse: 34.8162\n",
      "[450]\ttrain's rmse: 31.5488\tval's rmse: 34.7448\n",
      "[500]\ttrain's rmse: 31.2844\tval's rmse: 34.7194\n",
      "[550]\ttrain's rmse: 31.0453\tval's rmse: 34.7033\n",
      "[600]\ttrain's rmse: 30.8271\tval's rmse: 34.6988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:39:11,671] Trial 29 finished with value: 34.698715349712685 and parameters: {'num_leaves': 102, 'learning_rate': 0.010572528768819036, 'min_child_samples': 21, 'subsample': 0.5722373915065823, 'colsample_bytree': 0.5046537876358071, 'reg_alpha': 0.19875394712601677, 'reg_lambda': 0.1218222478526813, 'max_depth': 12}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[584]\ttrain's rmse: 30.8966\tval's rmse: 34.6987\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 38.7795\tval's rmse: 39.9446\n",
      "[100]\ttrain's rmse: 34.3749\tval's rmse: 36.0331\n",
      "[150]\ttrain's rmse: 32.74\tval's rmse: 34.9713\n",
      "[200]\ttrain's rmse: 31.8909\tval's rmse: 34.7048\n",
      "[250]\ttrain's rmse: 31.2837\tval's rmse: 34.676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:39:14,864] Trial 30 finished with value: 34.67330979872548 and parameters: {'num_leaves': 119, 'learning_rate': 0.01424741479688491, 'min_child_samples': 30, 'subsample': 0.7875493093172562, 'colsample_bytree': 0.9200979670007132, 'reg_alpha': 0.32190086473366797, 'reg_lambda': 0.07324249636249947, 'max_depth': 15}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttrain's rmse: 30.8045\tval's rmse: 34.6924\n",
      "Early stopping, best iteration is:\n",
      "[252]\ttrain's rmse: 31.262\tval's rmse: 34.6733\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 38.1012\tval's rmse: 39.0876\n",
      "[100]\ttrain's rmse: 34.2817\tval's rmse: 35.599\n",
      "[150]\ttrain's rmse: 33.0013\tval's rmse: 34.7247\n",
      "[200]\ttrain's rmse: 32.3793\tval's rmse: 34.5364\n",
      "[250]\ttrain's rmse: 31.9604\tval's rmse: 34.5139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:39:16,861] Trial 31 finished with value: 34.51124734960992 and parameters: {'num_leaves': 66, 'learning_rate': 0.0178028100997274, 'min_child_samples': 12, 'subsample': 0.8279366525124002, 'colsample_bytree': 0.8364721722524469, 'reg_alpha': 0.13896713016083317, 'reg_lambda': 0.23996308728924426, 'max_depth': 9}. Best is trial 7 with value: 34.464917712505624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttrain's rmse: 31.6233\tval's rmse: 34.5332\n",
      "Early stopping, best iteration is:\n",
      "[254]\ttrain's rmse: 31.928\tval's rmse: 34.5112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 37.855\tval's rmse: 38.682\n",
      "[100]\ttrain's rmse: 34.4018\tval's rmse: 35.4127\n",
      "[150]\ttrain's rmse: 33.3116\tval's rmse: 34.6227\n",
      "[200]\ttrain's rmse: 32.814\tval's rmse: 34.4737\n",
      "[250]\ttrain's rmse: 32.4923\tval's rmse: 34.4477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:39:18,926] Trial 32 finished with value: 34.44414053303151 and parameters: {'num_leaves': 42, 'learning_rate': 0.019495125758870285, 'min_child_samples': 11, 'subsample': 0.7713113309900425, 'colsample_bytree': 0.8173688807212683, 'reg_alpha': 0.16604566690078543, 'reg_lambda': 0.21994740446007705, 'max_depth': 9}. Best is trial 32 with value: 34.44414053303151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttrain's rmse: 32.2208\tval's rmse: 34.4522\n",
      "Early stopping, best iteration is:\n",
      "[255]\ttrain's rmse: 32.4609\tval's rmse: 34.4441\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 36.3897\tval's rmse: 37.2991\n",
      "[100]\ttrain's rmse: 33.6331\tval's rmse: 34.9456\n",
      "[150]\ttrain's rmse: 32.8019\tval's rmse: 34.5437\n",
      "[200]\ttrain's rmse: 32.3623\tval's rmse: 34.4896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:39:20,073] Trial 33 finished with value: 34.48059726845438 and parameters: {'num_leaves': 42, 'learning_rate': 0.028533939152508684, 'min_child_samples': 9, 'subsample': 0.6561429403930797, 'colsample_bytree': 0.6255664143188016, 'reg_alpha': 0.22757131631530325, 'reg_lambda': 0.12199759433109048, 'max_depth': 10}. Best is trial 32 with value: 34.44414053303151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\ttrain's rmse: 32.0396\tval's rmse: 34.4924\n",
      "Early stopping, best iteration is:\n",
      "[214]\ttrain's rmse: 32.2667\tval's rmse: 34.4806\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 35.89\tval's rmse: 36.7433\n",
      "[100]\ttrain's rmse: 33.5357\tval's rmse: 34.7271\n",
      "[150]\ttrain's rmse: 32.8462\tval's rmse: 34.4935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:39:20,876] Trial 34 finished with value: 34.48148485992334 and parameters: {'num_leaves': 40, 'learning_rate': 0.027663015174882576, 'min_child_samples': 22, 'subsample': 0.6636073400847252, 'colsample_bytree': 0.7836454920649512, 'reg_alpha': 0.20136040122568508, 'reg_lambda': 0.11413183068600238, 'max_depth': 8}. Best is trial 32 with value: 34.44414053303151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttrain's rmse: 32.4564\tval's rmse: 34.4826\n",
      "Early stopping, best iteration is:\n",
      "[185]\ttrain's rmse: 32.5609\tval's rmse: 34.4815\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 36.1102\tval's rmse: 36.9686\n",
      "[100]\ttrain's rmse: 33.6471\tval's rmse: 34.8386\n",
      "[150]\ttrain's rmse: 32.9693\tval's rmse: 34.5412\n",
      "[200]\ttrain's rmse: 32.6237\tval's rmse: 34.4982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:39:21,770] Trial 35 finished with value: 34.49245398548041 and parameters: {'num_leaves': 38, 'learning_rate': 0.02943117137421023, 'min_child_samples': 24, 'subsample': 0.6669541421301557, 'colsample_bytree': 0.7134216290384845, 'reg_alpha': 0.152757265561295, 'reg_lambda': 0.07468426896600028, 'max_depth': 7}. Best is trial 32 with value: 34.44414053303151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\ttrain's rmse: 32.3962\tval's rmse: 34.522\n",
      "Early stopping, best iteration is:\n",
      "[210]\ttrain's rmse: 32.5695\tval's rmse: 34.4925\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 33.5138\tval's rmse: 35.3575\n",
      "[100]\ttrain's rmse: 31.5825\tval's rmse: 34.6009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:39:22,705] Trial 36 finished with value: 34.595368093246705 and parameters: {'num_leaves': 89, 'learning_rate': 0.03981522681072439, 'min_child_samples': 9, 'subsample': 0.6185930821967267, 'colsample_bytree': 0.7504164464166815, 'reg_alpha': 0.24629663743460772, 'reg_lambda': 0.04889092612165413, 'max_depth': 10}. Best is trial 32 with value: 34.44414053303151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\ttrain's rmse: 30.6965\tval's rmse: 34.6625\n",
      "Early stopping, best iteration is:\n",
      "[104]\ttrain's rmse: 31.5\tval's rmse: 34.5954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 35.1097\tval's rmse: 36.3406\n",
      "[100]\ttrain's rmse: 32.8783\tval's rmse: 34.7323\n",
      "[150]\ttrain's rmse: 32.2341\tval's rmse: 34.5978\n",
      "Early stopping, best iteration is:\n",
      "[145]\ttrain's rmse: 32.2884\tval's rmse: 34.5963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:39:24,143] Trial 37 finished with value: 34.596323119823175 and parameters: {'num_leaves': 137, 'learning_rate': 0.026768281500961368, 'min_child_samples': 20, 'subsample': 0.7346539456208053, 'colsample_bytree': 0.9278082004101185, 'reg_alpha': 0.3531871782465501, 'reg_lambda': 0.14798977473845915, 'max_depth': 7}. Best is trial 32 with value: 34.44414053303151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 38.1066\tval's rmse: 38.9514\n",
      "[100]\ttrain's rmse: 34.5771\tval's rmse: 35.6069\n",
      "[150]\ttrain's rmse: 33.4472\tval's rmse: 34.7713\n",
      "[200]\ttrain's rmse: 32.9364\tval's rmse: 34.5608\n",
      "[250]\ttrain's rmse: 32.6132\tval's rmse: 34.507\n",
      "[300]\ttrain's rmse: 32.3699\tval's rmse: 34.5131\n",
      "Early stopping, best iteration is:\n",
      "[253]\ttrain's rmse: 32.5973\tval's rmse: 34.5034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:39:25,652] Trial 38 finished with value: 34.50337374435148 and parameters: {'num_leaves': 40, 'learning_rate': 0.02164537338694424, 'min_child_samples': 37, 'subsample': 0.6831251110196007, 'colsample_bytree': 0.6173197872949341, 'reg_alpha': 0.45882324630457233, 'reg_lambda': 0.11366706208053151, 'max_depth': 12}. Best is trial 32 with value: 34.44414053303151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's rmse: 34.0027\tval's rmse: 35.544\n",
      "[100]\ttrain's rmse: 32.0491\tval's rmse: 34.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 19:39:26,628] Trial 39 finished with value: 34.57446044866803 and parameters: {'num_leaves': 82, 'learning_rate': 0.035900567580878964, 'min_child_samples': 26, 'subsample': 0.6354483548900522, 'colsample_bytree': 0.7934432403779488, 'reg_alpha': 0.1344713392622623, 'reg_lambda': 0.013099968852774813, 'max_depth': 10}. Best is trial 32 with value: 34.44414053303151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\ttrain's rmse: 31.2441\tval's rmse: 34.6333\n",
      "Early stopping, best iteration is:\n",
      "[101]\ttrain's rmse: 32.029\tval's rmse: 34.5745\n",
      "Saved Optuna trials to: optuna_native_outputs\\optuna_trials.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "robust_lgb_train() got an unexpected keyword argument 'dval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 235\u001b[0m\n\u001b[0;32m    230\u001b[0m dtrain_full \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(pd\u001b[38;5;241m.\u001b[39mconcat([X_train_proc, X_val_proc], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m    231\u001b[0m                           label\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mconcat([y_train\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), y_val\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m    232\u001b[0m                           categorical_feature\u001b[38;5;241m=\u001b[39m[c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cat_feats \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m X_train_proc\u001b[38;5;241m.\u001b[39mcolumns], free_raw_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# robust retrain using the same wrapper\u001b[39;00m\n\u001b[1;32m--> 235\u001b[0m bst_best \u001b[38;5;241m=\u001b[39m robust_lgb_train(best_params, dtrain_full, dval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, early_stop_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# If bst_best didn't accept a val set (we passed dval=None), predict using best_iteration if present\u001b[39;00m\n\u001b[0;32m    238\u001b[0m best_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: robust_lgb_train() got an unexpected keyword argument 'dval'"
     ]
    }
   ],
   "source": [
    "# Robust Optuna tuning for LightGBM (native categorical)  compatibility-safe training\n",
    "# Adjust n_trials for runtime (default 40).\n",
    "\n",
    "import os, sys, subprocess, joblib, json, traceback\n",
    "from pathlib import Path\n",
    "from math import sqrt\n",
    "import pandas as pd, numpy as np\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure optuna is available\n",
    "try:\n",
    "    import optuna\n",
    "except Exception:\n",
    "    print(\"Installing optuna...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"optuna\"])\n",
    "    import optuna\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ---------- config ----------\n",
    "CLEAN_IN = 'amazon_delivery_cleaned.csv'\n",
    "OUT_DIR = 'optuna_native_outputs'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "n_trials = 40   \n",
    "timeout_minutes = None  \n",
    "\n",
    "# ---------- load data & preprocessing (same as native training) ----------\n",
    "df = pd.read_csv(CLEAN_IN)\n",
    "num_feats = [c for c in [\n",
    "    'distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed',\n",
    "    'hour_sin','hour_cos','agent_perf_score'\n",
    "] if c in df.columns]\n",
    "\n",
    "cat_feats = [c for c in [\n",
    "    'Weather_imputed','Traffic','Vehicle','Area','Category_grp','part_of_day',\n",
    "    'distance_bucket','Traffic_Weather','Area_PartOfDay','CatTraffic','agent_experience_bucket'\n",
    "] if c in df.columns]\n",
    "\n",
    "df_model = df.dropna(subset=['Delivery_Time']).copy()\n",
    "X = df_model[num_feats + cat_feats].copy()\n",
    "y = df_model['Delivery_Time'].copy()\n",
    "\n",
    "for c in cat_feats:\n",
    "    if c in X.columns:\n",
    "        X[c] = X[c].astype('category')\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.20, random_state=42)\n",
    "\n",
    "# numeric preprocess\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "if len(num_feats) > 0:\n",
    "    X_train_num = pd.DataFrame(num_imputer.fit_transform(X_train[num_feats]), columns=num_feats, index=X_train.index)\n",
    "    X_train_num = pd.DataFrame(scaler.fit_transform(X_train_num), columns=num_feats, index=X_train.index)\n",
    "    X_val_num = pd.DataFrame(scaler.transform(pd.DataFrame(num_imputer.transform(X_val[num_feats]), columns=num_feats, index=X_val.index)), columns=num_feats, index=X_val.index)\n",
    "    X_test_num = pd.DataFrame(scaler.transform(pd.DataFrame(num_imputer.transform(X_test[num_feats]), columns=num_feats, index=X_test.index)), columns=num_feats, index=X_test.index)\n",
    "else:\n",
    "    X_train_num = pd.DataFrame(index=X_train.index)\n",
    "    X_val_num = pd.DataFrame(index=X_val.index)\n",
    "    X_test_num = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "X_train_proc = pd.concat([X_train_num.reset_index(drop=True), X_train[cat_feats].reset_index(drop=True)], axis=1)\n",
    "X_val_proc = pd.concat([X_val_num.reset_index(drop=True), X_val[cat_feats].reset_index(drop=True)], axis=1)\n",
    "X_test_proc = pd.concat([X_test_num.reset_index(drop=True), X_test[cat_feats].reset_index(drop=True)], axis=1)\n",
    "\n",
    "for c in cat_feats:\n",
    "    if c in X_train_proc.columns:\n",
    "        X_train_proc[c] = X_train_proc[c].astype('category')\n",
    "        X_val_proc[c] = X_val_proc[c].astype('category')\n",
    "        X_test_proc[c] = X_test_proc[c].astype('category')\n",
    "\n",
    "dtrain = lgb.Dataset(X_train_proc, label=y_train.reset_index(drop=True), categorical_feature=[c for c in cat_feats if c in X_train_proc.columns], free_raw_data=False)\n",
    "dval = lgb.Dataset(X_val_proc, label=y_val.reset_index(drop=True), categorical_feature=[c for c in cat_feats if c in X_train_proc.columns], reference=dtrain, free_raw_data=False)\n",
    "\n",
    "# mlflow experiment\n",
    "os.makedirs(\"mlruns\", exist_ok=True)\n",
    "mlflow.set_tracking_uri(Path(os.path.abspath(\"mlruns\")).as_uri())\n",
    "EXP_NAME = 'lightgbm_optuna_native'\n",
    "mlflow.set_experiment(EXP_NAME)\n",
    "print(\"MLflow experiment:\", EXP_NAME)\n",
    "\n",
    "# ---------- robust train wrapper used by objective ----------\n",
    "def robust_lgb_train(params, train_set, val_set, num_boost_round=800, early_stop_rounds=50, verbose_eval=False):\n",
    "    \"\"\"\n",
    "    Try several ways of calling lgb.train to be compatible with different LightGBM versions.\n",
    "    Returns trained Booster.\n",
    "    \"\"\"\n",
    "    bst = None\n",
    "    # Attempt 1: common signature with early_stopping_rounds\n",
    "    try:\n",
    "        bst = lgb.train(\n",
    "            params=params,\n",
    "            train_set=train_set,\n",
    "            num_boost_round=num_boost_round,\n",
    "            valid_sets=[train_set, val_set],\n",
    "            valid_names=['train','val'],\n",
    "            early_stopping_rounds=early_stop_rounds,\n",
    "            verbose_eval=verbose_eval\n",
    "        )\n",
    "        return bst\n",
    "    except TypeError as e1:\n",
    "        # print(\"early_stopping_rounds not accepted:\", e1)\n",
    "        pass\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Attempt 2: callbacks API if available\n",
    "    try:\n",
    "        callbacks = []\n",
    "        if hasattr(lgb, 'early_stopping'):\n",
    "            callbacks.append(lgb.early_stopping(stopping_rounds=early_stop_rounds))\n",
    "        if hasattr(lgb, 'log_evaluation'):\n",
    "            callbacks.append(lgb.log_evaluation(period=50))\n",
    "        if callbacks:\n",
    "            bst = lgb.train(\n",
    "                params=params,\n",
    "                train_set=train_set,\n",
    "                num_boost_round=num_boost_round,\n",
    "                valid_sets=[train_set, val_set],\n",
    "                valid_names=['train','val'],\n",
    "                callbacks=callbacks\n",
    "            )\n",
    "            return bst\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Attempt 3: no early stopping (final fallback)\n",
    "    try:\n",
    "        bst = lgb.train(\n",
    "            params=params,\n",
    "            train_set=train_set,\n",
    "            num_boost_round=num_boost_round,\n",
    "            valid_sets=[train_set, val_set],\n",
    "            valid_names=['train','val'],\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        return bst\n",
    "    except Exception:\n",
    "        # Very last fallback: minimal call\n",
    "        bst = lgb.train(\n",
    "            params=params,\n",
    "            train_set=train_set,\n",
    "            num_boost_round=num_boost_round\n",
    "        )\n",
    "        return bst\n",
    "\n",
    "# ---------- Optuna objective (defensive) ----------\n",
    "def objective(trial):\n",
    "    # search space\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 16, 256),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 24),\n",
    "        'verbosity': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    num_boost_round = 800\n",
    "    try:\n",
    "        bst = robust_lgb_train(params, dtrain, dval, num_boost_round=num_boost_round, early_stop_rounds=50, verbose_eval=False)\n",
    "        # pick best iteration\n",
    "        best_iter = None\n",
    "        try:\n",
    "            if hasattr(bst, 'best_iteration') and bst.best_iteration is not None:\n",
    "                best_iter = int(bst.best_iteration)\n",
    "            elif hasattr(bst, 'best_ntree_limit') and bst.best_ntree_limit is not None:\n",
    "                best_iter = int(bst.best_ntree_limit)\n",
    "            else:\n",
    "                best_iter = num_boost_round\n",
    "        except Exception:\n",
    "            best_iter = num_boost_round\n",
    "\n",
    "        y_pred = bst.predict(X_val_proc, num_iteration=best_iter)\n",
    "        rmse = np.sqrt(np.mean((y_val.reset_index(drop=True).values - y_pred) ** 2))\n",
    "        # log trial info to optuna\n",
    "        trial.set_user_attr(\"best_iter\", int(best_iter))\n",
    "        return float(rmse)\n",
    "    except Exception as e:\n",
    "        # catch-all: return a high RMSE so the trial is considered bad but doesn't crash the study\n",
    "        print(\"Trial failed with exception (caught inside objective):\", e)\n",
    "        traceback.print_exc()\n",
    "        return float(1e6)\n",
    "\n",
    "# ---------- run study ----------\n",
    "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "print(\"Starting Optuna study with n_trials =\", n_trials)\n",
    "if timeout_minutes:\n",
    "    study.optimize(objective, n_trials=n_trials, timeout=60*timeout_minutes)\n",
    "else:\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "# ---------- save study results ----------\n",
    "joblib.dump(study, os.path.join(OUT_DIR, 'optuna_study.pkl'))\n",
    "trials_df = study.trials_dataframe()\n",
    "trials_csv = os.path.join(OUT_DIR, 'optuna_trials.csv')\n",
    "trials_df.to_csv(trials_csv, index=False)\n",
    "print(\"Saved Optuna trials to:\", trials_csv)\n",
    "\n",
    "# ---------- retrain best on train+val and evaluate on test ----------\n",
    "best = study.best_params\n",
    "best_params = {\n",
    "    'objective':'regression',\n",
    "    'metric':'rmse',\n",
    "    'num_leaves': int(best['num_leaves']),\n",
    "    'learning_rate': float(best['learning_rate']),\n",
    "    'min_child_samples': int(best['min_child_samples']),\n",
    "    'subsample': float(best['subsample']),\n",
    "    'colsample_bytree': float(best['colsample_bytree']),\n",
    "    'reg_alpha': float(best['reg_alpha']),\n",
    "    'reg_lambda': float(best['reg_lambda']),\n",
    "    'max_depth': int(best['max_depth']),\n",
    "    'verbosity': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "dtrain_full = lgb.Dataset(pd.concat([X_train_proc, X_val_proc], axis=0, ignore_index=True),\n",
    "                          label=pd.concat([y_train.reset_index(drop=True), y_val.reset_index(drop=True)], axis=0, ignore_index=True),\n",
    "                          categorical_feature=[c for c in cat_feats if c in X_train_proc.columns], free_raw_data=False)\n",
    "\n",
    "# robust retrain using the same wrapper\n",
    "bst_best = robust_lgb_train(best_params, dtrain_full, dval=None, num_boost_round=1000, early_stop_rounds=50, verbose_eval=False)\n",
    "\n",
    "# If bst_best didn't accept a val set (we passed dval=None), predict using best_iteration if present\n",
    "best_iter = None\n",
    "try:\n",
    "    if hasattr(bst_best, 'best_iteration') and bst_best.best_iteration is not None:\n",
    "        best_iter = int(bst_best.best_iteration)\n",
    "    elif hasattr(bst_best, 'best_ntree_limit') and bst_best.best_ntree_limit is not None:\n",
    "        best_iter = int(bst_best.best_ntree_limit)\n",
    "    else:\n",
    "        best_iter = 1000\n",
    "except Exception:\n",
    "    best_iter = 1000\n",
    "\n",
    "y_pred_test = bst_best.predict(X_test_proc, num_iteration=best_iter)\n",
    "test_mae = mean_absolute_error(y_test.reset_index(drop=True), y_pred_test)\n",
    "test_rmse = np.sqrt(np.mean((y_test.reset_index(drop=True).values - y_pred_test) ** 2))\n",
    "test_r2 = r2_score(y_test.reset_index(drop=True), y_pred_test)\n",
    "\n",
    "print(\"Optuna best params:\", best_params)\n",
    "print(f\"Test metrics -> MAE={test_mae:.3f}, RMSE={test_rmse:.3f}, R2={test_r2:.4f}\")\n",
    "\n",
    "# save best model and summary\n",
    "best_model_txt = os.path.join(OUT_DIR, 'lgbm_optuna_best_model.txt')\n",
    "best_model_joblib = os.path.join(OUT_DIR, 'lgbm_optuna_best_model.pkl')\n",
    "try:\n",
    "    bst_best.save_model(best_model_txt)\n",
    "except Exception:\n",
    "    pass\n",
    "joblib.dump(bst_best, best_model_joblib)\n",
    "\n",
    "summary = {'best_params': best_params, 'test_mae': float(test_mae), 'test_rmse': float(test_rmse), 'test_r2': float(test_r2)}\n",
    "with open(os.path.join(OUT_DIR, 'lgbm_optuna_summary.json'), 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# MLflow logging\n",
    "with mlflow.start_run(run_name='lgbm_optuna_native'):\n",
    "    mlflow.log_params({k: best_params[k] for k in ['num_leaves','learning_rate','max_depth','min_child_samples','subsample','colsample_bytree']})\n",
    "    mlflow.log_metric('test_mae', float(test_mae))\n",
    "    mlflow.log_metric('test_rmse', float(test_rmse))\n",
    "    mlflow.log_metric('test_r2', float(test_r2))\n",
    "    mlflow.log_artifact(trials_csv)\n",
    "    mlflow.log_artifact(os.path.join(OUT_DIR, 'lgbm_optuna_summary.json'))\n",
    "    if os.path.exists(best_model_txt):\n",
    "        mlflow.log_artifact(best_model_txt)\n",
    "    mlflow.log_artifact(best_model_joblib)\n",
    "\n",
    "print(\"Optuna tuning complete. Artifacts saved to\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ffa8cf1-5ef2-434e-86fb-e6e359b971b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Optuna study from optuna_native_outputs\\optuna_study.pkl\n",
      "Best params (from study): {'num_leaves': 42, 'learning_rate': 0.019495125758870285, 'min_child_samples': 11, 'subsample': 0.7713113309900425, 'colsample_bytree': 0.8173688807212683, 'reg_alpha': 0.16604566690078543, 'reg_lambda': 0.21994740446007705, 'max_depth': 9}\n",
      "[50]\ttrain's rmse: 37.9934\n",
      "[100]\ttrain's rmse: 34.5635\n",
      "[150]\ttrain's rmse: 33.5627\n",
      "[200]\ttrain's rmse: 33.1264\n",
      "[250]\ttrain's rmse: 32.842\n",
      "[300]\ttrain's rmse: 32.6047\n",
      "[350]\ttrain's rmse: 32.4091\n",
      "[400]\ttrain's rmse: 32.2288\n",
      "[450]\ttrain's rmse: 32.0618\n",
      "[500]\ttrain's rmse: 31.8979\n",
      "[550]\ttrain's rmse: 31.7486\n",
      "[600]\ttrain's rmse: 31.6103\n",
      "[650]\ttrain's rmse: 31.4666\n",
      "[700]\ttrain's rmse: 31.3429\n",
      "[750]\ttrain's rmse: 31.1877\n",
      "[800]\ttrain's rmse: 31.0495\n",
      "[850]\ttrain's rmse: 30.9238\n",
      "[900]\ttrain's rmse: 30.7906\n",
      "[950]\ttrain's rmse: 30.6706\n",
      "[1000]\ttrain's rmse: 30.5461\n",
      "Final retrain with Optuna best params completed.\n",
      "Test metrics -> MAE=23.774, RMSE=33.902, R2=0.5686\n",
      "Saved artifacts to optuna_native_outputs and logged to MLflow.\n"
     ]
    }
   ],
   "source": [
    "# Fix + retrain best Optuna model on train+val, evaluate on test, save artifacts and log to MLflow.\n",
    "# Extracts the best params i.e. trial 32\n",
    "\n",
    "import os, json, joblib, traceback\n",
    "from pathlib import Path\n",
    "from math import sqrt\n",
    "import pandas as pd, numpy as np\n",
    "import mlflow\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ---------- load Optuna study summary (optional) ----------\n",
    "study_file = os.path.join('optuna_native_outputs', 'optuna_study.pkl')\n",
    "trials_csv = os.path.join('optuna_native_outputs', 'optuna_trials.csv')\n",
    "if os.path.exists(study_file):\n",
    "    try:\n",
    "        study = joblib.load(study_file)\n",
    "        print(\"Loaded Optuna study from\", study_file)\n",
    "    except Exception:\n",
    "        study = None\n",
    "else:\n",
    "    study = None\n",
    "\n",
    "# If study object not present, read trials CSV and pick best row\n",
    "best_params = None\n",
    "if study is not None:\n",
    "    best = study.best_params\n",
    "    best_params = {k: study.best_params[k] for k in study.best_params}\n",
    "    print(\"Best params (from study):\", best_params)\n",
    "elif os.path.exists(trials_csv):\n",
    "    df_trials = pd.read_csv(trials_csv)\n",
    "    # optuna trial df column names may vary; try to find best row by value\n",
    "    if 'value' in df_trials.columns:\n",
    "        best_row = df_trials.loc[df_trials['value'].idxmin()]\n",
    "    else:\n",
    "        best_row = df_trials.iloc[df_trials['value'].argmin()]\n",
    "    # extract param columns (columns starting with 'params_')\n",
    "    best_params = {}\n",
    "    for col in df_trials.columns:\n",
    "        if col.startswith('params_'):\n",
    "            key = col.replace('params_', '')\n",
    "            best_params[key] = best_row[col]\n",
    "    print(\"Best params (from CSV):\", best_params)\n",
    "else:\n",
    "    raise FileNotFoundError(\"Could not find Optuna study or trials CSV. Check optuna_native_outputs/\")\n",
    "\n",
    "# Convert any numeric strings to numbers where appropriate\n",
    "for k,v in list(best_params.items()):\n",
    "    try:\n",
    "        if isinstance(v, str) and v.replace('.','',1).isdigit():\n",
    "            if '.' in v:\n",
    "                best_params[k] = float(v)\n",
    "            else:\n",
    "                best_params[k] = int(v)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# ---------- Recreate data preprocessing (same as training/optuna) ----------\n",
    "CLEAN_IN = 'amazon_delivery_cleaned.csv'\n",
    "df = pd.read_csv(CLEAN_IN)\n",
    "num_feats = [c for c in [\n",
    "    'distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed',\n",
    "    'hour_sin','hour_cos','agent_perf_score'\n",
    "] if c in df.columns]\n",
    "\n",
    "cat_feats = [c for c in [\n",
    "    'Weather_imputed','Traffic','Vehicle','Area','Category_grp','part_of_day',\n",
    "    'distance_bucket','Traffic_Weather','Area_PartOfDay','CatTraffic','agent_experience_bucket'\n",
    "] if c in df.columns]\n",
    "\n",
    "df_model = df.dropna(subset=['Delivery_Time']).copy()\n",
    "X = df_model[num_feats + cat_feats].copy()\n",
    "y = df_model['Delivery_Time'].copy()\n",
    "\n",
    "for c in cat_feats:\n",
    "    if c in X.columns:\n",
    "        X[c] = X[c].astype('category')\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.20, random_state=42)\n",
    "\n",
    "# numeric preprocess\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "if len(num_feats) > 0:\n",
    "    X_train_num = pd.DataFrame(num_imputer.fit_transform(X_train[num_feats]), columns=num_feats, index=X_train.index)\n",
    "    X_train_num = pd.DataFrame(scaler.fit_transform(X_train_num), columns=num_feats, index=X_train.index)\n",
    "    X_val_num = pd.DataFrame(scaler.transform(pd.DataFrame(num_imputer.transform(X_val[num_feats]), columns=num_feats, index=X_val.index)), columns=num_feats, index=X_val.index)\n",
    "    X_test_num = pd.DataFrame(scaler.transform(pd.DataFrame(num_imputer.transform(X_test[num_feats]), columns=num_feats, index=X_test.index)), columns=num_feats, index=X_test.index)\n",
    "else:\n",
    "    X_train_num = pd.DataFrame(index=X_train.index)\n",
    "    X_val_num = pd.DataFrame(index=X_val.index)\n",
    "    X_test_num = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "X_train_proc = pd.concat([X_train_num.reset_index(drop=True), X_train[cat_feats].reset_index(drop=True)], axis=1)\n",
    "X_val_proc   = pd.concat([X_val_num.reset_index(drop=True),   X_val[cat_feats].reset_index(drop=True)], axis=1)\n",
    "X_test_proc  = pd.concat([X_test_num.reset_index(drop=True),  X_test[cat_feats].reset_index(drop=True)], axis=1)\n",
    "\n",
    "for c in cat_feats:\n",
    "    if c in X_train_proc.columns:\n",
    "        X_train_proc[c] = X_train_proc[c].astype('category')\n",
    "        X_val_proc[c]   = X_val_proc[c].astype('category')\n",
    "        X_test_proc[c]  = X_test_proc[c].astype('category')\n",
    "\n",
    "# ---------- Build LightGBM params for core API ----------\n",
    "train_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': int(best_params.get('num_leaves', 31)),\n",
    "    'learning_rate': float(best_params.get('learning_rate', 0.02)),\n",
    "    'max_depth': int(best_params.get('max_depth', 16)),\n",
    "    'min_child_samples': int(best_params.get('min_child_samples', 5)),\n",
    "    'subsample': float(best_params.get('subsample', 0.7)),\n",
    "    'colsample_bytree': float(best_params.get('colsample_bytree', 0.7)),\n",
    "    'reg_alpha': float(best_params.get('reg_alpha', 0.0)),\n",
    "    'reg_lambda': float(best_params.get('reg_lambda', 0.0)),\n",
    "    'verbosity': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "num_boost_round = int(best_params.get('n_estimators', 400)) if 'n_estimators' in best_params else 1000\n",
    "\n",
    "# ---------- robust train wrapper (same as before, positional args!) ----------\n",
    "def robust_lgb_train(params, train_set, val_set=None, num_boost_round=800, early_stop_rounds=50, verbose_eval=False):\n",
    "    bst = None\n",
    "    try:\n",
    "        bst = lgb.train(\n",
    "            params=params,\n",
    "            train_set=train_set,\n",
    "            num_boost_round=num_boost_round,\n",
    "            valid_sets=[train_set, val_set] if val_set is not None else [train_set],\n",
    "            valid_names=['train','val'] if val_set is not None else ['train'],\n",
    "            early_stopping_rounds=early_stop_rounds,\n",
    "            verbose_eval=verbose_eval\n",
    "        )\n",
    "        return bst\n",
    "    except TypeError:\n",
    "        pass\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        callbacks = []\n",
    "        if hasattr(lgb, 'early_stopping') and val_set is not None:\n",
    "            callbacks.append(lgb.early_stopping(stopping_rounds=early_stop_rounds))\n",
    "        if hasattr(lgb, 'log_evaluation'):\n",
    "            callbacks.append(lgb.log_evaluation(period=50))\n",
    "        if callbacks:\n",
    "            bst = lgb.train(\n",
    "                params=params,\n",
    "                train_set=train_set,\n",
    "                num_boost_round=num_boost_round,\n",
    "                valid_sets=[train_set, val_set] if val_set is not None else [train_set],\n",
    "                valid_names=['train','val'] if val_set is not None else ['train'],\n",
    "                callbacks=callbacks\n",
    "            )\n",
    "            return bst\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Final fallback: no early stopping\n",
    "    bst = lgb.train(\n",
    "        params=params,\n",
    "        train_set=train_set,\n",
    "        num_boost_round=num_boost_round,\n",
    "        valid_sets=[train_set, val_set] if val_set is not None else [train_set],\n",
    "        valid_names=['train','val'] if val_set is not None else ['train']\n",
    "    )\n",
    "    return bst\n",
    "\n",
    "# ---------- Retrain best model on train+val ----------\n",
    "dtrain_full = lgb.Dataset(pd.concat([X_train_proc, X_val_proc], axis=0, ignore_index=True),\n",
    "                          label=pd.concat([y_train.reset_index(drop=True), y_val.reset_index(drop=True)], axis=0, ignore_index=True),\n",
    "                          categorical_feature=[c for c in cat_feats if c in X_train_proc.columns], free_raw_data=False)\n",
    "\n",
    "# Call the wrapper CORRECTLY (positional args; val_set=None because we're training on combined train+val)\n",
    "bst_best = robust_lgb_train(train_params, dtrain_full, val_set=None, num_boost_round=num_boost_round, early_stop_rounds=50, verbose_eval=False)\n",
    "\n",
    "# determine best_iter if available\n",
    "best_iter = None\n",
    "try:\n",
    "    if hasattr(bst_best, 'best_iteration') and bst_best.best_iteration is not None:\n",
    "        best_iter = int(bst_best.best_iteration)\n",
    "    elif hasattr(bst_best, 'best_ntree_limit') and bst_best.best_ntree_limit is not None:\n",
    "        best_iter = int(bst_best.best_ntree_limit)\n",
    "    else:\n",
    "        best_iter = num_boost_round\n",
    "except Exception:\n",
    "    best_iter = num_boost_round\n",
    "\n",
    "# ---------- Evaluate on test ----------\n",
    "y_pred_test = bst_best.predict(X_test_proc, num_iteration=best_iter)\n",
    "test_mae = mean_absolute_error(y_test.reset_index(drop=True), y_pred_test)\n",
    "test_rmse = sqrt(mean_squared_error(y_test.reset_index(drop=True), y_pred_test))\n",
    "test_r2 = r2_score(y_test.reset_index(drop=True), y_pred_test)\n",
    "\n",
    "print(\"Final retrain with Optuna best params completed.\")\n",
    "print(\"Test metrics -> MAE={:.3f}, RMSE={:.3f}, R2={:.4f}\".format(test_mae, test_rmse, test_r2))\n",
    "\n",
    "# ---------- Save & log artifacts ----------\n",
    "out_dir = 'optuna_native_outputs'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "best_model_txt = os.path.join(out_dir, 'lgbm_optuna_best_model.txt')\n",
    "best_model_joblib = os.path.join(out_dir, 'lgbm_optuna_best_model.pkl')\n",
    "try:\n",
    "    bst_best.save_model(best_model_txt)\n",
    "except Exception:\n",
    "    pass\n",
    "joblib.dump(bst_best, best_model_joblib)\n",
    "\n",
    "# feature importances\n",
    "try:\n",
    "    importances = bst_best.feature_importance(importance_type='gain')\n",
    "except Exception:\n",
    "    importances = bst_best.feature_importance()\n",
    "feature_names = list(X_train_proc.columns)\n",
    "if len(importances) != len(feature_names):\n",
    "    minlen = min(len(importances), len(feature_names))\n",
    "    feature_names = feature_names[:minlen]\n",
    "    importances = importances[:minlen]\n",
    "fi_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "fi_df = fi_df.sort_values('importance', ascending=False)\n",
    "fi_csv = os.path.join(out_dir, 'lgbm_optuna_feature_importance.csv')\n",
    "fi_df.to_csv(fi_csv, index=False)\n",
    "\n",
    "summary = {'best_params': best_params, 'test_mae': float(test_mae), 'test_rmse': float(test_rmse), 'test_r2': float(test_r2), 'best_iteration': int(best_iter)}\n",
    "with open(os.path.join(out_dir, 'lgbm_optuna_summary.json'), 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# MLflow log\n",
    "mlflow.set_tracking_uri(Path(os.path.abspath(\"mlruns\")).as_uri())\n",
    "mlflow.set_experiment('lightgbm_optuna_native')\n",
    "with mlflow.start_run(run_name='lgbm_optuna_native_final'):\n",
    "    mlflow.log_params({k: best_params[k] for k in best_params if k in best_params})\n",
    "    mlflow.log_metric('test_mae', float(test_mae))\n",
    "    mlflow.log_metric('test_rmse', float(test_rmse))\n",
    "    mlflow.log_metric('test_r2', float(test_r2))\n",
    "    mlflow.log_artifact(best_model_txt) if os.path.exists(best_model_txt) else None\n",
    "    mlflow.log_artifact(best_model_joblib)\n",
    "    mlflow.log_artifact(trials_csv) if os.path.exists(trials_csv) else None\n",
    "    mlflow.log_artifact(os.path.join(out_dir, 'lgbm_optuna_summary.json'))\n",
    "    mlflow.log_artifact(fi_csv)\n",
    "\n",
    "print(\"Saved artifacts to\", out_dir, \"and logged to MLflow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924ac463-479c-49e5-bf8e-f9bc0320854d",
   "metadata": {},
   "source": [
    "## Final model selection  summary\n",
    "\n",
    "**Selected production model:** LightGBM (native categorical  tuned earlier)  \n",
    "**Reason:** Best MAE (23.675 mins) and compact pipeline (no OHE explosion), solid RMSE (33.783) and explainability.\n",
    "\n",
    "### Optuna run outcome\n",
    "- Optuna-best params (study): num_leaves=42, learning_rate0.0195, min_child_samples=11, subsample0.771, colsample_bytree0.817, reg_alpha0.166, reg_lambda0.220, max_depth=9.\n",
    "- After retraining on train+val, Optuna model test metrics: **MAE=23.774, RMSE=33.902, R=0.5686**  slightly worse than the chosen model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c4d5071-5002-4eed-b61a-a58ec4e7c71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: ['distance_km', 'order_to_pickup_mins', 'Agent_Age', 'Agent_Rating_imputed', 'hour_sin', 'hour_cos']\n",
      "Categorical features: ['Weather_imputed', 'Traffic', 'Vehicle', 'Area', 'Category_grp', 'part_of_day', 'distance_bucket', 'Traffic_Weather', 'Area_PartOfDay', 'CatTraffic']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/27 22:53:12 INFO mlflow.tracking.fluent: Experiment with name 'model_packaging' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved imputer -> preprocessor_imputer.joblib\n",
      "Saved scaler  -> preprocessor_scaler.joblib\n",
      "Saved inference wrapper to: predict_wrapper.py\n",
      "Logged artifacts to MLflow run: aa70a711bbd74252a3ecf153a8e7160d\n",
      "Model registration via MLflow failed (common on local file-only setups).\n",
      "Error: Unable to find a logged_model with artifact_path lgbm_native_cat_model_booster.joblib under run aa70a711bbd74252a3ecf153a8e7160d\n",
      "You can still find the logged artifacts under the MLflow run artifact URI: file:///C:/Users/shail_u9zs758/mlruns/390273216647380284/aa70a711bbd74252a3ecf153a8e7160d/artifacts\n",
      "To register manually in MLflow UI: run `mlflow ui`, open the run, download artifact and use `mlflow.register_model()` pointing to a valid tracking server or provide an artifact URI accessible to the server.\n",
      "\\n=== Packaging completed ===\n",
      "Saved files:\n",
      " - model: lgbm_native_cat_model_booster.joblib\n",
      " - imputer: preprocessor_imputer.joblib\n",
      " - scaler: preprocessor_scaler.joblib\n",
      " - wrapper: predict_wrapper.py\n",
      "\n",
      "Usage example (in notebook):\n",
      ">>> from predict_wrapper import predict_delivery_time\n",
      ">>> sample = {\n",
      "    'distance_km': 10,\n",
      "    'order_to_pickup_mins': 10,\n",
      "    'Agent_Age': 10,\n",
      "    'Agent_Rating_imputed': 10,\n",
      "    'hour_sin': 10,\n",
      "    'hour_cos': 10,\n",
      "    'Weather_imputed': 'some_value',\n",
      "    'Traffic': 'some_value',\n",
      "    'Vehicle': 'some_value',\n",
      ">>> }\n",
      ">>> pred = predict_delivery_time(sample)\n",
      ">>> print('Predicted minutes:', pred)\n",
      "\n",
      "If the MLflow Model Registry registration failed above (common locally), you can still:\n",
      " - Open MLflow UI: `mlflow ui`\n",
      " - Navigate to the run 'register_lgbm_native_cat' and download artifacts.\n",
      " - Register the model on a remote MLflow server or keep artifacts with versioning in your repo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'lgbm_native_cat_prod'.\n"
     ]
    }
   ],
   "source": [
    "# Register model + create inference wrapper\n",
    "# - amazon_delivery_cleaned.csv exists\n",
    "# - lgbm_native_cat_model_booster.joblib exists (the chosen model)\n",
    "#\n",
    "# This cell will:\n",
    "# 1) re-fit numeric preprocessors on the full modelling dataset and save them\n",
    "# 2) create a prediction wrapper file predict_wrapper.py\n",
    "# 3) log artifacts to MLflow and attempt to register the model in Model Registry\n",
    "# 4) print usage instructions\n",
    "\n",
    "import os, json, joblib, traceback\n",
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np\n",
    "import mlflow\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ---------- Config / filenames ----------\n",
    "CLEAN_IN = 'amazon_delivery_cleaned.csv'\n",
    "MODEL_JOBLIB = 'lgbm_native_cat_model_booster.joblib'  # chosen model\n",
    "IMPUTER_FILE = 'preprocessor_imputer.joblib'\n",
    "SCALER_FILE = 'preprocessor_scaler.joblib'\n",
    "WRAPPER_FILE = 'predict_wrapper.py'\n",
    "MLFLOW_MODEL_NAME = 'lgbm_native_cat_prod'  # registry name to try to register\n",
    "\n",
    "# numeric/categorical features used in training (keeps names identical to training)\n",
    "num_feats = [c for c in [\n",
    "    'distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed',\n",
    "    'hour_sin','hour_cos','agent_perf_score'\n",
    "] if c in pd.read_csv(CLEAN_IN).columns]  # quick check to ensure columns exist\n",
    "\n",
    "cat_feats = [c for c in [\n",
    "    'Weather_imputed','Traffic','Vehicle','Area','Category_grp','part_of_day',\n",
    "    'distance_bucket','Traffic_Weather','Area_PartOfDay','CatTraffic','agent_experience_bucket'\n",
    "] if c in pd.read_csv(CLEAN_IN).columns]\n",
    "\n",
    "print(\"Numeric features:\", num_feats)\n",
    "print(\"Categorical features:\", cat_feats)\n",
    "\n",
    "# ---------- 1) Fit & save preprocessing artifacts ----------\n",
    "if not os.path.exists(CLEAN_IN):\n",
    "    raise FileNotFoundError(f\"{CLEAN_IN} not found in cwd: {os.getcwd()}\")\n",
    "\n",
    "if not os.path.exists(MODEL_JOBLIB):\n",
    "    raise FileNotFoundError(f\"{MODEL_JOBLIB} not found  please ensure the chosen model artifact exists.\")\n",
    "\n",
    "df = pd.read_csv(CLEAN_IN)\n",
    "df_model = df.dropna(subset=['Delivery_Time']).copy()\n",
    "\n",
    "# Fit imputer & scaler on numeric features using full modelling set\n",
    "if len(num_feats) > 0:\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    scaler = StandardScaler()\n",
    "    X_num = df_model[num_feats]\n",
    "    X_num_imp = imputer.fit_transform(X_num)\n",
    "    X_num_scaled = scaler.fit_transform(X_num_imp)\n",
    "    joblib.dump(imputer, IMPUTER_FILE)\n",
    "    joblib.dump(scaler, SCALER_FILE)\n",
    "    print(f\"Saved imputer -> {IMPUTER_FILE}\")\n",
    "    print(f\"Saved scaler  -> {SCALER_FILE}\")\n",
    "else:\n",
    "    # If no numeric features, create placeholder artifacts\n",
    "    imputer = None\n",
    "    scaler = None\n",
    "    print(\"No numeric features found; skipping imputer/scaler creation.\")\n",
    "\n",
    "# ---------- 2) Create the prediction wrapper file =========\n",
    "wrapper_code = f'''\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# filenames (assumed to be in same working directory)\n",
    "MODEL_FILE = \"{MODEL_JOBLIB}\"\n",
    "IMPUTER_FILE = \"{IMPUTER_FILE}\"\n",
    "SCALER_FILE = \"{SCALER_FILE}\"\n",
    "\n",
    "# feature lists (must match training)\n",
    "NUM_FEATS = {num_feats}\n",
    "CAT_FEATS = {cat_feats}\n",
    "\n",
    "# load artifacts lazily (first call)\n",
    "_model = None\n",
    "_imputer = None\n",
    "_scaler = None\n",
    "\n",
    "def _load_artifacts():\n",
    "    global _model, _imputer, _scaler\n",
    "    if _model is None:\n",
    "        _model = joblib.load(MODEL_FILE)\n",
    "    if len(NUM_FEATS) > 0 and _imputer is None:\n",
    "        _imputer = joblib.load(IMPUTER_FILE)\n",
    "        _scaler = joblib.load(SCALER_FILE)\n",
    "    return _model, _imputer, _scaler\n",
    "\n",
    "def _prepare_input(df):\n",
    "    \\\"\\\"\\\"Accepts a pandas DataFrame or a dict (single row). Returns processed DataFrame ready for model.predict.\\\"\\\"\\\"\n",
    "    if isinstance(df, dict):\n",
    "        df = pd.DataFrame([df])\n",
    "    elif not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"Input must be a pandas DataFrame or a dict (single row).\")\n",
    "\n",
    "    # ensure columns exist\n",
    "    missing = [c for c in (NUM_FEATS + CAT_FEATS) if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Input is missing required columns: {{missing}}\")\n",
    "\n",
    "    # numeric processing\n",
    "    if len(NUM_FEATS) > 0:\n",
    "        num_df = pd.DataFrame(df[NUM_FEATS].copy(), columns=NUM_FEATS)\n",
    "        num_imp = _imputer.transform(num_df)\n",
    "        num_scaled = _scaler.transform(num_imp)\n",
    "        num_scaled_df = pd.DataFrame(num_scaled, columns=NUM_FEATS, index=df.index)\n",
    "    else:\n",
    "        num_scaled_df = pd.DataFrame(index=df.index)\n",
    "\n",
    "    # categorical - cast to category dtype (LightGBM expects categories)\n",
    "    cat_df = df[CAT_FEATS].copy()\n",
    "    for c in CAT_FEATS:\n",
    "        if c in cat_df.columns:\n",
    "            cat_df[c] = cat_df[c].astype('category')\n",
    "\n",
    "    X_proc = pd.concat([num_scaled_df.reset_index(drop=True), cat_df.reset_index(drop=True)], axis=1)\n",
    "    return X_proc\n",
    "\n",
    "def predict_delivery_time(input_df_or_dict):\n",
    "    \\\"\\\"\\\"Return predicted delivery time (minutes) as numpy array (or scalar for single row).\\\"\\\"\\\"\n",
    "    global _model, _imputer, _scaler\n",
    "    _model, _imputer, _scaler = _load_artifacts()\n",
    "    X_proc = _prepare_input(input_df_or_dict)\n",
    "    # LightGBM booster predict expects X as DataFrame with categorical columns set to 'category'\n",
    "    preds = _model.predict(X_proc)\n",
    "    # return scalar for single-row input\n",
    "    if isinstance(input_df_or_dict, dict):\n",
    "        return float(preds[0])\n",
    "    return preds\n",
    "'''\n",
    "\n",
    "with open(WRAPPER_FILE, 'w') as f:\n",
    "    f.write(wrapper_code)\n",
    "print(f\"Saved inference wrapper to: {WRAPPER_FILE}\")\n",
    "\n",
    "# ---------- 3) Log artifacts to MLflow and attempt to register the model ----------\n",
    "# Use file-backed mlruns (same as earlier)\n",
    "os.makedirs(\"mlruns\", exist_ok=True)\n",
    "mlflow.set_tracking_uri(Path(os.path.abspath(\"mlruns\")).as_uri())\n",
    "mlflow.set_experiment('model_packaging')\n",
    "\n",
    "registered_model_uri = None\n",
    "try:\n",
    "    with mlflow.start_run(run_name='register_lgbm_native_cat'):\n",
    "        # log artifacts\n",
    "        mlflow.log_artifact(MODEL_JOBLIB)\n",
    "        if os.path.exists(IMPUTER_FILE):\n",
    "            mlflow.log_artifact(IMPUTER_FILE)\n",
    "        if os.path.exists(SCALER_FILE):\n",
    "            mlflow.log_artifact(SCALER_FILE)\n",
    "        mlflow.log_artifact(WRAPPER_FILE)\n",
    "\n",
    "        run_id = mlflow.active_run().info.run_id\n",
    "        # artifact path under the run\n",
    "        artifact_uri = mlflow.get_artifact_uri()  # e.g. file:///.../mlruns/0/<run_id>/artifacts\n",
    "        model_artifact_path = f\"runs:/{run_id}/{MODEL_JOBLIB}\"\n",
    "        print(\"Logged artifacts to MLflow run:\", run_id)\n",
    "        # Attempt to register model in registry (may fail for local-file-only mlruns)\n",
    "        try:\n",
    "            mv = mlflow.register_model(model_artifact_path, MLFLOW_MODEL_NAME)\n",
    "            registered_model_uri = mv.version\n",
    "            print(f\"Model registered in MLflow Model Registry as name '{MLFLOW_MODEL_NAME}', version: {registered_model_uri}\")\n",
    "        except Exception as e:\n",
    "            print(\"Model registration via MLflow failed (common on local file-only setups).\")\n",
    "            print(\"Error:\", e)\n",
    "            print(\"You can still find the logged artifacts under the MLflow run artifact URI:\", artifact_uri)\n",
    "            print(\"To register manually in MLflow UI: run `mlflow ui`, open the run, download artifact and use `mlflow.register_model()` pointing to a valid tracking server or provide an artifact URI accessible to the server.\")\n",
    "except Exception:\n",
    "    print(\"Failed to log artifacts to MLflow. Traceback:\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "# ---------- 4) Print final instructions & example ----------\n",
    "print(\"\\\\n=== Packaging completed ===\")\n",
    "print(\"Saved files:\")\n",
    "print(\" - model:\", MODEL_JOBLIB)\n",
    "if os.path.exists(IMPUTER_FILE):\n",
    "    print(\" - imputer:\", IMPUTER_FILE)\n",
    "if os.path.exists(SCALER_FILE):\n",
    "    print(\" - scaler:\", SCALER_FILE)\n",
    "print(\" - wrapper:\", WRAPPER_FILE)\n",
    "print()\n",
    "print(\"Usage example (in notebook):\")\n",
    "print(\">>> from predict_wrapper import predict_delivery_time\")\n",
    "print(\">>> sample = {\")\n",
    "for c in num_feats[:]:\n",
    "    print(f\"    '{c}': 10,\")  # placeholder values shown; replace with realistic values\n",
    "for c in cat_feats[:3]:\n",
    "    print(f\"    '{c}': 'some_value',\")\n",
    "print(\">>> }\")\n",
    "print(\">>> pred = predict_delivery_time(sample)\")\n",
    "print(\">>> print('Predicted minutes:', pred)\")\n",
    "print()\n",
    "print(\"If the MLflow Model Registry registration failed above (common locally), you can still:\")\n",
    "print(\" - Open MLflow UI: `mlflow ui`\")\n",
    "print(\" - Navigate to the run 'register_lgbm_native_cat' and download artifacts.\")\n",
    "print(\" - Register the model on a remote MLflow server or keep artifacts with versioning in your repo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "570e4297-dbc3-4ceb-9ba8-d8e983e0cee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shail_u9zs758\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\pyfunc\\utils\\data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n",
      "2025/09/27 22:58:40 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3446058c586f40ffa58d36c295ec32fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "MlflowException",
     "evalue": "The following failures occurred while downloading one or more artifacts from model_artifacts:\n##### File lgbm_native_cat_model_booster.joblib #####\n[WinError 3] The system cannot find the path specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_artifact(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlgbm_native_cat_model_booster.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m, artifact_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_artifacts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m artifacts \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_artifacts/lgbm_native_cat_model_booster.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m---> 16\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mpyfunc\u001b[38;5;241m.\u001b[39mlog_model(\n\u001b[0;32m     17\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyfunc_model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m     python_model\u001b[38;5;241m=\u001b[39mSklearnWrapper(),\n\u001b[0;32m     19\u001b[0m     artifacts\u001b[38;5;241m=\u001b[39martifacts\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m run_id \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mactive_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m     22\u001b[0m model_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/pyfunc_model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\tracing\\provider.py:508\u001b[0m, in \u001b[0;36mtrace_disabled.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    507\u001b[0m     is_func_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 508\u001b[0m     result \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     enable()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\pyfunc\\__init__.py:3605\u001b[0m, in \u001b[0;36mlog_model\u001b[1;34m(artifact_path, loader_module, data_path, code_paths, infer_code_paths, conda_env, python_model, artifacts, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, metadata, model_config, streamable, resources, auth_policy, prompts, name, params, tags, model_type, step, model_id)\u001b[0m\n\u001b[0;32m   3403\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3404\u001b[0m \u001b[38;5;124;03mLog a Pyfunc model with custom inference logic and optional data dependencies as an MLflow\u001b[39;00m\n\u001b[0;32m   3405\u001b[0m \u001b[38;5;124;03martifact for the current run.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3602\u001b[0m \u001b[38;5;124;03m    metadata of the logged model.\u001b[39;00m\n\u001b[0;32m   3603\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3604\u001b[0m flavor_name \u001b[38;5;241m=\u001b[39m _get_pyfunc_model_flavor_name(python_model)\n\u001b[1;32m-> 3605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Model\u001b[38;5;241m.\u001b[39mlog(\n\u001b[0;32m   3606\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39martifact_path,\n\u001b[0;32m   3607\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   3608\u001b[0m     flavor\u001b[38;5;241m=\u001b[39mmlflow\u001b[38;5;241m.\u001b[39mpyfunc,\n\u001b[0;32m   3609\u001b[0m     loader_module\u001b[38;5;241m=\u001b[39mloader_module,\n\u001b[0;32m   3610\u001b[0m     data_path\u001b[38;5;241m=\u001b[39mdata_path,\n\u001b[0;32m   3611\u001b[0m     code_paths\u001b[38;5;241m=\u001b[39mcode_paths,\n\u001b[0;32m   3612\u001b[0m     python_model\u001b[38;5;241m=\u001b[39mpython_model,\n\u001b[0;32m   3613\u001b[0m     artifacts\u001b[38;5;241m=\u001b[39martifacts,\n\u001b[0;32m   3614\u001b[0m     conda_env\u001b[38;5;241m=\u001b[39mconda_env,\n\u001b[0;32m   3615\u001b[0m     registered_model_name\u001b[38;5;241m=\u001b[39mregistered_model_name,\n\u001b[0;32m   3616\u001b[0m     signature\u001b[38;5;241m=\u001b[39msignature,\n\u001b[0;32m   3617\u001b[0m     input_example\u001b[38;5;241m=\u001b[39minput_example,\n\u001b[0;32m   3618\u001b[0m     await_registration_for\u001b[38;5;241m=\u001b[39mawait_registration_for,\n\u001b[0;32m   3619\u001b[0m     pip_requirements\u001b[38;5;241m=\u001b[39mpip_requirements,\n\u001b[0;32m   3620\u001b[0m     extra_pip_requirements\u001b[38;5;241m=\u001b[39mextra_pip_requirements,\n\u001b[0;32m   3621\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m   3622\u001b[0m     prompts\u001b[38;5;241m=\u001b[39mprompts,\n\u001b[0;32m   3623\u001b[0m     model_config\u001b[38;5;241m=\u001b[39mmodel_config,\n\u001b[0;32m   3624\u001b[0m     streamable\u001b[38;5;241m=\u001b[39mstreamable,\n\u001b[0;32m   3625\u001b[0m     resources\u001b[38;5;241m=\u001b[39mresources,\n\u001b[0;32m   3626\u001b[0m     infer_code_paths\u001b[38;5;241m=\u001b[39minfer_code_paths,\n\u001b[0;32m   3627\u001b[0m     auth_policy\u001b[38;5;241m=\u001b[39mauth_policy,\n\u001b[0;32m   3628\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m   3629\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m   3630\u001b[0m     model_type\u001b[38;5;241m=\u001b[39mmodel_type,\n\u001b[0;32m   3631\u001b[0m     step\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   3632\u001b[0m     model_id\u001b[38;5;241m=\u001b[39mmodel_id,\n\u001b[0;32m   3633\u001b[0m     \u001b[38;5;66;03m# only used for checking python model type\u001b[39;00m\n\u001b[0;32m   3634\u001b[0m     flavor_name\u001b[38;5;241m=\u001b[39mflavor_name,\n\u001b[0;32m   3635\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\models\\model.py:1218\u001b[0m, in \u001b[0;36mModel.log\u001b[1;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, auth_policy, prompts, name, model_type, params, tags, step, model_id, **kwargs)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     prompts \u001b[38;5;241m=\u001b[39m [pr\u001b[38;5;241m.\u001b[39muri \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pr, PromptVersion) \u001b[38;5;28;01melse\u001b[39;00m pr \u001b[38;5;28;01mfor\u001b[39;00m pr \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m   1208\u001b[0m mlflow_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m   1209\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39martifact_location,\n\u001b[0;32m   1210\u001b[0m     model_uuid\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1216\u001b[0m     model_id\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_id,\n\u001b[0;32m   1217\u001b[0m )\n\u001b[1;32m-> 1218\u001b[0m flavor\u001b[38;5;241m.\u001b[39msave_model(path\u001b[38;5;241m=\u001b[39mlocal_path, mlflow_model\u001b[38;5;241m=\u001b[39mmlflow_model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;66;03m# `save_model` calls `load_model` to infer the model requirements, which may result\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;66;03m# in __pycache__ directories being created in the model directory.\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pycache \u001b[38;5;129;01min\u001b[39;00m Path(local_path)\u001b[38;5;241m.\u001b[39mrglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__pycache__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\tracing\\provider.py:513\u001b[0m, in \u001b[0;36mtrace_disabled.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    512\u001b[0m         is_func_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 513\u001b[0m         result \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    514\u001b[0m \u001b[38;5;66;03m# We should only catch the exception from disable() and enable()\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m# and let other exceptions propagate.\u001b[39;00m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MlflowTracingException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\pyfunc\\__init__.py:3344\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(path, loader_module, data_path, code_paths, infer_code_paths, conda_env, mlflow_model, python_model, artifacts, signature, input_example, pip_requirements, extra_pip_requirements, metadata, model_config, streamable, resources, auth_policy, **kwargs)\u001b[0m\n\u001b[0;32m   3330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _save_model_with_loader_module_and_data_path(\n\u001b[0;32m   3331\u001b[0m         path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m   3332\u001b[0m         loader_module\u001b[38;5;241m=\u001b[39mloader_module,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3341\u001b[0m         infer_code_paths\u001b[38;5;241m=\u001b[39minfer_code_paths,\n\u001b[0;32m   3342\u001b[0m     )\n\u001b[0;32m   3343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m second_argument_set_specified:\n\u001b[1;32m-> 3344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mpyfunc\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_save_model_with_class_artifacts_params(\n\u001b[0;32m   3345\u001b[0m         path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m   3346\u001b[0m         signature\u001b[38;5;241m=\u001b[39msignature,\n\u001b[0;32m   3347\u001b[0m         python_model\u001b[38;5;241m=\u001b[39mpython_model,\n\u001b[0;32m   3348\u001b[0m         artifacts\u001b[38;5;241m=\u001b[39martifacts,\n\u001b[0;32m   3349\u001b[0m         conda_env\u001b[38;5;241m=\u001b[39mconda_env,\n\u001b[0;32m   3350\u001b[0m         code_paths\u001b[38;5;241m=\u001b[39mcode_paths,\n\u001b[0;32m   3351\u001b[0m         mlflow_model\u001b[38;5;241m=\u001b[39mmlflow_model,\n\u001b[0;32m   3352\u001b[0m         pip_requirements\u001b[38;5;241m=\u001b[39mpip_requirements,\n\u001b[0;32m   3353\u001b[0m         extra_pip_requirements\u001b[38;5;241m=\u001b[39mextra_pip_requirements,\n\u001b[0;32m   3354\u001b[0m         model_config\u001b[38;5;241m=\u001b[39mmodel_config,\n\u001b[0;32m   3355\u001b[0m         streamable\u001b[38;5;241m=\u001b[39mstreamable,\n\u001b[0;32m   3356\u001b[0m         model_code_path\u001b[38;5;241m=\u001b[39mmodel_code_path,\n\u001b[0;32m   3357\u001b[0m         infer_code_paths\u001b[38;5;241m=\u001b[39minfer_code_paths,\n\u001b[0;32m   3358\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\pyfunc\\model.py:1298\u001b[0m, in \u001b[0;36m_save_model_with_class_artifacts_params\u001b[1;34m(path, python_model, signature, artifacts, conda_env, code_paths, mlflow_model, pip_requirements, extra_pip_requirements, model_config, streamable, model_code_path, infer_code_paths)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     saved_artifact_subpath \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1295\u001b[0m         Path(snapshot_location)\u001b[38;5;241m.\u001b[39mrelative_to(Path(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(path)))\u001b[38;5;241m.\u001b[39mas_posix()\n\u001b[0;32m   1296\u001b[0m     )\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1298\u001b[0m     tmp_artifact_path \u001b[38;5;241m=\u001b[39m _download_artifact_from_uri(\n\u001b[0;32m   1299\u001b[0m         artifact_uri\u001b[38;5;241m=\u001b[39martifact_uri, output_path\u001b[38;5;241m=\u001b[39mtmp_artifacts_dir\u001b[38;5;241m.\u001b[39mpath()\n\u001b[0;32m   1300\u001b[0m     )\n\u001b[0;32m   1302\u001b[0m     relative_path \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1303\u001b[0m         Path(tmp_artifact_path)\n\u001b[0;32m   1304\u001b[0m         \u001b[38;5;241m.\u001b[39mrelative_to(Path(tmp_artifacts_dir\u001b[38;5;241m.\u001b[39mpath()))\n\u001b[0;32m   1305\u001b[0m         \u001b[38;5;241m.\u001b[39mas_posix()\n\u001b[0;32m   1306\u001b[0m     )\n\u001b[0;32m   1308\u001b[0m     saved_artifact_subpath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m   1309\u001b[0m         saved_artifacts_dir_subpath, relative_path\n\u001b[0;32m   1310\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\tracking\\artifact_utils.py:124\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[1;34m(artifact_uri, output_path, lineage_header_info, tracking_uri)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repo, ModelsArtifactRepository):\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m repo\u001b[38;5;241m.\u001b[39mdownload_artifacts(\n\u001b[0;32m    120\u001b[0m             artifact_path\u001b[38;5;241m=\u001b[39martifact_path,\n\u001b[0;32m    121\u001b[0m             dst_path\u001b[38;5;241m=\u001b[39moutput_path,\n\u001b[0;32m    122\u001b[0m             lineage_header_info\u001b[38;5;241m=\u001b[39mlineage_header_info,\n\u001b[0;32m    123\u001b[0m         )\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m repo\u001b[38;5;241m.\u001b[39mdownload_artifacts(artifact_path\u001b[38;5;241m=\u001b[39martifact_path, dst_path\u001b[38;5;241m=\u001b[39moutput_path)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artifact_uri\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;66;03m# When a Model ID like string is passed, suggest using 'models:/{artifact_uri}' instead.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\store\\artifact\\local_artifact_repo.py:86\u001b[0m, in \u001b[0;36mLocalArtifactRepository.download_artifacts\u001b[1;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03mArtifacts tracked by ``LocalArtifactRepository`` already exist on the local filesystem.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03mIf ``dst_path`` is ``None``, the absolute filesystem path of the specified artifact is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    Absolute path of the local filesystem location containing the desired artifacts.\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dst_path:\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdownload_artifacts(artifact_path, dst_path)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# NOTE: The artifact_path is expected to be a relative path in posix format.\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Posix paths work fine on windows but just in case we normalize it here.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m artifact_path \u001b[38;5;241m=\u001b[39m validate_path_is_safe(artifact_path)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\store\\artifact\\artifact_repo.py:323\u001b[0m, in \u001b[0;36mArtifactRepository.download_artifacts\u001b[1;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[0;32m    317\u001b[0m         template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m##### File \u001b[39m\u001b[38;5;132;01m{path}\u001b[39;00m\u001b[38;5;124m #####\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{error}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    319\u001b[0m     failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    320\u001b[0m         template\u001b[38;5;241m.\u001b[39mformat(path\u001b[38;5;241m=\u001b[39mpath, error\u001b[38;5;241m=\u001b[39merror, traceback\u001b[38;5;241m=\u001b[39mtracebacks[path])\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m path, error \u001b[38;5;129;01min\u001b[39;00m failed_downloads\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 323\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    324\u001b[0m         message\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    325\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following failures occurred while downloading one or more\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    326\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m artifacts from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifact_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_truncate_error(failures)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    327\u001b[0m         )\n\u001b[0;32m    328\u001b[0m     )\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst_path, artifact_path)\n",
      "\u001b[1;31mMlflowException\u001b[0m: The following failures occurred while downloading one or more artifacts from model_artifacts:\n##### File lgbm_native_cat_model_booster.joblib #####\n[WinError 3] The system cannot find the path specified"
     ]
    }
   ],
   "source": [
    "import mlflow, joblib\n",
    "from mlflow.pyfunc import PythonModel\n",
    "\n",
    "# Create a simple wrapper class to allow mlflow.pyfunc logging\n",
    "class SklearnWrapper(PythonModel):\n",
    "    def load_context(self, context):\n",
    "        import joblib\n",
    "        self.model = joblib.load(context.artifacts[\"model_path\"])\n",
    "    def predict(self, context, model_input):\n",
    "        return self.model.predict(model_input)\n",
    "\n",
    "mlflow.set_tracking_uri(\"file:///C:/Users/shail_u9zs758/mlruns\")\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_artifact(\"lgbm_native_cat_model_booster.joblib\", artifact_path=\"model_artifacts\")\n",
    "    artifacts = {\"model_path\": \"model_artifacts/lgbm_native_cat_model_booster.joblib\"}\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"pyfunc_model\",\n",
    "        python_model=SklearnWrapper(),\n",
    "        artifacts=artifacts\n",
    "    )\n",
    "    run_id = mlflow.active_run().info.run_id\n",
    "    model_uri = f\"runs:/{run_id}/pyfunc_model\"\n",
    "    # now register\n",
    "    mv = mlflow.register_model(model_uri, \"lgbm_native_cat_prod\")\n",
    "    print(\"Registered model version:\", mv.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "606c5bcd-948e-4685-bd9f-8aec3d2a1cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shail_u9zs758\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\pyfunc\\utils\\data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n",
      "2025/09/27 23:01:53 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute model path: C:\\Users\\shail_u9zs758\\lgbm_native_cat_model_booster.joblib\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8854a6c7cf6e4c63a33369dfa73bb02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/27 23:02:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'lgbm_native_cat_prod' already exists. Creating a new version of this model...\n",
      "2025/09/27 23:02:10 WARNING mlflow.tracking._model_registry.fluent: Run with id 3288d4ed01ec451996e2984522afb8c3 has no artifacts at artifact path 'pyfunc_model', registering model based on models:/m-2743501c5b8f4394bfe32dd631a07b03 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged pyfunc model to run: 3288d4ed01ec451996e2984522afb8c3\n",
      "Model URI: runs:/3288d4ed01ec451996e2984522afb8c3/pyfunc_model\n",
      "Successfully registered model 'lgbm_native_cat_prod', version: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'lgbm_native_cat_prod'.\n"
     ]
    }
   ],
   "source": [
    "# Robust pyfunc logging + registration\n",
    "import os, joblib, mlflow, traceback\n",
    "from mlflow.pyfunc import PythonModel\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_JOBLIB = 'lgbm_native_cat_model_booster.joblib'\n",
    "MLFLOW_MODEL_NAME = 'lgbm_native_cat_prod'\n",
    "\n",
    "if not os.path.exists(MODEL_JOBLIB):\n",
    "    raise FileNotFoundError(f\"{MODEL_JOBLIB} not found in cwd: {os.getcwd()}\")\n",
    "\n",
    "# 1) define wrapper\n",
    "class SklearnWrapper(PythonModel):\n",
    "    def load_context(self, context):\n",
    "        import joblib, os\n",
    "        # 'model_path' will point to the local path inside the saved pyfunc artifact\n",
    "        model_path = context.artifacts[\"model_path\"]\n",
    "        self.model = joblib.load(model_path)\n",
    "    def predict(self, context, model_input):\n",
    "        # model_input is a pandas DataFrame; return numpy array or pd.Series\n",
    "        return self.model.predict(model_input)\n",
    "\n",
    "# 2) log pyfunc model using absolute artifact path so mlflow can copy it reliably\n",
    "abs_model_path = os.path.abspath(MODEL_JOBLIB)\n",
    "print(\"Absolute model path:\", abs_model_path)\n",
    "\n",
    "mlflow.set_tracking_uri(mlflow.get_tracking_uri())  # keep current tracking uri (file:///.../mlruns)\n",
    "mlflow.set_experiment('model_packaging')  # or whichever experiment you want\n",
    "\n",
    "try:\n",
    "    with mlflow.start_run(run_name='pyfunc_register_attempt'):\n",
    "        # Pass absolute local path so mlflow copies from local fs into the model bundle\n",
    "        artifacts = {\"model_path\": abs_model_path}\n",
    "        # Log pyfunc model (this will copy the joblib into the model artifact dir)\n",
    "        mlflow.pyfunc.log_model(artifact_path=\"pyfunc_model\", python_model=SklearnWrapper(), artifacts=artifacts)\n",
    "        run_id = mlflow.active_run().info.run_id\n",
    "        model_uri = f\"runs:/{run_id}/pyfunc_model\"\n",
    "        print(\"Logged pyfunc model to run:\", run_id)\n",
    "        print(\"Model URI:\", model_uri)\n",
    "\n",
    "    # 3) register the model (this may fail locally if registry not available; handle gracefully)\n",
    "    try:\n",
    "        mv = mlflow.register_model(model_uri, MLFLOW_MODEL_NAME)\n",
    "        print(f\"Successfully registered model '{MLFLOW_MODEL_NAME}', version:\", mv.version)\n",
    "    except Exception as e:\n",
    "        print(\"Registering model programmatically failed (common on local file-only setups).\")\n",
    "        print(\"You can still use the model via model_uri:\", model_uri)\n",
    "        print(\"If you have an MLflow server with registry enabled, run the registration there or use MLflow UI.\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"pyfunc log_model failed. Full traceback:\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef694014-ec1b-42f1-a4bf-10e6feb206c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Invalid value \"<run_id>\" for parameter 'run_id' supplied.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmlflow\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns:/<run_id>/pyfunc_model\u001b[39m\u001b[38;5;124m\"\u001b[39m   \u001b[38;5;66;03m# copy from printed output\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m loaded \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mpyfunc\u001b[38;5;241m.\u001b[39mload_model(model_uri)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# assume you have a test dataframe X_test_proc prepared\u001b[39;00m\n\u001b[0;32m      5\u001b[0m preds \u001b[38;5;241m=\u001b[39m loaded\u001b[38;5;241m.\u001b[39mpredict(X_test_proc\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\tracing\\provider.py:508\u001b[0m, in \u001b[0;36mtrace_disabled.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    507\u001b[0m     is_func_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 508\u001b[0m     result \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     enable()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\pyfunc\\__init__.py:1132\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(model_uri, suppress_warnings, dst_path, model_config)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         entity_list\u001b[38;5;241m.\u001b[39mappend(Entity(job\u001b[38;5;241m=\u001b[39mjob_entity))\n\u001b[0;32m   1130\u001b[0m     lineage_header_info \u001b[38;5;241m=\u001b[39m LineageHeaderInfo(entities\u001b[38;5;241m=\u001b[39mentity_list) \u001b[38;5;28;01mif\u001b[39;00m entity_list \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1132\u001b[0m local_path \u001b[38;5;241m=\u001b[39m _download_artifact_from_uri(\n\u001b[0;32m   1133\u001b[0m     artifact_uri\u001b[38;5;241m=\u001b[39mmodel_uri, output_path\u001b[38;5;241m=\u001b[39mdst_path, lineage_header_info\u001b[38;5;241m=\u001b[39mlineage_header_info\n\u001b[0;32m   1134\u001b[0m )\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m suppress_warnings:\n\u001b[0;32m   1137\u001b[0m     model_requirements \u001b[38;5;241m=\u001b[39m _get_pip_requirements_from_model_path(local_path)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\tracking\\artifact_utils.py:115\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[1;34m(artifact_uri, output_path, lineage_header_info, tracking_uri)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m    artifact_uri: The *absolute* URI of the artifact to download.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    tracking_uri: The tracking URI to be used when downloading artifacts.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    114\u001b[0m root_uri, artifact_path \u001b[38;5;241m=\u001b[39m _get_root_uri_and_artifact_path(artifact_uri)\n\u001b[1;32m--> 115\u001b[0m repo \u001b[38;5;241m=\u001b[39m get_artifact_repository(artifact_uri\u001b[38;5;241m=\u001b[39mroot_uri, tracking_uri\u001b[38;5;241m=\u001b[39mtracking_uri)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repo, ModelsArtifactRepository):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\store\\artifact\\artifact_repository_registry.py:143\u001b[0m, in \u001b[0;36mget_artifact_repository\u001b[1;34m(artifact_uri, tracking_uri)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_artifact_repository\u001b[39m(\n\u001b[0;32m    127\u001b[0m     artifact_uri: \u001b[38;5;28mstr\u001b[39m, tracking_uri: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    128\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArtifactRepository:\n\u001b[0;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    Get an artifact repository from the registry based on the scheme of artifact_uri\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03m        requirements.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _artifact_repository_registry\u001b[38;5;241m.\u001b[39mget_artifact_repository(artifact_uri, tracking_uri)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\store\\artifact\\artifact_repository_registry.py:81\u001b[0m, in \u001b[0;36mArtifactRepositoryRegistry.get_artifact_repository\u001b[1;34m(self, artifact_uri, tracking_uri)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repository \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find a registered artifact repository for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently registered schemes are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     80\u001b[0m     )\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repository(artifact_uri, tracking_uri\u001b[38;5;241m=\u001b[39mtracking_uri)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\store\\artifact\\runs_artifact_repo.py:36\u001b[0m, in \u001b[0;36mRunsArtifactRepository.__init__\u001b[1;34m(self, artifact_uri, tracking_uri)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martifact\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martifact_repository_registry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_artifact_repository\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(artifact_uri, tracking_uri)\n\u001b[1;32m---> 36\u001b[0m uri \u001b[38;5;241m=\u001b[39m RunsArtifactRepository\u001b[38;5;241m.\u001b[39mget_underlying_uri(artifact_uri, tracking_uri)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo \u001b[38;5;241m=\u001b[39m get_artifact_repository(uri, tracking_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracking_uri)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\store\\artifact\\runs_artifact_repo.py:49\u001b[0m, in \u001b[0;36mRunsArtifactRepository.get_underlying_uri\u001b[1;34m(runs_uri, tracking_uri)\u001b[0m\n\u001b[0;32m     47\u001b[0m (run_id, artifact_path) \u001b[38;5;241m=\u001b[39m RunsArtifactRepository\u001b[38;5;241m.\u001b[39mparse_runs_uri(runs_uri)\n\u001b[0;32m     48\u001b[0m databricks_profile_uri \u001b[38;5;241m=\u001b[39m get_databricks_profile_uri_from_artifact_uri(runs_uri)\n\u001b[1;32m---> 49\u001b[0m uri \u001b[38;5;241m=\u001b[39m get_artifact_uri(\n\u001b[0;32m     50\u001b[0m     run_id\u001b[38;5;241m=\u001b[39mrun_id,\n\u001b[0;32m     51\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39martifact_path,\n\u001b[0;32m     52\u001b[0m     tracking_uri\u001b[38;5;241m=\u001b[39mdatabricks_profile_uri \u001b[38;5;129;01mor\u001b[39;00m tracking_uri,\n\u001b[0;32m     53\u001b[0m )\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m RunsArtifactRepository\u001b[38;5;241m.\u001b[39mis_runs_uri(uri)  \u001b[38;5;66;03m# avoid an infinite loop\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m add_databricks_profile_info_to_artifact_uri(\n\u001b[0;32m     56\u001b[0m     artifact_uri\u001b[38;5;241m=\u001b[39muri, databricks_profile_uri\u001b[38;5;241m=\u001b[39mdatabricks_profile_uri \u001b[38;5;129;01mor\u001b[39;00m tracking_uri\n\u001b[0;32m     57\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\tracking\\artifact_utils.py:53\u001b[0m, in \u001b[0;36mget_artifact_uri\u001b[1;34m(run_id, artifact_path, tracking_uri)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m     48\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA run_id must be specified in order to obtain an artifact uri!\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     49\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[0;32m     50\u001b[0m     )\n\u001b[0;32m     52\u001b[0m store \u001b[38;5;241m=\u001b[39m _get_store(tracking_uri)\n\u001b[1;32m---> 53\u001b[0m run \u001b[38;5;241m=\u001b[39m store\u001b[38;5;241m.\u001b[39mget_run(run_id)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Maybe move this method to RunsArtifactRepository so the circular dependency is clearer.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39murlparse(run\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39martifact_uri)\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# avoid an infinite loop\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\store\\tracking\\file_store.py:741\u001b[0m, in \u001b[0;36mFileStore.get_run\u001b[1;34m(self, run_id)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id):\n\u001b[0;32m    738\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;124;03m    Note: Will get both active and deleted runs.\u001b[39;00m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 741\u001b[0m     _validate_run_id(run_id)\n\u001b[0;32m    742\u001b[0m     run_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_run_info(run_id)\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m run_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\utils\\validation.py:393\u001b[0m, in \u001b[0;36m_validate_run_id\u001b[1;34m(run_id, path)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that `run_id` is a valid run ID and raise an exception if it isn't.\"\"\"\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _RUN_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(run_id) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 393\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(invalid_value(path, run_id), error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE)\n",
      "\u001b[1;31mMlflowException\u001b[0m: Invalid value \"<run_id>\" for parameter 'run_id' supplied."
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "model_uri = \"runs:/<run_id>/pyfunc_model\"   # copy from printed output\n",
    "loaded = mlflow.pyfunc.load_model(model_uri)\n",
    "# assume you have a test dataframe X_test_proc prepared\n",
    "preds = loaded.predict(X_test_proc.head(5))\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "504513a4-b496-47e2-9498-18b62a5043e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1778d032e76941c999c5f06ebb27f9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e0d8e964a542e1bd2c210b9b92b6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: runs:/3288d4ed01ec451996e2984522afb8c3/pyfunc_model\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "train and valid dataset categorical_feature do not match.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m X_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(sample)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# call model.predict (pyfunc expects DataFrame)\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m preds \u001b[38;5;241m=\u001b[39m loaded\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPred:\u001b[39m\u001b[38;5;124m\"\u001b[39m, preds)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\pyfunc\\__init__.py:846\u001b[0m, in \u001b[0;36mPyFuncModel.predict\u001b[1;34m(self, data, params)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id:\n\u001b[0;32m    845\u001b[0m     context\u001b[38;5;241m.\u001b[39mupdate(model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id)\n\u001b[1;32m--> 846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(data, params)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\pyfunc\\__init__.py:896\u001b[0m, in \u001b[0;36mPyFuncModel._predict\u001b[1;34m(self, data, params)\u001b[0m\n\u001b[0;32m    894\u001b[0m params_arg \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_fn)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m params_arg \u001b[38;5;129;01mand\u001b[39;00m params_arg\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m!=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mParameter\u001b[38;5;241m.\u001b[39mVAR_KEYWORD:\n\u001b[1;32m--> 896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_fn(data, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m    898\u001b[0m _log_warning_if_params_not_in_predict_signature(_logger, params)\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_fn(data)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\pyfunc\\model.py:1539\u001b[0m, in \u001b[0;36m_PythonModelPyfuncWrapper.predict\u001b[1;34m(self, model_input, params)\u001b[0m\n\u001b[0;32m   1537\u001b[0m     _log_warning_if_params_not_in_predict_signature(_logger, params)\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_context_in_predict_function_signature(parameters\u001b[38;5;241m=\u001b[39mparameters):\n\u001b[1;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_model\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(model_input), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1541\u001b[0m     )\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(model_input), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\pyfunc\\utils\\data_validation.py:77\u001b[0m, in \u001b[0;36m_wrap_predict_with_pyfunc.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[28], line 21\u001b[0m, in \u001b[0;36mSklearnWrapper.predict\u001b[1;34m(self, context, model_input)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, context, model_input):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# model_input is a pandas DataFrame; return numpy array or pd.Series\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(model_input)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\lightgbm\\basic.py:4767\u001b[0m, in \u001b[0;36mBooster.predict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features, **kwargs)\u001b[0m\n\u001b[0;32m   4765\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4766\u001b[0m         num_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 4767\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictor\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m   4768\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m   4769\u001b[0m     start_iteration\u001b[38;5;241m=\u001b[39mstart_iteration,\n\u001b[0;32m   4770\u001b[0m     num_iteration\u001b[38;5;241m=\u001b[39mnum_iteration,\n\u001b[0;32m   4771\u001b[0m     raw_score\u001b[38;5;241m=\u001b[39mraw_score,\n\u001b[0;32m   4772\u001b[0m     pred_leaf\u001b[38;5;241m=\u001b[39mpred_leaf,\n\u001b[0;32m   4773\u001b[0m     pred_contrib\u001b[38;5;241m=\u001b[39mpred_contrib,\n\u001b[0;32m   4774\u001b[0m     data_has_header\u001b[38;5;241m=\u001b[39mdata_has_header,\n\u001b[0;32m   4775\u001b[0m     validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   4776\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\lightgbm\\basic.py:1158\u001b[0m, in \u001b[0;36m_InnerPredictor.predict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     _safe_call(\n\u001b[0;32m   1150\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mLGBM_BoosterValidateFeatureNames(\n\u001b[0;32m   1151\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m         )\n\u001b[0;32m   1155\u001b[0m     )\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd_DataFrame):\n\u001b[1;32m-> 1158\u001b[0m     data \u001b[38;5;241m=\u001b[39m _data_from_pandas(\n\u001b[0;32m   1159\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m   1160\u001b[0m         feature_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m         categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1162\u001b[0m         pandas_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_categorical,\n\u001b[0;32m   1163\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1165\u001b[0m predict_type \u001b[38;5;241m=\u001b[39m _C_API_PREDICT_NORMAL\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raw_score:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\lightgbm\\basic.py:851\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cat_cols) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(pandas_categorical):\n\u001b[1;32m--> 851\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain and valid dataset categorical_feature do not match.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col, category \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(cat_cols, pandas_categorical):\n\u001b[0;32m    853\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(data[col]\u001b[38;5;241m.\u001b[39mcat\u001b[38;5;241m.\u001b[39mcategories) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m(category):\n",
      "\u001b[1;31mValueError\u001b[0m: train and valid dataset categorical_feature do not match."
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "# replace this with the exact model_uri printed earlier\n",
    "model_uri = \"runs:/3288d4ed01ec451996e2984522afb8c3/pyfunc_model\"\n",
    "\n",
    "# set tracking URI to your local mlruns folder (same as when you logged)\n",
    "mlflow.set_tracking_uri(\"file:///C:/Users/shail_u9zs758/mlruns\")\n",
    "\n",
    "# load the model (pyfunc)\n",
    "loaded = mlflow.pyfunc.load_model(model_uri)\n",
    "print(\"Loaded model:\", model_uri)\n",
    "\n",
    "# prepare a tiny test DataFrame matching the features expected by the model\n",
    "# Use the numeric + categorical feature names you logged earlier\n",
    "sample = {\n",
    "    'distance_km': [8.5],\n",
    "    'order_to_pickup_mins': [6],\n",
    "    'Agent_Age': [34],\n",
    "    'Agent_Rating_imputed': [4.5],\n",
    "    'hour_sin': [0.5],\n",
    "    'hour_cos': [0.866],\n",
    "    'Weather_imputed': ['Sunny'],\n",
    "    'Traffic': ['Low'],\n",
    "    'Vehicle': ['motorcycle'],\n",
    "    'Area': ['Metropolitian'],\n",
    "    'Category_grp': ['Clothing'],\n",
    "    'part_of_day': ['afternoon'],\n",
    "    'distance_bucket': ['short'],\n",
    "    'Traffic_Weather': ['Low_Sunny'],\n",
    "    'Area_PartOfDay': ['Metropolitian_afternoon'],\n",
    "    'CatTraffic': ['Clothing_Low']\n",
    "}\n",
    "X_test = pd.DataFrame(sample)\n",
    "\n",
    "# call model.predict (pyfunc expects DataFrame)\n",
    "preds = loaded.predict(X_test)\n",
    "print(\"Pred:\", preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c21230e-797d-4e55-8925-39e5cfcb0100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/27 23:10:34 WARNING mlflow.tracing.provider: An error occurred while disabling or re-enabling tracing: file://C:/Users/shail_u9zs758/mlruns is not a valid remote uri. For remote access on windows, please consider using a different scheme such as SMB (e.g. smb://<hostname>/<path>). The original function will still be executed, but the tracing state may not be as expected. For full traceback, set logging level to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved category levels for columns: ['Weather_imputed', 'Traffic', 'Vehicle', 'Area', 'Category_grp', 'part_of_day', 'distance_bucket', 'Traffic_Weather', 'Area_PartOfDay', 'CatTraffic']\n",
      "Wrote: category_levels.json\n",
      "Overwrote wrapper: predict_wrapper.py\n",
      "\\nAttempting quick test using mlflow.pyfunc.load_model(MODEL_URI) ...\n",
      "Loaded model: runs:/3288d4ed01ec451996e2984522afb8c3/pyfunc_model\n",
      "Test prediction (pyfunc_model via wrapper) -> 154.65189926108243\n",
      "\\nDone. Files updated:\n",
      " - category_levels.json\n",
      " - predict_wrapper.py\n",
      "\\nNow our wrapper will cast categorical columns to the exact training categories before prediction.\n"
     ]
    }
   ],
   "source": [
    "# === Fix LightGBM categorical mismatch: save training categories + overwrite wrapper ===\n",
    "import os, json, joblib, traceback\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "# Files and vars\n",
    "CLEAN_IN = 'amazon_delivery_cleaned.csv'\n",
    "CATEGORY_LEVELS_FILE = 'category_levels.json'\n",
    "IMPUTER_FILE = 'preprocessor_imputer.joblib'\n",
    "SCALER_FILE = 'preprocessor_scaler.joblib'\n",
    "MODEL_JOBLIB = 'lgbm_native_cat_model_booster.joblib'  # used by wrapper path\n",
    "WRAPPER_FILE = 'predict_wrapper.py'\n",
    "MODEL_URI = \"runs:/3288d4ed01ec451996e2984522afb8c3/pyfunc_model\"  \n",
    "\n",
    "# 1) Extract training category levels from the cleaned dataset\n",
    "if not os.path.exists(CLEAN_IN):\n",
    "    raise FileNotFoundError(f\"{CLEAN_IN} not found in cwd: {os.getcwd()}\")\n",
    "\n",
    "df = pd.read_csv(CLEAN_IN)\n",
    "\n",
    "# define categorical features same as training\n",
    "cat_feats = [c for c in [\n",
    "    'Weather_imputed','Traffic','Vehicle','Area','Category_grp','part_of_day',\n",
    "    'distance_bucket','Traffic_Weather','Area_PartOfDay','CatTraffic','agent_experience_bucket'\n",
    "] if c in df.columns]\n",
    "\n",
    "category_levels = {}\n",
    "for c in cat_feats:\n",
    "    # treat column as categorical exactly as used in training\n",
    "    series = df[c].astype('category')\n",
    "    # convert NaN to a string placeholder? Keep NaN as missing  we only store levels\n",
    "    levels = [str(x) for x in series.cat.categories.tolist()]\n",
    "    category_levels[c] = levels\n",
    "\n",
    "# save to json\n",
    "with open(CATEGORY_LEVELS_FILE, 'w') as f:\n",
    "    json.dump(category_levels, f, indent=2)\n",
    "print(\"Saved category levels for columns:\", list(category_levels.keys()))\n",
    "print(\"Wrote:\", CATEGORY_LEVELS_FILE)\n",
    "\n",
    "# 2) Overwrite predict_wrapper.py with robust casting using saved category_levels.json\n",
    "wrapper_code = f'''\n",
    "import joblib, json, pandas as pd, numpy as np, os\n",
    "# Files expected to be in same working directory\n",
    "MODEL_FILE = \"{MODEL_JOBLIB}\"\n",
    "IMPUTER_FILE = \"{IMPUTER_FILE}\"\n",
    "SCALER_FILE = \"{SCALER_FILE}\"\n",
    "CATEGORY_LEVELS = \"{CATEGORY_LEVELS_FILE}\"\n",
    "\n",
    "# lazy-loaded artifacts\n",
    "_model = None\n",
    "_imputer = None\n",
    "_scaler = None\n",
    "_cat_levels = None\n",
    "\n",
    "def _load_artifacts():\n",
    "    global _model, _imputer, _scaler, _cat_levels\n",
    "    if _model is None:\n",
    "        # try to load model from file if present, else fallback to mlflow pyfunc load if MODEL_FILE is not an absolute joblib\n",
    "        if os.path.exists(MODEL_FILE):\n",
    "            _model = joblib.load(MODEL_FILE)\n",
    "        else:\n",
    "            # leave None; user should load via mlflow if using model_uri approach\n",
    "            _model = None\n",
    "    if _imputer is None and os.path.exists(IMPUTER_FILE):\n",
    "        _imputer = joblib.load(IMPUTER_FILE)\n",
    "        _scaler = joblib.load(SCALER_FILE)\n",
    "    if _cat_levels is None and os.path.exists(CATEGORY_LEVELS):\n",
    "        with open(CATEGORY_LEVELS, 'r') as f:\n",
    "            _cat_levels = json.load(f)\n",
    "    return _model, _imputer, _scaler, _cat_levels\n",
    "\n",
    "def _prepare_input(df):\n",
    "    \\\"\\\"\\\"Accept DataFrame or dict. Ensures numeric imputation/scaling and categorical casting to original training categories.\\\"\\\"\\\"\n",
    "    if isinstance(df, dict):\n",
    "        df = pd.DataFrame([df])\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"Input must be a pandas DataFrame or a dict (single row).\")\n",
    "    model, imputer, scaler, cat_levels = _load_artifacts()\n",
    "    # numeric columns: detect those that are present in imputer/scaler training (we saved features list previously)\n",
    "    # we will assume the saved imputer/scaler were fit on the same numeric column order used in training\n",
    "    if imputer is not None:\n",
    "        # get numeric feature names from imputer if available (imputer doesn't store names). \n",
    "        # So rely on user to pass exactly the numeric columns used during training.\n",
    "        # We'll select numeric columns as those in df that are not in cat_levels keys.\n",
    "        num_cols = [c for c in df.columns if c not in (cat_levels.keys() if cat_levels else [])]\n",
    "        if len(num_cols) > 0:\n",
    "            num_df = df[num_cols].copy()\n",
    "            num_imp = imputer.transform(num_df)\n",
    "            num_scaled = scaler.transform(num_imp)\n",
    "            num_scaled_df = pd.DataFrame(num_scaled, columns=num_cols, index=df.index)\n",
    "        else:\n",
    "            num_scaled_df = pd.DataFrame(index=df.index)\n",
    "    else:\n",
    "        num_scaled_df = pd.DataFrame(index=df.index)\n",
    "        num_cols = []\n",
    "    # categorical casting using stored categories\n",
    "    cat_df = pd.DataFrame(index=df.index)\n",
    "    if cat_levels:\n",
    "        for c, levels in cat_levels.items():\n",
    "            if c in df.columns:\n",
    "                # cast incoming values to categorical with exact training categories\n",
    "                cat_df[c] = pd.Categorical(df[c].astype(object), categories=levels)\n",
    "            else:\n",
    "                # column missing in input -> create column of NaNs with correct categorical dtype\n",
    "                cat_df[c] = pd.Series(pd.Categorical([pd.NA]*len(df), categories=levels))\n",
    "    # combine numeric + categorical (keep original column order where possible)\n",
    "    X_proc = pd.concat([num_scaled_df.reset_index(drop=True), cat_df.reset_index(drop=True)], axis=1)\n",
    "    return X_proc\n",
    "\n",
    "def predict_delivery_time(input_df_or_dict, model=None, mlflow_model=None):\n",
    "    \\\"\\\"\\\"Predict delivery time. Provide either a local joblib model (default) or an mlflow.pyfunc model object via `mlflow_model`.\\n    Returns scalar for single input dict, or numpy array for DataFrame.\\n    \\\"\\\"\\\"\n",
    "    global _model\n",
    "    # load local artifacts\n",
    "    _model, _imputer, _scaler, _cat_levels = _load_artifacts()\n",
    "    if model is not None:\n",
    "        _model = model\n",
    "    if mlflow_model is not None:\n",
    "        # mlflow_model should be result of mlflow.pyfunc.load_model(...)\n",
    "        _model = mlflow_model\n",
    "    if _model is None:\n",
    "        raise ValueError(\"No model loaded. Ensure MODEL_FILE exists or pass `mlflow_model` loaded via mlflow.pyfunc.load_model(model_uri).\")\n",
    "    X_proc = _prepare_input(input_df_or_dict)\n",
    "    # LightGBM booster requires categorical columns with .dtype == 'category' and matching categories - done above\n",
    "    preds = _model.predict(X_proc)\n",
    "    if isinstance(input_df_or_dict, dict):\n",
    "        return float(preds[0])\n",
    "    return preds\n",
    "'''\n",
    "\n",
    "with open(WRAPPER_FILE, 'w') as f:\n",
    "    f.write(wrapper_code)\n",
    "print(\"Overwrote wrapper:\", WRAPPER_FILE)\n",
    "\n",
    "# 3) Quick test: load the pyfunc model (logged earlier) and run a sample prediction\n",
    "print(\"\\\\nAttempting quick test using mlflow.pyfunc.load_model(MODEL_URI) ...\")\n",
    "try:\n",
    "    mlflow.set_tracking_uri(\"file://\" + str(Path(os.path.abspath('mlruns')).as_posix()))\n",
    "except Exception:\n",
    "    try:\n",
    "        mlflow.set_tracking_uri(mlflow.get_tracking_uri())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# try to load pyfunc model if available\n",
    "try:\n",
    "    loaded = mlflow.pyfunc.load_model(MODEL_URI)\n",
    "    print(\"Loaded model:\", MODEL_URI)\n",
    "    # construct a sample dict; ensure keys match saved category_levels keys\n",
    "    sample = {}\n",
    "    # pick numerical and categorical columns from our saved sets\n",
    "    df0 = pd.read_csv(CLEAN_IN, nrows=1)\n",
    "    # fill numeric sample with median-ish values\n",
    "    for c in df0.columns:\n",
    "        if c in df0.select_dtypes(include=['number']).columns:\n",
    "            sample[c] = float(df0[c].iloc[0]) if pd.notna(df0[c].iloc[0]) else 0.0\n",
    "    # for each categorical, pick first training level (safe)\n",
    "    for c in cat_feats:\n",
    "        if c in df0.columns:\n",
    "            sample[c] = category_levels[c][0] if len(category_levels[c])>0 else None\n",
    "    # reduce sample to expected features (num + cat)\n",
    "    # create minimal sample that matches previously used features:\n",
    "    demo = {}\n",
    "    # numeric features explicitly used earlier (keep same names)\n",
    "    num_list = ['distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed','hour_sin','hour_cos']\n",
    "    for c in num_list:\n",
    "        if c in df0.columns:\n",
    "            demo[c] = float(df0[c].iloc[0]) if pd.notna(df0[c].iloc[0]) else 0.0\n",
    "    for c in cat_feats:\n",
    "        demo[c] = category_levels[c][0] if len(category_levels[c])>0 else None\n",
    "\n",
    "    # now use the wrapper via import\n",
    "    from importlib import reload\n",
    "    import predict_wrapper as pw\n",
    "    reload(pw)\n",
    "    pred = pw.predict_delivery_time(demo, mlflow_model=loaded)\n",
    "    print(\"Test prediction (pyfunc_model via wrapper) ->\", pred)\n",
    "except Exception as e:\n",
    "    print(\"Quick test failed; traceback below:\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\\\nDone. Files updated:\")\n",
    "print(\" -\", CATEGORY_LEVELS_FILE)\n",
    "print(\" -\", WRAPPER_FILE)\n",
    "print(\"\\\\nNow our wrapper will cast categorical columns to the exact training categories before prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2166354c-25e6-4216-a746-6a0ab6f1d283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91b15b64e4349a28d2cc7663a78c2cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbb9dd711cb42efb5d529f357db5aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted minutes: 115.01190596240998\n"
     ]
    }
   ],
   "source": [
    "import mlflow, pandas as pd\n",
    "mlflow.set_tracking_uri(\"file:///C:/Users/shail_u9zs758/mlruns\")\n",
    "\n",
    "model_uri = \"runs:/3288d4ed01ec451996e2984522afb8c3/pyfunc_model\"\n",
    "loaded = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "# prepare one-row DataFrame with exact columns (wrapper will cast categories)\n",
    "sample = pd.DataFrame([{\n",
    "    'distance_km': 8.5,\n",
    "    'order_to_pickup_mins': 6,\n",
    "    'Agent_Age': 34,\n",
    "    'Agent_Rating_imputed': 4.5,\n",
    "    'hour_sin': 0.5,\n",
    "    'hour_cos': 0.866,\n",
    "    'Weather_imputed': 'Sunny',\n",
    "    'Traffic': 'Low',\n",
    "    'Vehicle': 'motorcycle',\n",
    "    'Area': 'Metropolitian',\n",
    "    'Category_grp': 'Clothing',\n",
    "    'part_of_day': 'afternoon',\n",
    "    'distance_bucket': 'short',\n",
    "    'Traffic_Weather': 'Low_Sunny',\n",
    "    'Area_PartOfDay': 'Metropolitian_afternoon',\n",
    "    'CatTraffic': 'Clothing_Low'\n",
    "}])\n",
    "\n",
    "# Option A: call loaded pyfunc model directly (make sure categories match)\n",
    "# preds = loaded.predict(sample)\n",
    "\n",
    "# Option B (recommended): use the wrapper (handles categories + numeric scaling)\n",
    "from predict_wrapper import predict_delivery_time\n",
    "pred = predict_delivery_time(sample.to_dict(orient='records')[0], mlflow_model=loaded)\n",
    "print(\"Predicted minutes:\", pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbf4a6e-a1fb-48b6-a739-194d7a122625",
   "metadata": {},
   "source": [
    "## Model packaging & validation\n",
    "\n",
    "**Artifacts produced**\n",
    "- `lgbm_native_cat_model_booster.joblib` (LightGBM booster)\n",
    "- `preprocessor_imputer.joblib`, `preprocessor_scaler.joblib` (numeric preprocessing)\n",
    "- `category_levels.json` (exact training categories for each categorical column)\n",
    "- `predict_wrapper.py` (inference wrapper)\n",
    "\n",
    "**Verification**\n",
    "- Pyfunc model URI: `runs:/3288d4ed01ec451996e2984522afb8c3/pyfunc_model`\n",
    "- Quick test prediction (via wrapper + pyfunc): `154.65` (minutes) on a basic sample input  this confirms the wrapper casts categorical columns to the training categories and the model predicts successfully.\n",
    "\n",
    "**Notes**\n",
    "- The wrapper converts incoming categorical columns to `pd.Categorical(..., categories=training_levels)` so unseen levels become missing (handled by the model). Keep `category_levels.json` with your model version.\n",
    "- For production serving, use the wrapper or load the pyfunc model via `mlflow.pyfunc.load_model(model_uri)` and call `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "707e325e-4ed2-4e55-8890-7f772a77ee0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working dir: C:\\Users\\shail_u9zs758\n",
      "\n",
      "Current artifact presence:\n",
      " - lgbm_native_cat_model_booster.joblib: FOUND\n",
      " - preprocessor_imputer.joblib: FOUND\n",
      " - preprocessor_scaler.joblib: FOUND\n",
      " - category_levels.json: FOUND\n",
      " - amazon_delivery_cleaned.csv: FOUND\n",
      " - predict_wrapper.py: FOUND\n",
      " - shap_native_outputs: FOUND\n",
      "\n",
      "All artifacts present - no search needed.\n",
      "\n",
      "Wrote sample batch CSV: C:\\Users\\shail_u9zs758\\sample_batch_input.csv\n",
      "\n",
      "Final artifact presence after attempted fixes:\n",
      " - lgbm_native_cat_model_booster.joblib: FOUND\n",
      " - preprocessor_imputer.joblib: FOUND\n",
      " - preprocessor_scaler.joblib: FOUND\n",
      " - category_levels.json: FOUND\n",
      " - amazon_delivery_cleaned.csv: FOUND\n",
      " - predict_wrapper.py: FOUND\n",
      " - shap_native_outputs: FOUND\n",
      "\n",
      "If key artifacts are still missing:\n",
      " - Check where training / packaging code ran and copy these files into the Streamlit folder:\n",
      "   * lgbm_native_cat_model_booster.joblib\n",
      "   * preprocessor_imputer.joblib\n",
      "   * preprocessor_scaler.joblib\n",
      "   * category_levels.json  (or amazon_delivery_cleaned.csv to recreate it)\n",
      "   * predict_wrapper.py\n"
     ]
    }
   ],
   "source": [
    "# C:\\Users\\shail_u9zs758\\OneDrive\\Desktop\\Amazon Delivery Time Prediction\n",
    "# It will:\n",
    "# - print which expected artifacts are present\n",
    "# - search common parent folders for missing artifacts\n",
    "# - if needed recreate category_levels.json from amazon_delivery_cleaned.csv\n",
    "# - create a sample_batch.csv with the correct feature columns for testing\n",
    "\n",
    "import os, shutil, json, fnmatch\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "cwd = Path.cwd()\n",
    "print(\"Working dir:\", cwd)\n",
    "\n",
    "# expected artifact filenames (must match app)\n",
    "expected = {\n",
    "    \"model\": \"lgbm_native_cat_model_booster.joblib\",\n",
    "    \"imputer\": \"preprocessor_imputer.joblib\",\n",
    "    \"scaler\": \"preprocessor_scaler.joblib\",\n",
    "    \"cat_levels\": \"category_levels.json\",\n",
    "    \"cleaned_csv\": \"amazon_delivery_cleaned.csv\",\n",
    "    \"wrapper\": \"predict_wrapper.py\",\n",
    "    \"shap_dir\": \"shap_native_outputs\"\n",
    "}\n",
    "\n",
    "def exists(name):\n",
    "    return (cwd / name).exists()\n",
    "\n",
    "print(\"\\nCurrent artifact presence:\")\n",
    "for k,v in expected.items():\n",
    "    print(f\" - {v}: {'FOUND' if exists(v) else 'MISSING'}\")\n",
    "\n",
    "# If anything missing, try to search parent folders up to user home for files with those names\n",
    "missing = [v for v in expected.values() if not exists(v)]\n",
    "if missing:\n",
    "    print(\"\\nSearching parent folders for missing artifacts (this may take 5-30s)...\")\n",
    "    home = Path.home()\n",
    "    # limit search to home and its subfolders but avoid scanning entire disk - sensible depth\n",
    "    found_any = []\n",
    "    for root, dirs, files in os.walk(home):\n",
    "        # skip very large folders like node_modules or .git to speed up\n",
    "        if 'node_modules' in root or '.git' in root:\n",
    "            continue\n",
    "        for name in missing:\n",
    "            if name in files:\n",
    "                src = Path(root) / name\n",
    "                dest = cwd / name\n",
    "                try:\n",
    "                    shutil.copy2(src, dest)\n",
    "                    print(f\"Copied {name} from {src} -> {dest}\")\n",
    "                    found_any.append(name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to copy {src}: {e}\")\n",
    "        # stop early if all found\n",
    "        missing = [v for v in expected.values() if not exists(v)]\n",
    "        if not missing:\n",
    "            break\n",
    "    if not found_any:\n",
    "        print(\"No missing artifacts were found automatically under your home folder.\")\n",
    "else:\n",
    "    print(\"\\nAll artifacts present - no search needed.\")\n",
    "\n",
    "# If category_levels.json still missing but cleaned CSV exists, recreate category_levels.json\n",
    "if not exists(expected[\"cat_levels\"]) and exists(expected[\"cleaned_csv\"]):\n",
    "    try:\n",
    "        df = pd.read_csv(cwd / expected[\"cleaned_csv\"])\n",
    "        # define same cat features as app expects (fallback)\n",
    "        cat_feats = [c for c in [\n",
    "            'Weather_imputed','Traffic','Vehicle','Area','Category_grp','part_of_day',\n",
    "            'distance_bucket','Traffic_Weather','Area_PartOfDay','CatTraffic','agent_experience_bucket'\n",
    "        ] if c in df.columns]\n",
    "        cat_levels = {}\n",
    "        for c in cat_feats:\n",
    "            cat_levels[c] = [str(x) for x in df[c].astype('category').cat.categories.tolist()]\n",
    "        with open(cwd / expected[\"cat_levels\"], 'w') as f:\n",
    "            json.dump(cat_levels, f, indent=2)\n",
    "        print(f\"Recreated {expected['cat_levels']} from {expected['cleaned_csv']}\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not recreate category_levels.json:\", e)\n",
    "\n",
    "# If category_levels.json missing and cleaned CSV missing, instruct user where to look\n",
    "if not exists(expected[\"cat_levels\"]) and not exists(expected[\"cleaned_csv\"]):\n",
    "    print(\"\\ncategory_levels.json and amazon_delivery_cleaned.csv are both missing.\")\n",
    "    print(\"If we have original project folder (where training happened), copy those two files into this Streamlit folder.\")\n",
    "    print(\"Use Windows Explorer search to find 'amazon_delivery_cleaned.csv' or run a manual search from parent project folders.\")\n",
    "\n",
    "# Create a sample batch CSV in this folder to test batch upload\n",
    "sample_csv_path = cwd / \"sample_batch_input.csv\"\n",
    "if exists(expected[\"cat_levels\"]):\n",
    "    with open(cwd / expected[\"cat_levels\"], 'r') as f:\n",
    "        cat_levels = json.load(f)\n",
    "else:\n",
    "    cat_levels = {}\n",
    "\n",
    "# numeric features used earlier\n",
    "num_fields = ['distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed','hour_sin','hour_cos']\n",
    "cat_fields = list(cat_levels.keys()) if cat_levels else ['Weather_imputed','Traffic','Vehicle','Area','Category_grp','part_of_day','distance_bucket','Traffic_Weather','Area_PartOfDay','CatTraffic']\n",
    "\n",
    "# build one sample row using first available category levels or 'unknown'\n",
    "row = {}\n",
    "for c in num_fields:\n",
    "    row[c] = 10.0 if 'age' not in c.lower() else 30.0\n",
    "for c in cat_fields:\n",
    "    if c in cat_levels and isinstance(cat_levels[c], list) and len(cat_levels[c])>0:\n",
    "        row[c] = cat_levels[c][0]\n",
    "    else:\n",
    "        row[c] = 'unknown'\n",
    "\n",
    "pd.DataFrame([row]).to_csv(sample_csv_path, index=False)\n",
    "print(\"\\nWrote sample batch CSV:\", sample_csv_path)\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\nFinal artifact presence after attempted fixes:\")\n",
    "for k,v in expected.items():\n",
    "    print(f\" - {v}: {'FOUND' if exists(v) else 'MISSING'}\")\n",
    "\n",
    "print(\"\\nIf key artifacts are still missing:\")\n",
    "print(\" - Check where training / packaging code ran and copy these files into the Streamlit folder:\")\n",
    "print(\"   * lgbm_native_cat_model_booster.joblib\")\n",
    "print(\"   * preprocessor_imputer.joblib\")\n",
    "print(\"   * preprocessor_scaler.joblib\")\n",
    "print(\"   * category_levels.json  (or amazon_delivery_cleaned.csv to recreate it)\")\n",
    "print(\"   * predict_wrapper.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b6ff9de-71d3-46f1-888e-e1a9a8f991e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working dir: C:\\Users\\shail_u9zs758\n",
      "Created holdout test set shape: (8748, 35) using target: Delivery_Time\n",
      "Using features: ['distance_km', 'order_to_pickup_mins', 'Agent_Age', 'Agent_Rating_imputed', 'hour_sin', 'hour_cos', 'Weather_imputed', 'Traffic', 'Vehicle', 'Area', 'Category_grp', 'part_of_day', 'distance_bucket', 'Traffic_Weather', 'Area_PartOfDay', 'CatTraffic']\n",
      "Loading local joblib model: lgbm_native_cat_model_booster.joblib\n",
      "Overall test metrics: MAE=23.443, RMSE=33.347, R2=0.5810\n",
      "Saved segmented errors to: C:\\Users\\shail_u9zs758\\analysis_outputs\\segmented_errors.csv\n",
      "Saved plot: C:\\Users\\shail_u9zs758\\analysis_outputs\\segmented_errors_by_Area.png\n",
      "Saved plot: C:\\Users\\shail_u9zs758\\analysis_outputs\\segmented_errors_by_Category_grp.png\n",
      "Saved plot: C:\\Users\\shail_u9zs758\\analysis_outputs\\segmented_errors_by_Vehicle.png\n",
      "Segmented analysis complete. Overall metrics and CSV/plots written to: C:\\Users\\shail_u9zs758\\analysis_outputs\n"
     ]
    }
   ],
   "source": [
    "# ---------- Segmented error analysis (compatibility-fixed) ----------\n",
    "import os, joblib, json, warnings\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# CONFIG\n",
    "CLEANED_CSV = \"amazon_delivery_cleaned.csv\"\n",
    "TEST_CSV = \"amazon_delivery_test.csv\"   \n",
    "MODEL_JOBLIB = \"lgbm_native_cat_model_booster.joblib\"\n",
    "MLFLOW_MODEL_URI_FALLBACK = \"runs:/3288d4ed01ec451996e2984522afb8c3/pyfunc_model\"  \n",
    "\n",
    "OUT_DIR = Path.cwd() / \"analysis_outputs\"\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Working dir:\", Path.cwd())\n",
    "\n",
    "# ---------- Load dataset ----------\n",
    "if Path(TEST_CSV).exists():\n",
    "    df_test = pd.read_csv(TEST_CSV)\n",
    "    print(\"Loaded test set from\", TEST_CSV, \"shape:\", df_test.shape)\n",
    "else:\n",
    "    if not Path(CLEANED_CSV).exists():\n",
    "        raise FileNotFoundError(f\"{CLEANED_CSV} not found in working dir. Place your cleaned CSV here.\")\n",
    "    df = pd.read_csv(CLEANED_CSV)\n",
    "    # find target column\n",
    "    possible_targets = ['Delivery_Time','delivery_time','DeliveryTime','deliveryTime','target']\n",
    "    target_col = next((c for c in possible_targets if c in df.columns), None)\n",
    "    if target_col is None:\n",
    "        raise ValueError(\"Target column not found. Expected one of: \" + \", \".join(possible_targets))\n",
    "    strat_col = 'Category_grp' if 'Category_grp' in df.columns else None\n",
    "    if strat_col:\n",
    "        train, df_test = train_test_split(df, test_size=0.20, random_state=42, stratify=df[strat_col])\n",
    "    else:\n",
    "        train, df_test = train_test_split(df, test_size=0.20, random_state=42)\n",
    "    print(\"Created holdout test set shape:\", df_test.shape, \"using target:\", target_col)\n",
    "\n",
    "# ---------- Prepare features for prediction ----------\n",
    "numeric_features = ['distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed','hour_sin','hour_cos']\n",
    "categorical_features = ['Weather_imputed','Traffic','Vehicle','Area','Category_grp','part_of_day','distance_bucket','Traffic_Weather','Area_PartOfDay','CatTraffic']\n",
    "\n",
    "num_feats = [c for c in numeric_features if c in df_test.columns]\n",
    "cat_feats = [c for c in categorical_features if c in df_test.columns]\n",
    "features = num_feats + cat_feats\n",
    "print(\"Using features:\", features)\n",
    "\n",
    "# Drop rows with missing target for evaluation\n",
    "df_test = df_test.dropna(subset=[target_col]).reset_index(drop=True)\n",
    "X_test = df_test[features].copy()\n",
    "y_test = df_test[target_col].copy()\n",
    "\n",
    "# ---------- Load model ----------\n",
    "model = None\n",
    "if Path(MODEL_JOBLIB).exists():\n",
    "    print(\"Loading local joblib model:\", MODEL_JOBLIB)\n",
    "    model = joblib.load(MODEL_JOBLIB)\n",
    "else:\n",
    "    try:\n",
    "        import mlflow\n",
    "        print(\"Local joblib not found. Attempting to load MLflow pyfunc model:\", MLFLOW_MODEL_URI_FALLBACK)\n",
    "        mlflow.set_tracking_uri(\"file://\" + str(Path.cwd() / \"mlruns\"))\n",
    "        model = mlflow.pyfunc.load_model(MLFLOW_MODEL_URI_FALLBACK)\n",
    "    except Exception as e:\n",
    "        print(\"No local model and MLflow load failed:\", e)\n",
    "        raise FileNotFoundError(\"No model available. Place joblib model in folder or adjust MLFLOW_MODEL_URI_FALLBACK.\")\n",
    "\n",
    "# ---------- Prepare X_test for model.predict ----------\n",
    "cat_levels_file = Path(\"category_levels.json\")\n",
    "if cat_levels_file.exists():\n",
    "    with open(cat_levels_file, 'r') as f:\n",
    "        cat_levels = json.load(f)\n",
    "else:\n",
    "    cat_levels = {}\n",
    "\n",
    "for c in cat_feats:\n",
    "    if c in cat_levels:\n",
    "        X_test[c] = pd.Categorical(X_test[c].astype(object), categories=cat_levels[c])\n",
    "    else:\n",
    "        X_test[c] = X_test[c].astype('category')\n",
    "\n",
    "# For numeric columns, apply imputer/scaler if they exist\n",
    "imputer_file = Path(\"preprocessor_imputer.joblib\")\n",
    "scaler_file = Path(\"preprocessor_scaler.joblib\")\n",
    "if imputer_file.exists() and scaler_file.exists():\n",
    "    imp = joblib.load(imputer_file)\n",
    "    sc = joblib.load(scaler_file)\n",
    "    if num_feats:\n",
    "        # suppress feature-name warning from sklearn when transformer was fit without feature names\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "            num_imp = imp.transform(X_test[num_feats])\n",
    "            num_scaled = sc.transform(num_imp)\n",
    "        Xnum = pd.DataFrame(num_scaled, columns=num_feats, index=X_test.index)\n",
    "        for c in num_feats:\n",
    "            X_test[c] = Xnum[c]\n",
    "else:\n",
    "    print(\"No imputer/scaler found: predicting with raw numeric inputs (ok if model handles).\")\n",
    "\n",
    "# ---------- Predict ----------\n",
    "# Ensure model.predict works with pandas DataFrame. For raw booster or sklearn it should.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# ---------- Metrics overall ----------\n",
    "mae_overall = mean_absolute_error(y_test, y_pred)\n",
    "# compute RMSE without using 'squared' kwarg for compatibility\n",
    "rmse_overall = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "r2_overall = r2_score(y_test, y_pred)\n",
    "print(f\"Overall test metrics: MAE={mae_overall:.3f}, RMSE={rmse_overall:.3f}, R2={r2_overall:.4f}\")\n",
    "\n",
    "# ---------- Grouped metrics ----------\n",
    "group_cols = [c for c in ['Area','Category_grp','Vehicle'] if c in df_test.columns]\n",
    "records = []\n",
    "for g in group_cols:\n",
    "    grouped = df_test.groupby(g)\n",
    "    for name, group in grouped:\n",
    "        idx = group.index\n",
    "        if len(idx) < 5:\n",
    "            continue\n",
    "        y_true_g = y_test.loc[idx]\n",
    "        X_g = X_test.loc[idx]\n",
    "        y_pred_g = model.predict(X_g)\n",
    "        mae_g = mean_absolute_error(y_true_g, y_pred_g)\n",
    "        rmse_g = float(np.sqrt(mean_squared_error(y_true_g, y_pred_g)))\n",
    "        r2_g = r2_score(y_true_g, y_pred_g)\n",
    "        records.append({\"group_by\": g, \"group\": name, \"n\": len(idx),\n",
    "                        \"MAE\": mae_g, \"RMSE\": rmse_g, \"R2\": r2_g})\n",
    "\n",
    "df_groups = pd.DataFrame.from_records(records)\n",
    "df_groups.sort_values([\"group_by\",\"MAE\"], ascending=[True,False], inplace=True)\n",
    "df_groups.to_csv(OUT_DIR / \"segmented_errors.csv\", index=False)\n",
    "print(\"Saved segmented errors to:\", OUT_DIR / \"segmented_errors.csv\")\n",
    "\n",
    "# ---------- Quick bar plots (top 10 by MAE) ----------\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "for g in ['Area','Category_grp','Vehicle']:\n",
    "    if g in group_cols:\n",
    "        d = df_groups[df_groups['group_by']==g].nlargest(10,'MAE').set_index('group').sort_values('MAE')\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.barh(d.index, d['MAE'])\n",
    "        plt.title(f\"Top groups by MAE ({g})\")\n",
    "        plt.xlabel(\"MAE (mins)\")\n",
    "        plt.tight_layout()\n",
    "        pfile = OUT_DIR / f\"segmented_errors_by_{g}.png\"\n",
    "        plt.savefig(pfile, dpi=150)\n",
    "        plt.close()\n",
    "        print(\"Saved plot:\", pfile)\n",
    "\n",
    "print(\"Segmented analysis complete. Overall metrics and CSV/plots written to:\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1ba4f8f-5b16-47d5-aef0-2d9877ab0a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmented errors CSV: C:\\Users\\shail_u9zs758\\analysis_outputs\\segmented_errors.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_by</th>\n",
       "      <th>group</th>\n",
       "      <th>n</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Area</td>\n",
       "      <td>Semi-Urban</td>\n",
       "      <td>21</td>\n",
       "      <td>26.395171</td>\n",
       "      <td>33.341428</td>\n",
       "      <td>-5.484630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Area</td>\n",
       "      <td>Metropolitian</td>\n",
       "      <td>6552</td>\n",
       "      <td>24.089104</td>\n",
       "      <td>34.437192</td>\n",
       "      <td>0.544735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Area</td>\n",
       "      <td>Other</td>\n",
       "      <td>230</td>\n",
       "      <td>22.392664</td>\n",
       "      <td>30.634176</td>\n",
       "      <td>0.612756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Area</td>\n",
       "      <td>Urban</td>\n",
       "      <td>1945</td>\n",
       "      <td>21.358767</td>\n",
       "      <td>29.726197</td>\n",
       "      <td>0.613478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Category_grp</td>\n",
       "      <td>Other</td>\n",
       "      <td>4294</td>\n",
       "      <td>29.275224</td>\n",
       "      <td>41.770416</td>\n",
       "      <td>0.428853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Category_grp</td>\n",
       "      <td>Books</td>\n",
       "      <td>565</td>\n",
       "      <td>18.671726</td>\n",
       "      <td>23.253909</td>\n",
       "      <td>0.760102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Category_grp</td>\n",
       "      <td>Toys</td>\n",
       "      <td>556</td>\n",
       "      <td>17.978178</td>\n",
       "      <td>22.812836</td>\n",
       "      <td>0.773912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Category_grp</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>570</td>\n",
       "      <td>17.827815</td>\n",
       "      <td>22.475344</td>\n",
       "      <td>0.756479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Category_grp</td>\n",
       "      <td>Snacks</td>\n",
       "      <td>554</td>\n",
       "      <td>17.804325</td>\n",
       "      <td>22.515093</td>\n",
       "      <td>0.741336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Category_grp</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>561</td>\n",
       "      <td>17.778368</td>\n",
       "      <td>22.097887</td>\n",
       "      <td>0.769189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Category_grp</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>545</td>\n",
       "      <td>17.688063</td>\n",
       "      <td>21.803703</td>\n",
       "      <td>0.781891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Category_grp</td>\n",
       "      <td>Skincare</td>\n",
       "      <td>554</td>\n",
       "      <td>17.568459</td>\n",
       "      <td>22.355833</td>\n",
       "      <td>0.776707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Category_grp</td>\n",
       "      <td>Outdoors</td>\n",
       "      <td>549</td>\n",
       "      <td>17.220380</td>\n",
       "      <td>21.863654</td>\n",
       "      <td>0.798455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Vehicle</td>\n",
       "      <td>motorcycle</td>\n",
       "      <td>5097</td>\n",
       "      <td>25.918607</td>\n",
       "      <td>36.305621</td>\n",
       "      <td>0.533727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Vehicle</td>\n",
       "      <td>van</td>\n",
       "      <td>733</td>\n",
       "      <td>21.032059</td>\n",
       "      <td>30.615673</td>\n",
       "      <td>0.575673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Vehicle</td>\n",
       "      <td>scooter</td>\n",
       "      <td>2914</td>\n",
       "      <td>19.725639</td>\n",
       "      <td>28.210674</td>\n",
       "      <td>0.650026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        group_by           group     n        MAE       RMSE        R2\n",
       "0           Area     Semi-Urban     21  26.395171  33.341428 -5.484630\n",
       "1           Area  Metropolitian   6552  24.089104  34.437192  0.544735\n",
       "2           Area           Other   230  22.392664  30.634176  0.612756\n",
       "3           Area          Urban   1945  21.358767  29.726197  0.613478\n",
       "4   Category_grp           Other  4294  29.275224  41.770416  0.428853\n",
       "5   Category_grp           Books   565  18.671726  23.253909  0.760102\n",
       "6   Category_grp            Toys   556  17.978178  22.812836  0.773912\n",
       "7   Category_grp     Electronics   570  17.827815  22.475344  0.756479\n",
       "8   Category_grp          Snacks   554  17.804325  22.515093  0.741336\n",
       "9   Category_grp         Jewelry   561  17.778368  22.097887  0.769189\n",
       "10  Category_grp         Apparel   545  17.688063  21.803703  0.781891\n",
       "11  Category_grp        Skincare   554  17.568459  22.355833  0.776707\n",
       "12  Category_grp        Outdoors   549  17.220380  21.863654  0.798455\n",
       "13       Vehicle     motorcycle   5097  25.918607  36.305621  0.533727\n",
       "14       Vehicle             van   733  21.032059  30.615673  0.575673\n",
       "15       Vehicle        scooter   2914  19.725639  28.210674  0.650026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAAJYCAYAAABy5h8aAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAXEgAAFxIBZ5/SUgAAiw9JREFUeJzs3Xd4FFXfxvF70xskAUJJKKELoYogNQlFQGqkCAgIKs0uIgKKAuoDAR9FQUUpgqgg0ptIrwIKiAgRkZZQpPeeNu8fvLsPy25CEgI7wPdzXXsJM+ec+c1kdzW3Z85YDMMwBAAAAAAAAJiUm6sLAAAAAAAAANJDgAUAAAAAAABTI8ACAAAAAACAqRFgAQAAAAAAwNQIsAAAAAAAAGBqBFgAAAAAAAAwNQIsAAAAAAAAmBoBFgAAAAAAAEyNAAsAAAAAAACmRoAFAAAAAAAAUyPAAgAAAAAAgKkRYAEAAAAAAMDUCLAAAAAAAABgagRYAAAAAAAAMDUCLAAAAAAAAJgaARYAAAAAAABMjQALAAAAAAAApkaABQAAAAAAAFMjwAIAAAAAAICpEWABAAAAAADA1AiwAAAAsqBr166yWCzq2rWrq0uBE3///bc8PT1Vrlw5paamurocIMNSU1MVEREhT09P7dq1y9XlAIBpEGABAB44Fosly69Jkya5unzglqKjo23vWQ8PDx0+fDjd9teuXVPu3LltfcLDwzN0nCeffNLWZ+DAgRnqk5nP2+DBgzM0pjN9+/ZVcnKyBg0aJDe39P+Td9GiRerRo4ciIiKUK1cueXp6Knfu3KpWrZpee+01/frrr1muIy2DBw/W4MGDFR8fn+1j497m5uamd955R8nJyXrzzTddXQ4AmIaHqwsAAOBuy5cvn9PtFy9e1KVLl9Jt4+vre8fqAu6ElJQUTZ48WQMGDEizzZw5c3T69OlMjXvq1CnNmzfP9vdJkyZpyJAhcnd3z1B/f39/BQQEpNvmVvvTsnLlSi1YsEDlypVTmzZt0mz3zz//qGPHjtq8ebNtm7u7uwIDA3Xu3Dlt2rRJmzZt0qeffqq6devqxx9/VJ48ebJU082GDBki6XrYmNHAEA+OJ598Uu+//77mzZunNWvWKDIy0tUlAYDLMQMLAPDAOXr0qNPXG2+8ccs27dq1c2HlQOZYg5GJEyem2866PzNBynfffadr166pSZMmKl68uA4fPqzFixdnuP8bb7yR5ufM2WcyM4YPHy5J6tWrlywWi9M2mzZt0qOPPqrNmzfL399fAwYM0LZt25SUlKRTp04pMTFRcXFx+s9//qN8+fJp5cqVOnToUJbqATLLzc1N3bt3lySNGDHCxdUAgDkQYAEAANynIiMjFR4ert27d2vdunVO2xw6dEhLly5VQECAWrduneGxJ0yYIEl6+umn1blzZ0nS119/fftF36b9+/dryZIl8vT0TDNwPnXqlFq1aqWzZ88qNDRUv/76q4YOHaoKFSrYAi83NzeVLVtWb731lvbt26cePXqkGYYBd0KHDh3k7u6uRYsW6cCBA64uBwBcjgALAIBM2Lp1q55++mkVKVJEPj4+Cg4OVs2aNfXJJ5/o2rVrTvtMmjTJbl2hpUuX6vHHH1dISIh8fX0VERGhDz74QFevXr2t2tasWaPmzZsrT5488vX1VenSpfX222/r4sWLDjXc6MbFyA3D0Pjx41W7dm3bmkg3r/u1atUqtW3bVmFhYfL29laePHlUv359TZw4USkpKU5ry8iC55mp8csvv1S1atUUGBionDlzqnbt2vr+++/TvT4//vijHn/8ceXLl0+enp4KCgpSyZIl1aJFC33++ee3df0zU9OZM2fk5+cni8WiH3/8Md1x33nnHVksFhUrVkyGYWS6rhuveVqzsCZNmqTU1FS1bds2w7fsbdq0Sdu3b1dgYKBatmypp59+WhaLRfPmzdOJEycyXWd2Gj9+vAzD0GOPPZbm7X4jRoywzaaaOnWqIiIi0h3Tz89PX331lcqXL2+3/ffff9d7772nyMhI23dCUFCQqlevruHDh+vixYsOY1nfy1Z169a1W/crrVlwc+bMUUxMjEJDQ+Xl5aXg4GBFRkbqyy+/VFJSUpq1G4ahiRMnqkaNGsqRI4cCAwP16KOPauzYsTIMI0OfzVmzZqlZs2bKly+fvLy8lC9fPjVr1kyzZ89Os09Gvlf69+8vi8Vyy+t//vx5BQQEZNs6hJcuXdKgQYNUpkwZ+fr6Km/evGrSpImWL18u6fpMRGfHio+Pt/2c4uPjtXfvXvXo0UNFixaVt7e33c/Oug7d4MGDlZiYqNjYWFWoUEH+/v4KDg7WY489pkWLFqVbZ758+VSvXj2lpqbaAmMAeKAZAADAMAzDGDRokCHJSOtfjyNHjjQsFoutTWBgoOHp6Wn7e4UKFYx///3Xod/EiRMNSUaRIkWMzz77zDZGUFCQ4eHhYetfuXJl4/Tp01mqfdSoUQ61eXl5GZKMMmXKGCNHjrTVcLMuXboYkoynn37aaNOmjSHJcHNzM4KDgw03Nzdj4sSJtra9e/e2HcNisRhBQUGGu7u7bVu9evWM8+fPp3mMLl26pHkON16n9Pq3a9fOrsYbz/uZZ54xUlNTHfo/++yztjaSjICAAMPPz89u2/79+zNwpbOnJmvf+vXrpzl+cnKyERYWZkgy/vOf/2SqtqioKFtt8fHxhsViMQICAoyLFy86tC1evLghyVizZo3tM+DsZ3Cjnj17GpKM7t2727ZFRkYakoyPPvoo3b7W6zJo0KBMnVNGPfzww4YkY9iwYU73JyUlGYGBgbe8/hlx4/vHzc3NCAoKsttWtmxZ49ixY3Z9XnnlFSNfvny2NsHBwUa+fPlsr0ceecSu/YULF4xmzZrZjZszZ06791iNGjWcfnckJyfb3pvWz6z1cy3J6NChQ7qfzWvXrtn1v/F7wbqtQ4cORmJiokPfjHyv7Nu3z3Yea9euTfM6jxkzxva9dunSpQz+dJw7duyYUbZsWVv9np6etp+bxWIxxowZYxQpUsSQZPfdZxiGsX//flu/77//3ggICDAkGX5+foa/v7/d58b6GRwwYIBRp04dQ5Lh4eHh8B651efg/fffNyQZ1apVu63zBoD7AQEWAAD/L70Aa/78+bZ9LVu2NPbt22cYxvVf8CZPnmzkyJHDkGTUrFnTSE5OtutrDWb8/PwMT09Po23btsaBAwcMwzCMK1euGF9++aXh7e1tSDKeeOKJTNf9yy+/2H6hfOyxx4xdu3YZhnH9F/Xp06cbuXLlMoKDg28ZDgUEBBgeHh7Gf//7X+PcuXOGYVz/5dkayo0ePdp2DXr06GEcOXLEMAzDuHjxojFy5EhbGNeuXbs0j3G7AVZgYKBhsViM999/31bj8ePHjZdeeslW26effmrXd+3atbZfnocPH26cOnXKtu/kyZPG4sWLjS5duhiHDx9O+yI7cTs1bdy40fYL8969e52OP2/ePNsvvdZrnVE3BliGYRj169d3+gv5qlWrDElGiRIlDMMwMhRgXbp0yciZM6dD6DBhwgRDkhEREZFubXcywDp37pwtUF2+fLnTNhs2bLDV8Nlnn93W8Ro0aGB8/fXXRkJCgpGUlGQYhmFcvnzZmDVrllG6dOl0P9PWGlauXJnuMWJiYmw/oylTptgC4itXrhhz5841ihUrZkgyYmJiHPoOGzbMdpzXX3/dOHnypGEY16/T0KFDbYFWWp/NPn362N6n77zzjnHmzBnDMAzj9OnTxltvvWUbu1+/fg59M/q90rhxY1vQlRZrKPnSSy+le60ywno8X19fY8KECcbVq1cNwzCMAwcOGO3atTO8vLxs4XZ6AVZAQIDx6KOPGps2bbLtt373Gsb/PoOBgYGGt7e38eWXXxpXrlyxHcsa6kky5s6dm2a9S5YssX0PXLhw4bbPHwDuZQRYAAD8v/QCLOv/sa9du7ZDQGUY/wsbJBnTp0+322cNZiQZUVFRRkpKikP/8ePH29r89ttvmarbGk6ULVvW9svYjVasWGEbO71wSJIxatQop8e4fPmykStXLtuMC2dGjRplG+fGX+puPMbtBliSjHfeecdp/06dOhmSjFy5ctl+UTQMwxg+fLghyWjYsGGax86K26nJMAyjcuXKhiSjf//+TvtaZ920atUq07XdHGB99913hiQjMjLSrt3TTz9tSP+b4ZWRAOubb74xJBnFixe3237+/HnD19fXkGRs3Lgxzf7Wa+bv728388jZyxr0ZtTy5ctt41vDmpvd+Fn75ZdfMjV+Zhw6dMjw9vY2LBaLkZCQ4LA/IwHWggULDElG/vz5jUOHDjltc/DgQcPf39+QZGzdutW2/cag8bnnnnPa98bvvJs/m4cOHbKF0gMGDHDa//XXX7fNYrp59mlGvlcMwzDmzJljC5SsAdmNtmzZYhvnzz//THOcjLCG2ZKMb7/91mF/SkqKUbduXVub9AKsIkWKpBsoWT+DkowJEyY4PZZ11mLZsmXTHOfEiRO2cVasWJHxkwWA+xBrYAEAcAt//vmn/vrrL0nX1yRyd3d3aNO8eXNVq1ZN0vU1ddIycOBAubk5/uv3mWeeUcGCBSVJP/zwQ4ZrO336tFasWCFJ6tu3r7y9vR3a1K1bV3Xq1LnlWMHBwerZs6fTfUuXLtXp06clSYMHD3ba5oUXXlCBAgUkpX8Nboevr2+aT6Z79913JV2/JkuXLrVtDwoKkiSdOHEizTW67nZN0vUn5EnX16a6eQ2jw4cP29bHSetnkhmtWrVSYGCg1qxZo71790qSLly4oJkzZ8rNzU1dunTJ8FjWtXisC7db5ciRQ0888YRdm/RcunRJx44dS/eV2Z/Xv//+K0lyd3dXrly5nLY5deqU7c9ptckOYWFhqlixogzD0Pr167M0xvjx4yVdv9ZhYWFO2xQsWFB169aVJLunQC5evFjnz5+XJL399ttO+/bp00d+fn5O982cOVPJycny8fFR//79nbYZOHCgvL29lZSUpBkzZjhtk973iiQ1a9ZMhQoV0pUrV/Ttt9867B87dqwkqUaNGg5rkGXW9OnTJV1f46pjx44O+93c3DRw4MAMjfXSSy9laM24QoUK6Zlnnkn3WH/99Ze2b9/utH+uXLls/86wvr8B4EFFgAUAwC1s3rxZkuTh4aGoqKg02z322GN27W/m4eGRZpDk5uam6OjodPs7s3XrVtvi3unVZh07PVWrVpWXl5fTfdaaChUqpFKlSjlt4+7urnr16tm1z26PPPKIcubM6XRfyZIlbSHgjcdv0KCBfHx8tHXrVtWpU0cTJkzQ/v37XVqTJD311FPKmTOnjh07pvnz59vt+/rrr5WSkqKiRYva3le3w9fXV+3bt5f0v8Xcp02bpkuXLqlhw4ZphiM327Nnj9asWSOLxeIQYEmyBWE//PCDLl++nO5YgwYNknH9boA0X2ktaJ4W6wLyQUFBaT4x0Pp5kXTbTxVMTU3VlClT1KJFCxUuXFi+vr52C7L/9ttvkmRbMD6zrE+OHDt2rPLnz5/ma9myZZKkhIQEW9/ff/9dklS4cGEVLVrU6fg5cuRQlSpVnO6zvl+rVq2a5vs7ODhYjzzyiF37m6X3vSJd/97o1q2bJGncuHF2+y5dumQLw3v06JHmGBllvSaRkZFp/uxr1aolDw+PW45Vq1atDB3Tupi7M5GRkbZjpXX93NzcFBgYKEkuf0ACALgaARYAALdw/PhxSVKePHmcznCysgYV1vY3u1V/a4iQVn9nbvyFJjQ09JZjpydv3rxp7rPWdKtxbnUNbtetju/sGhYrVkzjx49XQECANmzYoG7duqlYsWLKmzev2rVrp7lz52bpCX+3U5MkBQQE2GaBWGeZSLJ74lj37t1vO2SxevbZZyVJkydPVmpqqi3Ism7PiK+//lrS9V/eixUr5rC/QYMGCgsL04ULF2yzXe4m65Mk0/uc3fhkwhtnY2XW5cuX1aBBA3Xs2FHz58/XwYMHlZqaqly5cilfvny2p11K14OYzEpKStLJkyclSefOnUt3ppr1vG8MDa3fDel9L0hpv3+z6zOf3veKVbdu3eTh4aHt27dr48aNtu0//PCDzp8/r6CgID355JO3HOdWMnJNrE9WvZWMnJeU/vXz9vZW7ty5JaX/nenr6ytJt/2kWgC41xFgAQCQQRkNEtJql11BxI0yOpskIwGNs1sjb3a71+B2ZXXcjh07KiEhQV9++aXatWunQoUK6cSJE/rxxx8VExOjqKgo2+1Wd6smSXr++eclXb9FMz4+XpK0ZMkSJSQkyMPDw+mtR1lVrVo1lS1bVgcPHtTnn3+u9evXK1euXGrRokWG+qekpOibb76RdH1m0I0zjawvd3d3HT58WFLGbiPMbtYw4MyZM2m2iYiIsP1569atWT7Wf/7zH61cuVK+vr4aOXKkEhISdPXqVZ06dUpHjx7V0aNH9eijj0rK2OfvZjfePvnDDz/ccraaYRiaNGmSrY/1mLd6f96qttv9zGfkeyU0NNT2PrwxzLXOyOrUqVOatzpmRnZdEylj55WRY2WE9fZt6/sbAB5UBFgAANyC9f+0nzhxQteuXUuznfU2oZCQEKf7b9Xf+ot/Rv/P/s1t01sf5XbXTrEe5+DBg+m2S+saWG+TSW8Gwblz525Zx61uxUrvGubKlUs9e/bUDz/8oAMHDmjPnj3q37+/LBaL1q5dm+baXneypvLly6tmzZp2s66sv7S3bNlS+fPnz1JNabEGYtY1u5566ql0ZyvdaNGiRZl6H61du1a7d+/OfJG3wfq+u3LlSprvtUceecR2S9bs2bOzfCzrWnXvvvuuXnvtNRUuXNghrDh69GiWx/fx8bHVmdb6SOmxvt9u9TNLa//tfuYzy7om3LRp03T+/Hlt375dv/76q6TsuX1Qytg1uXbt2m3NzLtZet8PNx4rre/9q1ev2t7Lt3uNAeBeR4AFAMAtWNd4SU5O1urVq9NsZ12HpmrVqk73Jycn29a0uZlhGFqzZo3d8TKicuXKtl+aV61alWa79PZlhLWmQ4cO6Z9//nHaJiUlRStXrpTkeA2Cg4Mlpf/LsPWX1fRs3rxZFy5ccLpvz549tl8WM3INixcvrmHDhumpp56SJIdF1jPqdmuyzsL6+uuvdfjwYdt6WNn1S/uNOnfuLA8PDyUmJkrK3O2D1oDtiSee0IULF9J9Pfzww5L+d8vh3VK2bFnbn/ft2+e0jYeHh+3aLl++3Pa5y4jU1FTbn63v5cqVKzttGx8frz179qQ5lvVzm95sH+s6S9OnT7c7dkZYfwYJCQm22X03u3jxorZs2eJ0341rW6UVLp89e9Zurazb0aBBA5UoUUKXL1/W999/bwtys2PxdivrNUnve/yXX35RcnJythzPeqy0fsZr1661HSut74cb38dlypTJtroA4F5EgAUAwC1UqFDB9ovxBx984PTJaD/99JMtgOnQoUOaY/3nP/9x+ovoN998owMHDkiS2rVrl+HacuXKZXsC2UcffWQLJm60Zs0arV27NsNjOvPYY4/Zbl9Ja6bSV199ZZvZcPM1qFixoiRp06ZNTkOsnTt3atasWbes48qVK/roo4+c7vvggw8kXb8mNy58nt6sN+l/68tk9Jag7KjpRm3btlXu3Ln177//6qmnnlJSUlK2Ld5+s3z58mnkyJHq06ePhgwZkmb4crNjx45pwYIFkq6/PwMCAtJ9tW3bVtL19/WdePJjWkqXLq18+fJJkm0BdWfefPNN2zpIHTp0UFxcXLrjXrlyRS+88ILdTCjr7Kht27Y57ZPWk/usrAujnz17Ns021qDtn3/+0YcffpjueJcuXbL7/Dds2NB2jKFDhzrtM3LkyDQX22/durU8PDx09epVDR8+3GmboUOH6tq1a/L09FTr1q3Tre9WLBaL7WmFX3zxhb777jtJ2RvktmnTRtL1cHHKlCkO+w3DSPNaZdWBAwdst97eKDU11XasMmXKpBnSWf+9ki9fPpUuXTpbawOAe44BAAAMwzCMQYMGGZIMZ/96nD9/vm1fTEyMsW/fPsMwDCMxMdH47rvvjJw5cxqSjJo1axrJycl2fSdOnGhIMvz8/AxPT0+jXbt2xsGDBw3DMIwrV64YY8eONXx8fAxJRsuWLTNd99q1aw2LxWJIMho1amT8888/hmEYRlJSkjFz5kwjT548RnBwsCHJKFKkiEP/Ll26GJKMLl26pHuc0aNH265Bz549jaNHjxqGYRiXLl0yRo0aZXh6ehqSjHbt2jn0PXv2rBEQEGBIMqpXr278/fffhmFcv35z5swxQkNDjVy5ct2yxsDAQMPNzc0YOnSocf78ecMwDOPEiRPGK6+8Yqtt5MiRdn27detmtG3b1pgxY4Zx7Ngx2/YLFy4YY8aMMby8vAxJxoABA9I9/+ys6WZ9+vSxtZVkDB06NFO13CwqKipDP9ObWT8DN/8MRowYYUgyfH19jYsXL95ynL1799rOZf78+Xb7rNsHDRqUqdoy6sknnzQkGb169Uq33YYNG2yfW39/f2PAgAHG9u3bjdTUVMMwDCM1NdXYuXOnMXz4cKNAgQKGJGPr1q22/p06dTIkGTly5DBmzpxpJCUlGYZhGPv27TM6dOhgWCwW2+fO2bnWqlXLkGS0bt3auHTpUpp1PvHEE7Zr1qtXL2PXrl22fdeuXTM2btxovPnmm0bu3Llt3ytW//nPf2x9+/bta5w6dcowDMM4f/68ERsba7i5udlqdPZesb4vLRaL8e677xpnzpwxDMMwzpw5YwwcONA2dr9+/Rz6ZvR75UYnT540vL29beMGBQUZly9fznD/jHjsscds38cTJ040rl69ahiGYRw8eNDo0KGD4eXlZfj5+RmSjIkTJ9r13b9/v622/fv3p3sc62cwMDDQ8PHxMcaOHWtcuXLFMAzDOHDggO19KsmYNWtWmuP07NnTkGQ8+eSTt3XeAHA/IMACAOD/pRdgGYZhfPzxx7agyPrLlTX8kGSUL1/eOHz4sEM/a4BVpEgR47PPPrONERwcbAt9JBkVK1Y0Tp48maXaR44caReABAUF2X4RLFeunG1/6dKlHfpm5hfN3r17245h/QXdw8PDtq1u3bq2EOdm48ePt6sxR44ctutXvXp147PPPstQyNauXTtDkuHu7m4EBwfb/UyefvppIyUlxWlf6ysgIMAICgqy21a7du0MBTPZVdPNdu/ebevj4eFhHDlyJFO13Cy7A6yHHnrIFrZk1MMPP2wLfG9kvS7+/v5Gvnz50n098cQTmarfMAxj9uzZhiSjYMGCtjAqLX/99ZetTuvLw8PDyJUrl9372hoO3/j5jI+PN/Lly2fXLzAw0C6EtP4cnAVY3377ra2tp6enERYWZhQpUsSoVauWXbtLly4Z7du3t6vF39/fCA4ONtzc3Oy2Hzp0yK5vUlKS0aZNG9t+a2Dl7u5uSDI6d+5sPP3007ZQ+mbXrl2zC1qs/W88bocOHYzExESHvlkJsAzjf8GgJOOll17KVN+MOHLkiO39bL321u8DNzc3Y+zYsUbhwoUNScbUqVPt+mYlwBowYIBRu3Zt27GsgaH1NXDgwDTHSElJMQoWLGhIMubMmZMdpw8A9zRuIQQAIIN69+6tzZs3q1OnTipUqJAuX74sX19fVa9eXR9//LF+++23Wz6y/sUXX9TixYvVuHFjubm5yc3NTQ899JDee+89bdiwIctPmXrttde0atUqNWnSRMHBwbp69arCw8M1cOBAbdy40bYGS1BQUJbGt/r444+1YsUKtW7dWvny5dPFixeVI0cO1a1bV19//bWWLl2qHDlyOO373HPP6aefflK9evWUM2dOJScnq1SpUoqNjdXq1avl7++foRqmTp2qMWPGqHLlykpOTpa/v79q1KihyZMn65tvvpGbm/1/3rzzzjsaNWqUnnjiCT300EPy8PDQxYsXlTdvXj322GP6+uuvtWrVqgwfPztqulmJEiVUqVIlSXdm8fbb8csvv+jvv/+WJD355JMZ7mdtu2DBAh07dsxh/6VLl3Ts2LF0X9anr2VG8+bNFRYWpkOHDqW71pF0/datLVu2aMGCBXruuef00EMPKSAgQOfPn1fOnDlVtWpV9e7dW1u2bNHPP/9s9/ksUqSINm/erOeee872uffx8VGzZs20ePFiDRgwIN1jd+rUSd9++61q164tPz8/HTlyRAkJCQ6Lfvv5+Wnq1KlauXKlOnfurGLFiik1NdX2Hq5Xr55GjBih3bt3KywszK6vh4eHfvzxR40fP17VqlWTr6+vkpOT9cgjj2j8+PGaPHmy7RZGZ98NXl5emjZtmmbOnKnHH39cuXPn1oULF5Q7d249/vjjmjVrlqZMmSJPT890zzUzrLefSndmHbj8+fNr06ZNGjhwoEqVKiU3Nzd5eHioSZMmWrFihbp3725b8+t2vy+l69dw+fLlGjp0qEqXLq1r164pMDBQ9evX18KFC/X++++n2Xf16tU6dOiQwsLC1KxZs9uuBQDuea5O0AAAuN/dOAPLVZ566ilDkvHss8+6rIbbkdXZHPeKI0eO2Gb8LF682NXl3POGDBliSDKeeeYZV5diaqmpqbYZPpMnT3Z1OYZhGMZLL71kSDJq1KjhkuP/888/ttlRBw4cyPI46c2+y6hnnnnGkGQMGTIky2MAwP2EGVgAANzn/vnnH9sC6Y0bN3ZxNXDmyy+/VHJyskqUKHFHFm9/0Lz22msKCQnR999/7zCjCf/z7bff6tChQ/Lw8FD9+vVdXY7Onz+vyZMnS/rf0znvtmHDhkm6/kTLQoUKuaQG6fpTLr///nuFhITotddec1kdAGAmBFgAANwH3n33XX322Wc6cOCA7SmHly5d0rRp01S3bl1dvXpVDz30kGJiYlxbKBxs3rzZ9hTD119/XRaLxcUV3fty5sypQYMGKTExMdufKnev6dChg2bMmKGTJ0/ath07dkyxsbHq3r27JOnpp5++5e3Pd9q1a9f06quv6vz58ypUqFCmnsaaGX///be6deumNWvW6MKFC3bbn3nmGU2cOFHSrZ8ieacNHTpUiYmJGjx4sO1pkgDwoPNwdQEAAOD2/fnnn5o7d65efvlleXp6KkeOHDp79qwtzAoLC9P06dOzda0a3J7w8HBdu3ZNR48elSRVrlxZ3bp1c3FV94+ePXvq7NmzcnNzU2pq6i3XIbtfLVq0SD/88IOk6+tpeXp62tZ4kqQ6depo5MiRripPn3zyiT755BMdP35cV65ckXR9rT0vL687cryrV69qwoQJmjBhgiQpMDBQSUlJunz5sq3NK6+8os6dO9+R42dEamqqChcurA8++OCOrAMGAPcqAiwAAO4DvXv3VmhoqNavX68jR47o9OnTypEjh0qVKqVmzZrppZdeUq5cuVxdJm6QkJAg6fqi0o0bN1ZsbCwBYzby8PDQ22+/7eoyXG7UqFFatGiRtm7dquPHj+vixYsKCQlRpUqV1L59e3Xu3Nml77uzZ88qISFBPj4+qlSpkgYMGKA2bdqk2ycrDzmwBsXFixfXf//7Xy1btky7du3S8ePHlZKSokKFCqlGjRrq0aOHy2+ndHNzu+VDAADgQWQxjP9/LBEAAAAAmFxWbrPlVx4AuPcxAwsAAADAPYMwCgAeTA/mYgAAAAAAAAC4ZxBgAQAAAAAAwNQIsAAAAAAAAGBqBFgAAAAAAAAwNQIsAAAAAAAAmBpPIcQdkT9/fl26dEmFCxd2dSkAAAAAAOAuOHDggPz9/XX06NFsH5sZWLgjLl26pKSkJFeXAQAAAAAA7pKkpCRdunTpjozNDCzcEdaZV3FxcS6uBAAAAAAA3A0RERF3bGxmYAEAAAAAAMDUCLAAAAAAAABgagRYAAAAAAAAMDUCLAAAAAAAAJgaARYAAAAAAABMjQALAAAAAAAApkaABQAAAAAAAFMjwAIAAAAAAICpEWABAAAAAADA1AiwAAAAAAAAYGoEWAAAAAAAADA1AiwAAAAAAACYGgEWAAAAAAAATI0ACwAAAAAAAKZGgAUAAAAAAABTI8ACAAAAAACAqRFgAQAAAAAAwNQIsAAAAAAAAGBqBFgAAAAAAAAwNQ9XF4D71+5jFxXef6GrywAAAAAA4J4QH9vU1SWYFjOwAAAAAAAAYGoEWAAAAAAAADA1AiwAAAAAAACYGgEWAAAAAAAATI0ACwAAAAAAAKZGgAUAAAAAAABTI8ACAAAAAACAqRFgAQAAAAAAwNQIsAAAAAAAAGBqBFgAAAAAAAAwNQKsbHDy5Em98847qly5soKCguTn56cSJUqoR48e2rFjR5bGjI6OlsViUXx8fPYWCwAAAAAAcI8hwLpNy5YtU8mSJfXBBx/o8OHDioqKUrNmzeTp6alx48apUqVKio2NdegXHh4ui8XigooBAAAAAADuLR6uLuBetmnTJjVt2lRJSUkaNmyY3njjDXl4/O+S/vTTT+rUqZMGDBggPz8/vfLKKy6sFgAAAAAA4N7EDKwsMgxDXbp0UWJiot577z3179/fLrySpCZNmmjOnDmyWCzq16+fEhISXFQtAAAAAADAvYsAK4sWLVqknTt3KiwsTP369UuzXWRkpNq2baurV6/q888/16pVq2SxWGxhlsVisb3Cw8OdjjFnzhxVr15d/v7+ypUrlzp06KBDhw45bWsYhr755htFRkYqKChIvr6+qlChgv773/8qKSnJob31VkbDMDR69GhVrFhRfn5+qlSpUqavCQAAAAAAwJ1AgJVFP/30kySpbdu28vT0TLftU089Jel66JU/f3516dJF/v7+kqQuXbrYXm3atHHo+8UXX6h169YyDEONGzdWQECAfvjhB9WrV09Xrlyxa5uamqp27dqpa9eu2rZtmx555BE1atRIJ06cUN++fRUTE6PU1FSnNfbq1Ut9+vRR3rx51aJFCxUrVizT1wQAAAAAAOBOYA2sLPrjjz8kSVWqVLllW2ubv/76S8WLF9ekSZO0atUqXbp0SZMmTUq37xdffKGlS5eqXr16kqTLly/rscce0/r16zV16lQ9++yztrb//e9/NX36dD322GP6/vvvFRISIkm6dOmSOnTooPnz52vMmDF68cUXHY4za9Ysbd26VRERERk5fQAAAAAAgLuGGVhZdOrUKUlS3rx5b9nWGiSlpqbq9OnTmTpO7969beGVJPn5+alPnz6SpDVr1ti2Jycn68MPP1SOHDk0ZcoU2zElyd/fX+PGjZO3t7e++uorp8fp169flsKriIgIp6+9e/dmeiwAAAAAAABnCLCyyDAMu39mpK10fc2rzGjYsKHDtlKlSkmSjhw5Ytu2detWnTx5UrVr11aePHkc+uTLl08lS5bUjh07HG49lKQWLVpkqi4AAAAAAIC7hVsIsyhPnjzatWuXjh8/fsu2J06ckHQ9vAoODs7UcQoWLOiwLSAgQJJ07do127b4+HhJ19fZulVIdvr0aYWFhdltK1y4cKbqsoqLi3O6PSIiQruPXczSmAAAAAAAADciwMqiihUr6pdfftGWLVvUuXPndNtu2bJF0vVQ51YLvt8sozO2UlJSJEklS5ZUzZo1023r7e3tsM3HxydTdQEAAAAAANwtBFhZ9Pjjj+uLL77QjBkz9OGHH6YbTE2ZMkWS1Lhx4ztWj3WmVrly5W65MDwAAAAAAMC9hDWwsqhJkyYqXbq0Dh8+rOHDh6fZbs2aNZoxY4a8vLzsnv7n5eUl6fri69mhatWqCgwM1MqVK3X+/PlsGRMAAAAAAMAMCLCyyM3NTZMmTZKnp6feffddDR8+3HYbn9WiRYsUExMjwzAUGxur8PBw277Q0FBJ0q5du7KlHm9vb73xxhs6e/asWrdurYSEBIc2f/75p6ZNm5YtxwMAAAAAALhbuIXwNlSvXl3z5s1T+/bt1b9/f3388ceqUaOGvL29tX37du3cuVNubm56//331bt3b7u+LVq00OrVq1W/fn3VrVtX/v7+ypMnj2JjY7Ncz1tvvaW//vpLU6dOVenSpfXwww+rcOHCOnnypPbt26f9+/erZcuWateu3e2eOgAAAAAAwF1DgHWbGjdurN27d+vTTz/VggULtGLFCiUlJalAgQLq1q2bXn75ZVWoUMGh3yuvvKIzZ85o6tSpmjlzppKSklSkSJHbCrDc3Nw0ZcoUtW7dWuPHj9fmzZu1efNm5cmTR0WKFFGXLl3Uvn372zldAAAAAACAu85iGIbh6iJw/4mIiNDuYxcV2u0LV5cCAAAAAMA9IT62qatLuC0RERGSpLi4uGwfmzWwAAAAAAAAYGoEWAAAAAAAADA1AiwAAAAAAACYGgEWAAAAAAAATI0ACwAAAAAAAKZGgAUAAAAAAABTI8ACAAAAAACAqRFgAQAAAAAAwNQIsAAAAAAAAGBqBFgAAAAAAAAwNQ9XF4D7V8l8AYqLberqMgAAAAAAwD2OGVgAAAAAAAAwNQIsAAAAAAAAmBoBFgAAAAAAAEyNAAsAAAAAAACmRoAFAAAAAAAAUyPAAgAAAAAAgKkRYAEAAAAAAMDUCLAAAAAAAABgah6uLgD3r93HLiq8/0JXlwEAAIAMiI9t6uoSAABIEzOwAAAAAAAAYGoEWAAAAAAAADA1AiwAAAAAAACYGgEWAAAAAAAATI0ACwAAAAAAAKZGgAUAAAAAAABTI8ACAAAAAACAqRFgAQAAAAAAwNQIsAAAAAAAAGBqBFgAAAAAAAAwNQKsTLBYLA4vLy8vFSpUSB07dtT27dtdVtukSZNksVg0ePBgl9UAAAAAAABwJ3i4uoB7UZcuXWx/PnfunLZs2aIpU6ZoxowZ+vnnn1W3bl0XVgcAAAAAAHB/IcDKgkmTJtn9PSkpSc8995y+/fZbvfrqq/rzzz9dUxgAAAAAAMB9iFsIs4Gnp6ft1r3t27fr7NmzLq0HAAAAAADgfkKAlU3y5ctn+3NycrLD/oMHD6pnz54qUqSIvL29lTdvXrVq1UqbNm1Kc8wNGzaoZcuWCgkJkbe3t8LDw/XCCy/o33//zVRtH330kdzc3FS2bFkdPnzYtn3x4sVq1KiRChYsKG9vb4WGhqp27doaMmRIpsYHAAAAAAC4kwiwssmWLVskSXny5FGePHns9m3fvl0PP/ywxo4dKz8/P7Vq1UolS5bU7NmzVbNmTU2fPt1hvO+++0516tTR/PnzVbp0abVq1Ure3t4aM2aMHn74Yf39998Zquutt97SG2+8oUceeURr165VWFiYJOnLL79U48aNtXr1apUpU0atW7dWRESE4uPjWQgeAAAAAACYCmtg3aZz587pt99+00svvSTpemB0I8Mw1LFjR508eVIDBgzQf/7zH1ksFknSjBkz1K5dOz333HOKjIy0zeI6ePCgevToIYvFonnz5qlZs2aSpNTUVPXp00effPKJnn76af32229p1pWamqrnn39eY8eOVb169TR37lwFBATY9sfGxipnzpzatm2bwsPD7epdtWpVdlwaAAAAAACAbMEMrCywWCy2V1BQkBo2bKizZ89qypQp6t27t13bVatWafv27SpatKjef/99W3glSW3atFFMTIwuXLigiRMn2raPHz9eV65cUYcOHWzhlSS5ubkpNjZWoaGh2rRpkzZu3Oi0vsTERLVv315jx47VE088oZ9++skuvJKk48ePq2jRonbhlfXcMvMUxYiICKevvXv3ZngMAAAAAACA9BBgZUGXLl1sr/bt26tGjRo6efKk3nzzTa1evdqu7dq1ayVJ7dq1k7u7u8NYnTt3tmt34587duzo0N7b21tt27Z16GN16dIlNWvWTNOnT9czzzyj6dOny9vb26FdlSpVtG3bNvXv35+wCQAAAAAAmBq3EGbBpEmTHLZt3bpVUVFRatSokXbu3KmiRYtKkm3B9ZtnOllZt9+4MHtW+lh98sknSk5OVpMmTTRhwgS7GV83+vzzzxUTE6Phw4dr+PDhCg0NVZ06ddSmTRu1atVKbm4Zyzbj4uKcbo+IiNDuYxczNAYAAAAAAEB6mIGVTSpXrqyePXvq2rVr+uyzzxz2pxUkpbc/K30ef/xxBQYGasmSJZo5c2aafStUqKC//vpLs2fPVvfu3RUQEKBp06apbdu2ioqKUmJiYrrHBgAAAAAAuFsIsLKRddbVrl27bNtCQ0MlSfv373faJyEhQZJUoECB2+pj9fDDD2vx4sXy8/NThw4dNHv27DTr9fHxUUxMjMaOHatdu3YpLi5OFSpU0Lp16zRhwoQ0+wEAAAAAANxNBFjZaN++fZIkf39/27Y6depIkqZNm6aUlBSHPt99951duxv//P333zu0T0xM1PTp0x363OjRRx/V4sWL5evrq3bt2mnevHkZqr9s2bJ68cUXJUnbt2/PUB8AAAAAAIA7jQArm2zdulVjx46VJDVp0sS2PTo6WuXLl9f+/fv17rvvyjAM2745c+Zo1qxZCggIUNeuXW3bn3vuOfn6+mrq1KlauHChbXtqaqreeustHT58WFWrVlX16tXTrKd69er6+eefbYu+3zjO5cuXNWrUKJ09e9auT2pqqpYsWSJJKly4cJauAwAAAAAAQHZjEfcsuDFsSkxMVEJCgjZu3KjU1FQ1b97c9mRB6fo6Vd9//73q1q2roUOHavbs2apUqZIOHDigX375RR4eHvr666+VP39+W5/ChQtr7Nix6tq1q5o3b65atWqpUKFC+v3337Vr1y7ly5dPkydPvmWdNWvW1KJFi/T444+rdevWmjNnjho3bqzExES9+uqr6tu3rx5++GGFh4crMTFRmzdv1oEDB1SsWDH17NkzW68ZAAAAAABAVhFgZcE333xj+7Obm5uCgoIUGRmpzp07q2vXrg5P8Ctfvrx+//13ffDBB/r55581Y8YMBQYGKiYmRgMGDFC1atUcjtGpUycVK1ZMsbGxWr9+vX799VcVKFBAzz//vN5++22FhYVlqNbatWtr4cKFatKkiZ544gnNmzdPdevW1eeff67ly5dr27Zt+vPPP+Xl5aUiRYqoe/fueumllxQUFHRb1wgAAAAAACC7WIwb72kDsklERIR2H7uo0G5fuLoUAAAAZEB8bFNXlwAAuMdFRERIkuLi4rJ9bNbAAgAAAAAAgKkRYAEAAAAAAMDUCLAAAAAAAABgagRYAAAAAAAAMDUCLAAAAAAAAJgaARYAAAAAAABMjQALAAAAAAAApkaABQAAAAAAAFMjwAIAAAAAAICpEWABAAAAAADA1DxcXQDuXyXzBSgutqmrywAAAAAAAPc4ZmABAAAAAADA1AiwAAAAAAAAYGoEWAAAAAAAADA1AiwAAAAAAACYGgEWAAAAAAAATI0ACwAAAAAAAKZGgAUAAAAAAABTI8ACAAAAAACAqRFgAQAAAAAAwNQ8XF0A7l+7j11UeP+Fri4DAADgvhEf29TVJQAA4BLMwAIAAAAAAICpEWABAAAAAADA1AiwAAAAAAAAYGoEWAAAAAAAADA1AiwAAAAAAACYGgEWAAAAAAAATI0ACwAAAAAAAKZGgAUAAAAAAABTI8ACAAAAAACAqRFgAQAAAAAAwNQIsO4ii8WSqVd4eLirSwYAAAAAAHA5D1cX8CDp0qWLw7Z169Zp7969qlixoipVqmS3L0+ePHepMgAAAAAAAPMiwLqLJk2a5LCta9eu2rt3r2JiYjR48OC7XhMAAAAAAIDZcQshAAAAAAAATI0Ay8ROnTqlvn37qmTJkvLx8VGuXLnUuHFjLVmyxK7dkSNH5OnpqcKFCys1NdXpWN98840sFou6detm25aUlKSvvvpK1apVU548eeTn56fw8HA1a9ZMP/zwwx09NwAAAAAAgIwiwDKpw4cPq1q1avrvf/+rxMRExcTEqHLlylq2bJkaNWqkkSNH2toWKFBALVq00MGDB/Xzzz87HW/8+PGSpO7du9u2de7cWb169dL+/ftVs2ZNtWjRQoUKFdLatWv15Zdf3tkTBAAAAAAAyCDWwDKpXr16ad++fercubMmTJggT09PSdcXfW/UqJH69u2r+vXrq0KFCrb2s2bN0rhx49SkSRO7sf7++2+tW7dO5cqV06OPPipJio+P17Rp01S1alWtWbNGPj4+tvZXrlzRH3/8cXdOFAAAAAAA4BaYgWVC+/bt04IFC5QzZ06NGjXKFl5JUu3atdWrVy+lpKToiy++sG1v0KCBihcvrgULFujo0aN241lnX/Xo0cO27fjx45KkmjVr2oVXkuTr66saNWpkqNaIiAinr71792bupAEAAAAAANJAgGVC69atkyQ1adJEQUFBDvs7d+4sSVq7dq1tm8ViUY8ePZScnGz3tMPExERNnjxZPj4+6tSpk237Qw89JH9/f02cOFHjxo3TqVOn7szJAAAAAAAA3CYCLBP6999/JUnh4eFO91u3W9tZPfPMM/Ly8tL48eNlGIYkac6cOTpx4oTatGmj4OBgW9ucOXNq3LhxSk1NVY8ePRQSEqIyZcrohRde0MaNGzNca1xcnNNX8eLFM3HGAAAAAAAAaSPAMjGLxZLu9pv3h4SEqFWrVtq7d69WrVolyfni7VYdOnTQvn37NG7cOLVp00anT5/WmDFjVKNGDb355pvZeCYAAAAAAABZR4BlQqGhoZKk/fv3O90fHx8v6frTB2/Wq1cvSdK4ceMUHx+vZcuWqVSpUoqMjHQ6VkhIiLp166Yff/xRR48e1aJFi5QzZ059+OGH+uuvv7LhbAAAAAAAAG4PAZYJ1a5dW5K0cOFCnT171mH/d999J0mqU6eOw76oqCg99NBDmjVrlkaMGCHDMJzOvnLGYrGocePGatq0qSRpx44dWTwDAAAAAACA7EOAZULFihVT06ZNdeHCBb366qtKSkqy7duwYYPGjBkjd3d3vfDCC0779+zZU9euXdOYMWPk6empLl26OLTZunWrZs2aZTe2JJ05c0a//vqrJKlw4cLZeFYAAAAAAABZ4+HqAuDcV199pTp16mjy5MlavXq1atSooRMnTmjVqlVKSUnRRx99pAoVKjjt26VLFw0YMEBXr15VTEyMQkJCHNokJCSodevWCgwM1COPPKL8+fPr7NmzWrt2rc6fP68nnnhC1atXv9OnCQAAAAAAcEvMwDKpsLAwbdq0SX369JGHh4dmzZqlLVu2qH79+lq8eLFef/31NPsGBwercuXKkpwv3i5J1atX1wcffKAqVapo165dmj59ujZv3qwKFSrom2++0Y8//nhHzgsAAAAAACCzLIZhGK4uAtnr0KFDKlKkiAoXLqx9+/al+TTDOykiIkK7j11UaLcv7vqxAQAA7lfxsU1dXQIAAGmKiIiQJMXFxWX72MzAug8NGzZMqampevHFF10SXgEAAAAAAGQn1sC6T+zatUsffvih9u3bp5UrV6pgwYJ6/vnnXV0WAAAAAADAbSPAuk8cOXJEEyZMkK+vr6KiojR69Gj5+/u7uiwAAAAAAIDbRoB1n4iOjhbLmQEAAAAAgPsRa2ABAAAAAADA1AiwAAAAAAAAYGoEWAAAAAAAADA1AiwAAAAAAACYGgEWAAAAAAAATI0ACwAAAAAAAKbm4eoCcP8qmS9AcbFNXV0GAAAAAAC4xzEDCwAAAAAAAKZGgAUAAAAAAABTI8ACAAAAAACAqRFgAQAAAAAAwNQIsAAAAAAAAGBqBFgAAAAAAAAwNQIsAAAAAAAAmBoBFgAAAAAAAEzNw9UF4P61+9hFhfdf6OoyAAAA7knxsU1dXQIAAKbBDCwAAAAAAACYGgEWAAAAAAAATI0ACwAAAAAAAKZGgAUAAAAAAABTI8ACAAAAAACAqRFgAQAAAAAAwNQIsAAAAAAAAGBqBFgAAAAAAAAwNQIsAAAAAAAAmBoBFgAAAAAAAEztrgRYFovllq+uXbva9QkPD5fFYrkb5d2ToqOjZbFYFB8f7+pSAAAAAAAA7iiPu3mwLl26pLmvdu3ad7GStFksFhUpUoRgCAAAAAAAwCTuaoA1adKku3m4+9rkyZN1+fJlhYWFuboUAAAAAACAO+quBljIPoULF3Z1CQAAAAAAAHfFPbmIe3x8vHr27Knw8HB5e3srJCREbdq00Z9//plmnw0bNujJJ59UaGiovL29FRYWpkaNGum7776TdH12mHXNrYSEBLv1uaKjo23jWNfmMgxDo0ePVsWKFeXn56dKlSrZ2pw6dUp9+/ZVyZIl5ePjo1y5cqlx48ZasmSJ09osFovCw8OVkpKiESNGqFSpUvL29lahQoXUr18/Xbt2zaFPemtgnTx5UgMGDFC5cuXk7++voKAgVapUSW+//bZOnTpla5eUlKSvvvpK1apVU548eeTn56fw8HA1a9ZMP/zwQ3o/AgAAAAAAgLvmnpuBtW7dOjVt2lTnz59XRESEWrRoocOHD2vWrFn66aeftHDhQtWtW9euzyeffKLXX39dhmGoatWqioqK0vHjx/X7779r165d6tSpk0qUKKEuXbrom2++kb+/v9q0aWPr/9BDDznU0atXL02cOFFRUVEqU6aMEhMTJUmHDx9WZGSk9u3bp8KFCysmJkYnTpzQsmXLtHjxYn388cfq3bu303Pr2LGjFixYoGrVqql06dJau3atRowYocOHD9uCtlv566+/1LBhQx0+fFgFChRQ48aNlZKSol27dmno0KF67LHHbIFc586dNW3aNOXJk0c1a9aUn5+fDh8+rLVr1+rixYtq3759ho4JAAAAAABwJ1kMwzDu+EH+f2ZTZg4VHh6uhIQEuz7nz59X6dKlderUKU2ZMsUuZFq2bJmaNm2qkJAQ7du3T15eXpKkNWvWKDo6Wjly5NDcuXPtZlMlJiZq5cqVatSokV2t6S3ibq0rT548WrVqlSIiIuz2N2/eXAsWLFDnzp01YcIEeXp6SroevDVq1EjXrl3T77//rgoVKjhcnzJlyuinn35SeHi4JGn//v2qUqWKzpw5oz179qh48eK2PtHR0Vq9erX2799va5+cnKzy5cvr77//Vp8+fTRs2DDb8SVp69atCgkJUcGCBRUfH6+iRYuqatWqWrNmjXx8fGztrly5oj/++EM1atRI8+dzKxEREdp97KJCu32R5TEAAAAeZPGxTV1dAgAAmWLNSOLi4rJ97Lt6C+GNt+Xd/JozZ84t+3/99dc6evSo3njjDbvwSpIaNGigF154QYcPH9aCBQts22NjY2UYht5991278EqSvLy87MKrzOjXr59DeLVv3z4tWLBAOXPm1KhRo+zCo9q1a6tXr15KSUnRF184D3VGjx5tC6MkqWjRourUqZMkae3atbesadasWfr7779VoUIFjRgxwu74klS5cmUVLFhQknT8+HFJUs2aNe3CK0ny9fXNcHgVERHh9LV3794M9QcAAAAAALiVu3oLYZcuXdLcl5FFyZcuXSpJiomJcbq/du3a+uSTT7Rp0ya1atVKKSkpWrVqlSSpR48ema43PS1atHDYtm7dOklSkyZNFBQU5LC/c+fO+vjjj52GUZ6eng4BmySVKlVKknTkyJFb1rRs2TJJUvfu3eXmln42+dBDD8nf318TJ05URESEWrVqpdy5c9/yGAAAAAAAAHfbXQ2wJk2adFv9rbf1Pfroo+m2O3nypO2fV65cUd68eZUjR47bOvbNnAVu//77ryTZzaK6kXW7td2NChQoIHd3d4ftAQEBkuR0IfebHTx4UJLsbjVMS86cOTVu3Dj16NFDPXr0UM+ePVW6dGnVrVtXTz/9tKpXr37LMaS0pwVabyEEAAAAAAC4XffUIu4pKSmSpLZt28rPzy/NdjcHXNY1prLTzbfdZeR41u3O9mdnjRkdq0OHDmrQoIHmzp2rJUuWaPXq1RozZozGjBmjvn37asSIEdlWEwAAAAAAQFbdUwFWwYIFtWvXLg0cONBuEfS05MmTR76+vjp27JguXLiQ7bOwbhYaGirp+uLrzlhnkBUoUOCOHL9QoUKSpD179mS4T0hIiLp166Zu3brJMAwtXrxY7dq104cffqiuXbuqbNmyd6RWAAAAAACAjLqri7jfrgYNGkhShhZ8lyR3d3fbulLjxo3LUB9PT08lJydnpTzVrl1bkrRw4UKdPXvWYf93330nSapTp06Wxr8V6/UZP358pp74aGWxWNS4cWM1bXr9iTc7duzI1voAAAAAAACy4p4KsHr27KmQkBANHTpUEydOdAhpLl26pMmTJ+vQoUO2bf369ZPFYtH777/vsHh6UlKSFi9ebLctNDRUx44dcxpA3UqxYsXUtGlTXbhwQa+++qqSkpJs+zZs2KAxY8bI3d1dL7zwQqbHzohWrVqpVKlS2rZtm/r37+8QxP3xxx+2a7N161bNmjXLrkZJOnPmjH799VdJGVtYHwAAAAAA4E67q7cQdu3aNc19hQsX1nvvvZdu/+DgYM2ePVstWrTQs88+qyFDhqhcuXLy9vbWgQMHtHPnTl26dElbt25VwYIFJUlRUVEaMWKE+vbtq8jISFWrVk3FixfX8ePHtW3bNvn7+9tu7ZOuP11w9OjRevjhh1WzZk35+PiodOnS6tu3b4bO8auvvlKdOnU0efJkrV69WjVq1NCJEye0atUqpaSk6KOPPsrQ7Y9Z4eHhoZkzZ+qxxx7TiBEj9N1336lmzZpKTk7Wrl27tHPnTq1cuVIFCxZUQkKCWrdurcDAQD3yyCPKnz+/zp49q7Vr1+r8+fN64oknMryQOwAAAAAAwJ10VwOsb775Js19FStWvGWAJUm1atXS9u3b9fHHH2vhwoVasWKF3N3dFRoaqmbNmqlVq1YO6za98cYbqlq1qkaOHKn169dr69atyps3r6pUqaKnn37aru2wYcNkGIbmzp2radOmKTk5WVFRURkOsMLCwrRp0yYNGzZMc+bM0axZs+Tn56f69eurT58+atiwYYbGyapy5crpjz/+0Icffqh58+Zp/vz58vPzU5EiRezWDqtevbo++OADrVixQrt27dLatWsVHBysChUqqHv37nrqqafuaJ0AAAAAAAAZZTGyslgScAsRERHafeyiQrt94epSAAAA7knxsU1dXQIAAJkSEREhSYqLi8v2se+pNbAAAAAAAADw4CHAAgAAAAAAgKkRYAEAAAAAAMDUCLAAAAAAAABgagRYAAAAAAAAMDUCLAAAAAAAAJgaARYAAAAAAABMjQALAAAAAAAApkaABQAAAAAAAFMjwAIAAAAAAICpebi6ANy/SuYLUFxsU1eXAQAAAAAA7nHMwAIAAAAAAICpEWABAAAAAADA1AiwAAAAAAAAYGoEWAAAAAAAADA1AiwAAAAAAACYGgEWAAAAAAAATI0ACwAAAAAAAKZGgAUAAAAAAABTI8ACAAAAAACAqXm4ugDcv3Yfu6jw/gtdXQYAAMA9Jz62qatLAADAVJiBBQAAAAAAAFMjwAIAAAAAAICpEWABAAAAAADA1AiwAAAAAAAAYGoEWAAAAAAAADA1AiwAAAAAAACYGgEWAAAAAAAATI0ACwAAAAAAAKZGgAUAAAAAAABTI8ACAAAAAACAqRFg/b+lS5cqJiZG+fPnl5eXl3Lnzq2yZcuqY8eOGjdunBITE11dYrqio6NlsVgUHx/v6lIAAAAAAACyFQGWpEGDBqlhw4aaO3euQkJC1Lx5c9WvX1+enp6aOnWqevToodOnT7u6TAAAAAAAgAeSh6sLcLXNmzfrvffek5eXl2bPnq0mTZrY7T98+LDGjRsnb29vF1UIAAAAAADwYHvgA6zZs2dLkp588kmH8EqSwsLCNHjw4LtcFQAAAAAAAKwe+FsIT5w4IUkKCQnJcB+LxaLw8HClpKRoxIgRKlWqlLy9vVWoUCH169dP165dc+jzxx9/6M0331SVKlUUEhIib29vFStWTC+88IL+/fffNI914MABvfTSSypZsqR8fHyUO3duVatWTUOHDtWVK1duWeu5c+cUGRkpi8Wi1157TYZhSJIuXbqk4cOHq1KlSgoKClJAQICKFy+utm3bavHixRm+FgAAAAAAAHfaAx9gFSxYUJI0c+ZMW5iVUR07dtR7772nggULqmHDhrpw4YJGjBih5557zqFtbGysPv74Y6WkpKhWrVpq0qSJDMPQmDFj9MgjjzgNsdasWaMKFSro888/V2pqqlq2bKkaNWro5MmTevvtt3Xs2LF06zt27Jiio6O1du1aDRkyRJ988oksFotSUlLUsGFD9e/fX6dOnVJ0dLSaNGmifPnyacGCBZo6dWqmrgMAAAAAAMCd9MDfQtixY0cNGzZMBw4cUIkSJRQTE6M6deqoRo0aKlu2rCwWi9N+CQkJ8vPz044dOxQeHi5J2r9/v6pUqaLvv/9eQ4YMUfHixW3te/TooZEjR6pAgQK2bampqfrggw80aNAgDRw4UF9//bVt35kzZ9SmTRudO3dOI0eO1KuvvmpXy5o1axQcHJzmecXHx+uxxx7T3r17NXr0aL300ku2fWvXrtX69evVsmVLzZo1S25u/8sxz507pz179mT8AgIAAAAAANxhD/wMrOLFi2vu3LkKDQ3V+fPnNXnyZHXv3l3lypVT/vz59eabb+rs2bNO+44ePdoWXklS0aJF1alTJ0nXQ6Ib1atXzy68kiQ3Nze9++67CgsL09y5c+32jRs3TidOnFCzZs302muvOQRpkZGRCgwMdFpXXFycatWqpfj4eH377bd24ZUkHT9+XJIUHR1tF15JUmBgoKpUqeJ0XGciIiKcvvbu3ZvhMQAAAAAAANLzwM/AkqSGDRtq3759mjdvnpYuXapff/1VO3bs0PHjx/Xhhx9q9uzZWr9+vd06WZ6enoqOjnYYq1SpUpKkI0eOOOw7deqU5s2bpx07dujs2bNKSUmRJCUlJen06dM6ffq0cuXKJUlatmyZJKlnz56ZOpeNGzfqxRdf1JUrVzRnzhw1bdrUoU2lSpXk5uamDz/8UPnz51fTpk2VI0eOTB0HAAAAAADgbiHA+n/e3t5q27at2rZtK+n64u6TJk3S4MGDtWfPHr311lsaN26crX2BAgXk7u7uME5AQIAkOSzkPnXqVPXo0UMXL15Ms4YLFy7YAqyDBw9Kkt1tiBnRuXNnJScna9q0aU7DK+l6yPbhhx+qf//+6tChg9zd3VWuXDk1aNBAzzzzjCIiIjJ8vLi4OKfbIyIitPtY2ucKAAAAAACQUQ/8LYRpCQkJUd++fTV8+HBJ0sKFC+32p7U2ljMJCQnq2rWrrl27pk8++US7d+/W5cuXZRiGDMNQjRo1JMn2hMCsHkeSOnToIEl69913dfTo0TTbvf7669q7d69GjRqlJk2aKCEhQR999JFt0XgAAAAAAACzIMC6BettgidPnszyGD/99JMSExP1yiuv6NVXX1WJEiXk6+tr279v3z6HPoUKFZKkTC+o/t5776lfv37atWuX6tevb1vvyplChQrp5Zdf1rx583TixAl9++23cnNz0+uvv57mul8AAAAAAAB32wMfYDmb9XQj62LkoaGhWT7GmTNnJP0vlLrRmjVrdOzYMYftDRo0kCSNHTs208eLjY1V37599ddff6l+/foZCt88PDzUqVMnVa1aVYmJifrnn38yfVwAAAAAAIA74YEPsN555x29+eab2r9/v8O+3bt3q0+fPpKkVq1aZfkY1oXdv/vuO126dMm2/fDhw+rVq5fTPt26dVOePHk0f/58ffbZZw5B29q1a3Xu3Lk0jzlixAi9/vrr2rFjh+rXr69Tp07Z9q1cuVLLli1TamqqXZ+EhATt3LlTFotFBQsWzPR5AgAAAAAA3AkP/CLuFy9e1Keffqr//ve/Kl26tMqUKSNPT08dOHBAv/32m1JTU1WlShUNGjQoy8do0aKFIiIitHnzZpUoUUK1atXS1atXtXLlSlWqVEk1a9bU+vXr7frkypVLP/74o1q2bKmXX35Zn3zyiapUqaLLly8rLi5O+/fv1/79+xUYGJjmcT/66COlpqbqk08+UYMGDbRixQoFBwdr27Zt6t27t0JCQlSlShXlzp1bJ06c0Jo1a3T16lW99tprtzXjDAAAAAAAIDs98AHWwIEDVaVKFS1evFjbtm3T6tWrdf78eQUFBSkqKkpt2rRRt27d5OXlleVjeHl5ae3atXr77be1aNEiLViwQGFhYXr55Zf17rvvqkmTJk771a1bV3/88YeGDx+uxYsXa86cOcqZM6eKFy+uHj16KH/+/Lc89siRI5WSkqLRo0frscce07Jly9SsWTOdOnVKK1eu1LZt23Tq1CmFhISoTp06euGFFxQTE5PlcwUAAAAAAMhuFuNWi0ABWRAREaHdxy4qtNsXri4FAADgnhMf29TVJQAAkGkRERGSpLi4uGwf+4FfAwsAAAAAAADmRoAFAAAAAAAAUyPAAgAAAAAAgKkRYAEAAAAAAMDUCLAAAAAAAABgagRYAAAAAAAAMDUCLAAAAAAAAJgaARYAAAAAAABMjQALAAAAAAAApkaABQAAAAAAAFPzcHUBuH+VzBeguNimri4DAAAAAADc45iBBQAAAAAAAFMjwAIAAAAAAICpEWABAAAAAADA1AiwAAAAAAAAYGoEWAAAAAAAADA1AiwAAAAAAACYGgEWAAAAAAAATI0ACwAAAAAAAKbm4eoCcP/afeyiwvsvdHUZAAAA95T42KauLgEAANNhBhYAAAAAAABMjQALAAAAAAAApkaABQAAAAAAAFMjwAIAAAAAAICpEWABAAAAAADA1AiwAAAAAAAAYGoEWAAAAAAAADA1AiwAAAAAAACYGgEWAAAAAAAATI0ACwAAAAAAAKb2QAdYFotFFovF1WVkyeDBg2WxWDRp0iRXlwIAAAAAAHBHPdABFgAAAAAAAMyPAAsAAAAAAACmRoAFAAAAAAAAUyPAciI+Pl49e/ZUeHi4vL29FRISojZt2ujPP/+0a7dy5UpZLBY988wzdttTUlIUGBgoi8WiIUOG2O07ceKE3NzcVLVqVYfjrlu3Tk888YTy5s0rb29vhYeH65VXXtGJEycyXHt0dLQsFovi4+M1ZcoUVa9eXTly5FBQUJA2bdoki8WiWrVqpdl/yJAhslgs+uCDDzJ8TAAAAAAAgDuJAOsm69atU8WKFTV27FgFBASoRYsWKlmypGbNmqXq1atr5cqVtrY1atSQt7e33TZJ2rp1q86fPy9JDvtWr14twzAUFRVlt33UqFGKjIzU/PnzVaJECbVo0UK+vr4aPXq0Hn30UR05ciRT5zFs2DB17txZXl5eatasmcqVK6eqVauqSpUqWr9+veLi4hz6pKamauLEiXJ3d3cI5QAAAAAAAFyFAOsG58+fV9u2bXXlyhVNnz5dO3bs0PTp07V+/XotWbJEKSkp6ty5sxITEyVJPj4+evTRR5WQkKD4+HjbOKtWrZIkRUREaOPGjbp69arDvujoaNu2jRs3qnfv3ipcuLB+//13rV+/XtOnT9dff/2l9957T/v379crr7ySqXOZPHmyVqxYoTVr1mjq1Klat26dJKlnz56SpPHjxzv0WbJkiRISEtSkSROFhYVl6ngAAAAAAAB3CgHWDb7++msdPXpUb7zxhtq0aWO3r0GDBnrhhRd0+PBhLViwwLbdOpPKGkxJ12dZBQUF6ZVXXtG1a9e0ceNGu31ubm6qU6eObVtsbKxSU1M1duxYVahQwbbdYrFo4MCBqly5smbNmqWTJ09m+Fyee+45h1lekvTUU08pZ86c+vbbb3Xt2jW7fdZQq3v37hk+TkREhNPX3r17MzwGAAAAAABAegiwbrB06VJJUkxMjNP9tWvXliRt2rTJts06k8oaYKWmpmrdunWqU6eO6tWrZ7fv5MmTiouLU6VKlRQYGGhrv3z5cuXIkUP169d3OKZ1zarU1FRt2bIlw+fSokULp9v9/f3VsWNHnTp1SrNnz7ZtP378uObNm6fQ0FA1adIkw8cBAAAAAAC40zxcXYCZWG8DfPTRR9Ntd+NMqBo1asjLy8sWUm3dulVnz55V3bp1VaJECRUsWNC2z7r+1Y23D546dUoXL16UJHl4pP/jyMwMrMKFC6e5r1evXhozZozGjRun9u3bS5ImTZqkpKQkPfvss3J3d8/wcZytpSVdn5m1+9jFDI8DAAAAAACQFgKsG6SkpEiS2rZtKz8/vzTb3Rhw+fr6qlq1alq3bp3i4+O1evVqSf+bmRUVFaUZM2bo6tWrDvtuPGaOHDnUqlWrdOsrUqRIhs/Fx8cnzX0VKlSwLUi/d+9eFS9eXBMmTJDFYtFzzz2X4WMAAAAAAADcDQRYNyhYsKB27dqlgQMH2q1FdSvR0dFat26dVq1apVWrVik4OFgVK1a07fv++++1ceNGrVq1ymH9qzx58sjb21uenp6aNGlSdp9Smnr16qWNGzdqwoQJatSokf755x81bNhQ4eHhd60GAAAAAACAjGANrBs0aNBAkjRnzpxM9bPOqFqxYoXWrl2ryMhIubm52e2bOXOmduzYoYoVKyooKMjW18PDQ9HR0Tp9+rTWrFlzu6eQYU8++aSCg4M1adIkjRkzRlLmFm8HAAAAAAC4WwiwbtCzZ0+FhIRo6NChmjhxogzDsNt/6dIlTZ48WYcOHbLbXrNmTXl5eWn69Ok6e/as3S2C1nWwxo8f77D+ldVbb70lNzc3denSRevWrXPY/++//+rzzz/PlnO08vX11dNPP60jR45o2rRpCgkJUcuWLbP1GAAAAAAAANnhgQ+wLBaL7c/BwcGaPXu2/P399eyzz6po0aJq1qyZWrdurapVqypfvnzq0qWLw2Lqvr6+qlq1qq5evSpJDiFVVFSUbV9UVJRDDZGRkfr000918OBB1alTRxUrVlSbNm3UrFkzlS9fXoULF9bbb7+dzWd+PbCz6tq1qzw9PbP9GAAAAAAAALfrgQ2wrIGSv7+/3fZatWpp+/bt6tOnj3x9fbVixQotWbJE58+fV7NmzTRt2jSVLVvWYTxraBUcHOywfpZ1n8ViUWRkpNN6XnrpJf3666/q2LGjzpw5o3nz5mnDhg1yc3NTr169NHfu3Ns8Y0dlypRRaGioJKlbt27ZPj4AAAAAAEB2sBg33yf3gPjrr78UERGhsmXLKi4uztXluMT69etVq1YtRUVFadWqVdk6dkREhHYfu6jQbl9k67gAAAD3u/jYpq4uAQCALImIiJCkO5KzPJAzsAzD0GeffSbJ8Xa/B8nQoUMlXZ/9BQAAAAAAYFYeri7gbjp58qReffVVbd++Xdu3b1eOHDnUp08fV5d1V61fv14TJkzQjh079Ntvv6lKlSpq1aqVq8sCAAAAAABI0wM1A+vixYuaOnWqDh06pObNm2vt2rUqVqyYq8u6q/755x99/fXX2rlzp5o3b65Zs2bJze2BehsAAAAAAIB7zAM1Ays8PFypqamuLsOlunbtqq5du7q6DAAAAAAAgAxj6g0AAAAAAABMjQALAAAAAAAApkaABQAAAAAAAFMjwAIAAAAAAICpEWABAAAAAADA1AiwAAAAAAAAYGoeri4A96+S+QIUF9vU1WUAAAAAAIB7HDOwAAAAAAAAYGoEWAAAAAAAADA1AiwAAAAAAACYGgEWAAAAAAAATI0ACwAAAAAAAKZGgAUAAAAAAABTI8ACAAAAAACAqRFgAQAAAAAAwNQIsAAAAAAAAGBqHq4uAPev3ccuKrz/QleXAQAAYHrxsU1dXQIAAKbGDCwAAAAAAACYGgEWAAAAAAAATI0ACwAAAAAAAKZGgAUAAAAAAABTI8ACAAAAAACAqRFgAQAAAAAAwNQIsAAAAAAAAGBqBFgAAAAAAAAwNQIsAAAAAAAAmBoBFgAAAAAAAEztgQywfv31V1ksFlksFg0bNszV5ZhG165dZbFYtGrVKleXAgAAAAAAYPNABljffvut0z8DAAAAAADAfB64ACspKUnTpk2TxWJR/vz5tXPnTv3++++uLgsAAAAAAABpeOACrEWLFunkyZOKjIxUjx49JDELCwAAAAAAwMweuADLGlZ16tRJnTp1kiRNnTpVKSkpDm3Dw8NlsVhkGIY+/fRTlS1bVj4+PgoLC9Mrr7yis2fPOvS5cR2pRYsWqXbt2goICFBwcLBatWqlv//+26HP1atXNWHCBLVs2VLFihWTr6+vgoKCFBkZqR9++MHpedx4nMWLF6tu3boKCgqSxWKxq2v+/Plq1KiRcufOLR8fH5UqVUrvvPOOLl68mIWrBwAAAAAAcPc9UAHWuXPntGDBAnl7e6tNmzYqWbKkqlWrpmPHjmnp0qVp9nv55ZfVt29fFSxYUC1btlRKSopGjx6tqKgoXbhwwWmf6dOnq2nTpkpMTFTz5s0VGhqq2bNnq3r16tq2bZtd2/j4eHXr1k2//vqrChcurJYtW6pSpUrauHGjOnTooMGDB6dZ25QpU/T444/r0qVLevzxx1W1alVZLBZJUp8+fdSiRQutWbNG5cqVs9XzwQcfKDo6WpcuXcr8RQQAAAAAALjLHqgA68cff9TVq1fVrFkzBQUFSZJtFtZ3332XZr9vv/1WGzZs0JIlSzRt2jTt2bNH9erV059//qlBgwY57fPFF1/oq6++0m+//aapU6dqx44d6tevn86dO6dnn33Wrm1ISIgWL16sf//9V6tWrdIPP/ygVatWadeuXQoPD9f777+v+Ph4p8cZN26cpk6dajvOb7/9psDAQP3444/6+OOPVblyZe3cuVOrV6/WzJkztXv3bvXo0UNbtmxJNxgDAAAAAAAwiwcqwLrx9kGr9u3by8PDQ7Nnz07ztrqXXnpJVapUsf09ICBAn332mSwWiyZMmKBr16459KlZs6a6d+9u+7vFYtH777+vQoUK6ffff9eGDRts+3Lnzq2GDRvKzc3+x1G0aFG9/fbbSk1N1fz5853W1rRpU7Vr185h+9ChQyVdvz0yPDzctt3T01Offvqp8ufPr/Hjxys1NdXpuBkVERHh9LV3797bGhcAAAAAAMDqgQmw4uPjtW7dOuXKlUtNmjSxbQ8JCVGjRo10+fJlzZ4922nf9u3bO2wrU6aMKlasqPPnz+vPP//MUB9PT0+1bt1akrRu3TqH/evWrdMHH3yg559/Xs8884y6du2q6dOnS5J2797ttLYWLVo4bDt+/Li2bdumMmXKqHTp0g77fXx89Mgjj+js2bNpjgsAAAAAAGAWHq4u4G757rvvZBiGnnzySXl5ednt69SpkxYuXKhvv/1WnTt3duhbpEgRp2OGh4frjz/+0L///pupPpLs+pw7d06tWrXSihUr0qw/rbW2Chcu7LAtISFBkrRz507belhpOXnypNOQK6Pi4uKcbo+IiNDuYywUDwAAAAAAbt8DFWBJ0vLly1W7dm27fdZbAJcvX64jR46oQIECGRrTMIxM1+GsT79+/bRixQpFRkbqvffeU7ly5RQUFCR3d3ctWbJEjRo1SvNYPj4+DtusT1QsUKCAGjZsmG49uXPnzvQ5AAAAAAAA3E0PRID122+/adeuXZKu34qX1m1zqampmjJlivr06WO3PSEhQeXLl3dof+DAAUlSaGiowz7rLKiM9Jk9e7bc3d01b948BQYG2rXft29fWqeVpoIFC0qS8ufPr0mTJmW6PwAAAAAAgJk8EGtgWRdv79u3rwzDcPpasmSJJOdPI5w2bZrDtr///lt//PGHcuTIoQoVKmSoT3JysmbOnClJqlWrlm37mTNnlCNHDofwSrr+5MTMKliwoEqXLq0///xT+/fvz3R/AAAAAAAAM7nvA6zk5GRbmNShQ4c029WrV0958+bVH3/8oR07dtjt++yzz7R161bb3y9duqSXX35ZhmHo2Weflbe3t8N4v/zyi77++mvb3w3D0KBBg3TgwAFVrFhRNWvWtO0rVaqUzp496xB6jRw5UitXrszcCf+/gQMHKiUlRa1bt3Y4H0nau3evXX0AAAAAAABmdd8HWIsWLdKJEydUunRpVa5cOc127u7uatOmjSTHWVidOnXSo48+qsaNG6tdu3YqUaKEli1bpoiICA0ZMsTpeM8//7y6deumRx99VE899ZTKly+voUOHKkeOHJo4caJd2wEDBki6/uTCyMhIPfXUU4qIiNAbb7yh3r17Z+m8O3XqpDfffFNbt25VpUqVVLVqVT355JNq3LixypQpoxIlSmjUqFFZGhsAAAAAAOBuuu8DLOvtg+3bt79lW+sMre+//16pqam27aNHj9awYcOUkJCguXPnymKx6MUXX9TatWud3vYnSU8++aTmzZsnd3d3zZ07V4cOHVLLli21ceNGhyCtY8eOWrhwoapXr64//vhDixYtUmhoqFasWKEWLVpk9dQ1fPhwLV++XC1atNChQ4c0Z84cbd26VX5+furbty8zsAAAAAAAwD3BYmTlUXoPiPDwcCUkJGTqaYNdu3bVN998o5UrVyo6OvrOFWdyERER2n3sokK7feHqUgAAAEwvPrapq0sAAOC2RURESJLi4uKyfez7fgYWAAAAAAAA7m0EWAAAAAAAADA1AiwAAAAAAACYGgFWOuLj4zO1/pUkTZo0SYZhPNDrXwEAAAAAAGQnAiwAAAAAAACYGgEWAAAAAAAATI0ACwAAAAAAAKZGgAUAAAAAAABTI8ACAAAAAACAqRFgAQAAAAAAwNQ8XF0A7l8l8wUoLrapq8sAAAAAAAD3OGZgAQAAAAAAwNQIsAAAAAAAAGBqBFgAAAAAAAAwNQIsAAAAAAAAmBoBFgAAAAAAAEyNAAsAAAAAAACmRoAFAAAAAAAAUyPAAgAAAAAAgKl5uLoA3L92H7uo8P4LXV0GAACA6cTHNnV1CQAA3FOYgQUAAAAAAABTI8ACAAAAAACAqRFgAQAAAAAAwNQIsAAAAAAAAGBqBFgAAAAAAAAwNQIsAAAAAAAAmBoBFgAAAAAAAEyNAAsAAAAAAACmRoAFAAAAAAAAUyPAAgAAAAAAgKndNwHW0qVLFRMTo/z588vLy0u5c+dW2bJl1bFjR40bN06JiYm2thaLReHh4RkeOzw8XBaL5Q5UDQAAAAAAgFu5LwKsQYMGqWHDhpo7d65CQkLUvHlz1a9fX56enpo6dap69Oih06dPu7pMAAAAAAAAZIGHqwu4XZs3b9Z7770nLy8vzZ49W02aNLHbf/jwYY0bN07e3t5ZPsby5cuVlJR0u6UCAAAAAAAgC+75AGv27NmSpCeffNIhvJKksLAwDR48+LaOUbx48dvqDwAAAAAAgKy7528hPHHihCQpJCTktsfasWOHQkND5eXlpWnTptm2O1sDKz4+XhaLRdHR0bpy5Yr69++vIkWKyNvbWyVKlNDw4cNlGIbT45w8eVIDBgxQuXLl5O/vr6CgIFWqVElvv/22Tp06ZWt35MgRjRgxQlFRUQoLC5OXl5fy58+vVq1aadOmTU7HttZqGIZGjx6tihUrys/PT5UqVbK1SUxM1KeffqqqVasqR44c8vf3V7Vq1TRhwoQ0awYAAAAAAHCVez7AKliwoCRp5syZtjArKzZs2KDIyEidO3dO8+bNU7t27TLULzExUQ0bNtTYsWNVpkwZ1a1bV4cPH1b//v31zjvvOLT/66+/VKlSJcXGxur06dNq3LixoqOjde3aNQ0dOlTbt2+3tZ07d6769eunf//9V+XLl1dMTIxCQ0M1e/Zs1apVS0uWLEmzrl69eqlPnz7KmzevWrRooWLFikmSLl26pAYNGui1115TfHy8ateurejoaO3Zs0fdunXT888/n8krBwAAAAAAcGdZjHt8ys3evXtVrlw5Xb16VTlz5lRMTIzq1KmjGjVqqGzZsk6fHmixWFSkSBHFx8dLkhYvXqzWrVvL09NTCxYsUK1atezah4eHKyEhwW52Unx8vIoWLSpJqlOnjmbNmqU8efJIur4uV40aNeTl5aVjx44pICBAkpScnKzy5cvr77//Vp8+fTRs2DB5enraxty6datCQkJsodz27dtlGIYqVKhgV8/ixYvVokULFSpUSLt377Y7R2utefLk0apVqxQREWHX94UXXtCYMWPUuXNnffHFF7baTpw4oebNm+vXX3/VggUL1LRp04z/EJyIiIjQ7mMXFdrti9saBwAA4H4UH3t7/60FAIAZWTOIuLi4bB/7np+BVbx4cc2dO1ehoaE6f/68Jk+erO7du6tcuXLKnz+/3nzzTZ09ezbN/j/++KNatGihHDlyaPXq1Q7h1a24ublp/PjxtvBKkh555BE9/vjjunz5sjZv3mzbPmvWLP3999+qUKGCRowYYRdeSVLlypVt4ZUklS9f3iG8kqRGjRqpbdu22rt3r3bs2OG0rn79+jmEV8ePH9f48eNVtGhRjRs3zhZeSddvwfzqq68kyfbPjIiIiHD62rt3b4bHAAAAAAAASM89v4i7JDVs2FD79u3TvHnztHTpUv3666/asWOHjh8/rg8//FCzZ8/W+vXrHdbJ+vLLL/Xiiy+qSJEiWrp0aZYWaw8PD1epUqUctlu3HTlyxLZt2bJlkqTu3bvLzS1j2eG1a9f0888/67ffftOJEyeUmJgoSbZbDXfv3q3y5cs79GvRooXDttWrVyspKUmNGzd2+lTGihUrKkeOHGmurwUAAAAAAOAK90WAJUne3t5q27at2rZtK+n6LXGTJk3S4MGDtWfPHr311lsaN26crf2hQ4f0/PPPy8fHRytXrlSRIkWydNwbZ0zdyDq76dq1a7ZtBw8elJTxpxpu375dLVq0sN3q6MyFCxecbi9cuLDDNus4Y8aM0ZgxY9Ic88qVKxmqT0p7WqD1FkIAAAAAAIDbdd8EWDcLCQlR37595evrq5dfflkLFy602583b16VLVtWy5cv1xtvvKGpU6fKwyPzl8PZGlvZ0ccwDD355JOKj49Xr1691KtXLxUrVkwBAQGyWCx66623NGzYsDSfGujj4+OwLSUlRdL1WxWd3ZoIAAAAAABgRvdtgGUVHR0tSTp58qTddi8vL82fP19NmzbVjBkz5O7uru+//17u7u53rJZChQpJkvbs2XPLtn///bf+/vtvPfLII05nS+3bty/Tx7fOFouOjtbHH3+c6f4AAAAAAACucM8v4n6rhyhaFxMPDQ112Ofr66sFCxYoKipK06ZN09NPP63U1NQ7UqckNWjQQJI0fvz4W9Z95swZSc5vUTxz5oyWLl2a6ePXrVtX7u7uWrBggW02FgAAAAAAgNnd8wHWO++8ozfffFP79+932Ld792716dNHktSqVSun/f38/LRw4ULVqVNHU6ZMUdeuXe9YiNWqVSuVKlVK27ZtU//+/ZWcnGy3/48//tChQ4ckSSVKlJCbm5tWrFih3bt329pcvXpVvXr10unTpzN9/LCwMHXt2lW7d+9W586dHWalSdL69ev1008/ZXpsAAAAAACAO+WeD7AuXryoDz/8UMWLF1eZMmXUqlUrtWvXTjVq1NBDDz2kvXv3qkqVKho0aFCaY/j7++unn35SrVq19O233+q555675QyprPDw8NDMmTOVP39+jRgxQkWKFFHbtm31xBNPqGzZsqpcubLt9sK8efPqueee0/nz51WxYkU1a9ZMbdu2VXh4uFasWKGuXbtmqYZRo0apbt26mjp1qooVK6bIyEi1b99e0dHRKliwoGrVqqUlS5Zk41kDAAAAAADcnns+wBo4cKAmT56sp556Sh4eHlq9erVmzZqlPXv2KCoqSp9//rnWr1+vwMDAdMcJCAjQokWLVLNmTU2aNEk9evS4IyFWuXLl9Mcff6hPnz7y9/fX/PnztXr1anl7e2vgwIF2i6uPGTNGH330kYoWLarly5dr7dq1atCggTZv3pzlpyb6+flpyZIlGj9+vB5++GHt2LFDs2fP1t69e1W8eHGNGDFCb7zxRnadLgAAAAAAwG2zGHcipcEDLyIiQruPXVRoty9cXQoAAIDpxMc2dXUJAABku4iICElSXFxcto99z8/AAgAAAAAAwP2NAAsAAAAAAACmRoAFAAAAAAAAUyPAAgAAAAAAgKkRYAEAAAAAAMDUCLAAAAAAAABgagRYAAAAAAAAMDUCLAAAAAAAAJgaARYAAAAAAABMjQALAAAAAAAApubh6gJw/yqZL0BxsU1dXQYAAAAAALjHMQMLAAAAAAAApkaABQAAAAAAAFMjwAIAAAAAAICpEWABAAAAAADA1AiwAAAAAAAAYGoEWAAAAAAAADA1AiwAAAAAAACYGgEWAAAAAAAATI0ACwAAAAAAAKbm4eoCcP/afeyiwvsvdHUZAAAAd0V8bFNXlwAAwH2LGVgAAAAAAAAwNQIsAAAAAAAAmBoBFgAAAAAAAEyNAAsAAAAAAACmRoAFAAAAAAAAUyPAAgAAAAAAgKkRYAEAAAAAAMDUCLAAAAAAAABgagRYAAAAAAAAMDUCLAAAAAAAAJjaPRdgnTx5Uu+8844qV66soKAg+fn5qUSJEurRo4d27Njh6vIkSfHx8bJYLIqOjnZ1KQAAAAAAAPe8eyrAWrZsmUqWLKkPPvhAhw8fVlRUlJo1ayZPT0+NGzdOlSpVUmxsbLYcKzo6WhaLRfHx8dkyHgAAAAAAALLGw9UFZNSmTZvUtGlTJSUladiwYXrjjTfk4fG/8n/66Sd16tRJAwYMkJ+fn1555RUXVgsAAAAAAIDsck/MwDIMQ126dFFiYqLee+899e/f3y68kqQmTZpozpw5slgs6tevnxISElxULQAAAAAAALLTPRFgLVq0SDt37lRYWJj69euXZrvIyEi1bdtWV69e1eeff27bbrFYFB4e7rTPpEmTZLFYNHjwYEn/W79q9erVkqSiRYvKYrHYXjc6efKkevbsqfz588vPz0+VK1fW5MmT0z2X5ORkjR49WlWqVFFAQIACAgJUrVo1jRkzRikpKU77nDp1Sn379lXJkiXl4+OjXLlyqXHjxlqyZInT9tbztQZ+Dz30kLy9vRUTE2Nrs3jxYjVq1EgFCxaUt7e3QkNDVbt2bQ0ZMiTd+gEAAAAAAO62e+IWwp9++kmS1LZtW3l6eqbb9qmnntKPP/6oRYsWacSIEZk+VkBAgLp06aKff/5Zx44dU+vWrRUQEODQ7tSpU6pVq5b++ecfFSxYUC1atNDRo0f1zDPPqFevXk7HTklJUcuWLfXTTz8pZ86catCggSRpxYoVeuGFF7R06VLNmDFDbm7/yxUPHz6syMhI7du3T4ULF1ZMTIxOnDihZcuWafHixfr444/Vu3dvh2OlpqYqJiZGa9asUVRUlCpUqKDcuXNLkr788ks9//zz8vb2Vp06dRQZGakTJ05o586dGjx4sAYNGpTp6wYAAAAAAHCn3BMB1h9//CFJqlKlyi3bWtv89ddfSkpKumXgdbM8efJo0qRJio6O1rFjx/Tf//7X6eytt956S//8849atmypadOmydvbW9L12WItWrRwOvYnn3yin376SeXLl9eyZcuUN29eSdKRI0dUt25dzZ49W19++aVeeOEFW59evXpp37596ty5syZMmGA7n3Xr1qlRo0bq27ev6tevrwoVKtgd6+DBg/L29tauXbsUFhZmty82NlY5c+bUtm3b7M7NMAytWrUqU9cLAAAAAADgTrsnbiE8deqUJNkCn/SEhIRIuj4D6fTp03eknosXL+rbb7+Vh4eHRo0aZQuvJOnxxx9X27ZtnfYbNWqUpOtB1o3nUqBAAX344Yd2bSRp3759WrBggXLmzKlRo0bZhXG1a9dWr169lJKSoi+++MLp8YYNG+YQXknS8ePHVbRoUYdgzmKxqG7durc4e3sRERFOX3v37s3UOAAAAAAAAGm5JwIswzDs/pmRtpIc1qzKLr///ruuXLmiRx99VIULF3bY36FDB4dtBw4c0IEDB5Q/f37Vq1fPYX+zZs0UFBSkXbt26cSJE5Kuz7KSri9QHxQU5NCnc+fOkqS1a9c67LNYLGrevLnT+qtUqaJt27apf//+BE0AAAAAAMD07okAK0+ePJKuzxy6FWv4Y7FYFBwcfEfq+ffffyXJaXiV1nZrn7QWk7dYLCpSpIhd21v1sW63trtR3rx57WaG3ejzzz9X0aJFNXz4cJUoUUJhYWFq3769ZsyYodTUVKd90hIXF+f0Vbx48UyNAwAAAAAAkJZ7IsCqWLGiJGnLli23bGttExERkaH1rzIb2Ej/m+WVlRleGelzc5u0+li3O9vv4+OT5vgVKlTQX3/9pdmzZ6t79+4KCAjQtGnT1LZtW0VFRSkxMfGWNQIAAAAAANwt90SA9fjjj0uSZsyYoaSkpHTbTpkyRZLUuHFj2zZPT09dvHjRafuDBw9mup7Q0FBJUkJCgtP9Bw4cSLPP/v370xzX2q9AgQIZ6hMfH2/XPjN8fHwUExOjsWPHateuXYqLi1OFChW0bt06TZgwIdPjAQAAAAAA3Cn3RIDVpEkTlS5dWocPH9bw4cPTbLdmzRrNmDFDXl5eevHFF23bCxQooFOnTjld1H3JkiVOx/Ly8pIkJScnO+yrUqWKfHx89OuvvzoNwH744QeHbYULF1bhwoV19OhRrVixwmH/woULdebMGZUuXdq2EH3t2rVt+86ePevQ57vvvpMk1alTx+k5ZEbZsmVt12z79u23PR4AAAAAAEB2uScCLDc3N02aNEmenp569913NXz4cKWkpNi1WbRokWJiYmQYhmJjY+3WjYqKipIkvf/++7ZthmFo2LBhWr9+vdNjWmc/7dq1y2FfQECAOnbsqOTkZL366qu6du2abd+SJUv0448/Oh3z5ZdfliT17t3btlaXJB09elR9+/a1ayNJxYoVU9OmTXXhwgW9+uqrdrPPNmzYoDFjxsjd3V0vvPCC0+M5c/nyZY0aNcohEEtNTbWFeWmt7QUAAAAAAOAKFiMjj/YziZ9//lnt27fXuXPnlDdvXtWoUUPe3t7avn27du7cKTc3Nw0ZMkQDBw606xcXF6eqVavqypUrqlSpkooXL67t27fr4MGDeuaZZ/TFF19o0KBBGjx4sK3PrFmz1Lp1a+XMmVMNGzZUYGCgJGn8+PGSpJMnT6pGjRras2ePChUqpFq1aunYsWNavXq1evbsqTFjxigqKkqrVq2yjZmSkqLmzZtr0aJFCgwMVL169WQYhpYvX64LFy4oJiZGM2fOlJvb/3LFw4cPq06dOtq/f7+KFCmiGjVq6MSJE1q1apVSUlL00Ucf6fXXX7c7X+uC8NZbDG909uxZBQcHy8vLSw8//LDCw8OVmJiozZs368CBAypWrJg2b9582wvgR0REaPexiwrt9sVtjQMAAHCviI9t6uoSAABwqYiICEnXc5jsdk/MwLJq3Lixdu/erbffflsFChTQihUrNG/ePF29elXdunXT1q1bHcIr6foFXLFihaKjo/XPP/9o6dKlKl68uDZs2KCqVas6PVarVq00cuRIFSxYUPPnz9eECRPs1obKkyePfvnlF3Xr1k3Xrl3TnDlzdOrUKY0bN05vvvmm0zHd3d01b948ffrppypWrJgWL16sJUuWqHTp0vr88881Y8YMu/BKksLCwrRp0yb16dNHHh4emjVrlrZs2aL69etr8eLFDuHVrQQEBOjzzz9Xs2bNdOLECc2bN08rVqxQcHCw3n//fW3ZsuWOPb0RAAAAAAAgK+6pGVi4dzADCwAAPGiYgQUAeNAxAwsAAAAAAAAPLAIsAAAAAAAAmBoBFgAAAAAAAEyNAAsAAAAAAACmRoAFAAAAAAAAUyPAAgAAAAAAgKkRYAEAAAAAAMDUCLAAAAAAAABgagRYAAAAAAAAMDUCLAAAAAAAAJiah6sLwP2rZL4AxcU2dXUZAAAAAADgHscMLAAAAAAAAJgaARYAAAAAAABMjQALAAAAAAAApkaABQAAAAAAAFMjwAIAAAAAAICpEWABAAAAAADA1AiwAAAAAAAAYGoEWAAAAAAAADA1AiwAAAAAAACYGgEWAAAAAAAATI0ACwAAAAAAAKZGgAUAAAAAAABTI8ACAAAAAACAqRFgAQAAAAAAwNQIsAAAAAAAAGBqBFgAAAAAAAAwNQIsAAAAAAAAmBoBFgAAAAAAAEyNAAsAAAAAAACmZjEMw3B1Ebj/5MiRQ0lJSSpevLirSwEAAAAAAHfB3r175enpqQsXLmT72B7ZPiIg6cqVKyIbhRnt3btXkghXYTq8N2FWvDdhVrw3YVa8N2FWd+O96enpKX9//zsyNgEW7ojSpUtLkuLi4lxcCWAvIiJCEu9NmA/vTZgV702YFe9NmBXvTZjVvf7eZA0sAAAAAAAAmBoBFgAAAAAAAEyNAAsAAAAAAACmRoAFAAAAAAAAUyPAAgAAAAAAgKlZDMMwXF0EAAAAAAAAkBZmYAEAAAAAAMDUCLAAAAAAAABgagRYAAAAAAAAMDUCLAAAAAAAAJgaARYAAAAAAABMjQALAAAAAAAApkaAhWxz9epVDRo0SKVKlZKPj49CQ0P17LPP6tChQ64uDQ+46OhoWSyWNF8///yzq0vEfWzLli2KjY1Vq1atFBYWJovFIh8fn1v2mzx5sqpVq6aAgADlypVLTZo00fr16+9CxXhQZPa9OXjw4HS/S/v3738Xq8f96vLly5ozZ46ee+45VahQQTlz5pS/v78qVqyo9957TxcvXkyzL9+buJOy8t7kexN3y8cff6xWrVqpZMmSCgwMlLe3t4oUKaIuXbooLi4uzX732vemxTAMw9VF4N539epV1a9fX+vXr1eBAgVUp04dxcfH67ffflNISIg2bNig4sWLu7pMPKCio6O1evVqtW7dWgEBAQ77+/Tpo/Lly7ugMjwIYmJiNHfuXLtt3t7eunr1app9Xn/9dY0cOVK+vr5q2LChrl69quXLl8swDE2fPl1PPPHEnS4bD4DMvjcHDx6sIUOGqFatWipRooTD/v9r7+5jqjzvP45/eBZQQEEUUHzAgpXOFdmMLaMldWrVbtbiulqZm10aZ7J2VTubuVCT2S6Lxa3OrFnmnFUKVKcrK4zNdKUrKoo6bGVUZCqCoJ1AQXlUKdfvD8Mp58fhqcg5B3m/kpOU6+G+v4dc+cZ+ue7rXrx4sb7zne8MSqwYPv74xz/q2WeflSRFR0drxowZun79uvLz89XQ0KDp06frww8/VHBwsNU88iYG25dZm+RN2EtQUJCampo0c+ZMhYWFSZKKi4tVWloqT09PZWZmauHChVZzhmTeNMAdkJycbCSZBx54wDQ0NFjat27daiSZhx56yIHRYbh7+OGHjSRTVlbm6FAwDP3qV78yL7/8ssnKyjKffvqpkWS8vLy6Hf/+++8bSSYwMNCUlpZa2vPz842np6fx9/c3n332mT1Cx12uv2tz06ZNRpLZtWuX/YLEsLN7926zZs0aq/xnjDGXL182MTExRpJZvny5VR95E/bwZdYmeRP2cvjwYdPS0tKl/Y033jCSTGhoqGlra7O0D9W8SQELA3bz5k0TEBBgJJnCwsIu/TNnzjSSzMmTJx0QHUABC86ltyLBokWLjCTzm9/8pkvf888/bySZlJSUQYwQwxUFLDi7/Px8yzq9ceOGpZ28CUfrbm2SN+EMpk2bZiSZ4uJiS9tQzZucgYUBO3z4sOrr6xUREaGYmJgu/cuWLZMkZWVl2Ts0ABhSOrZuS1/kzs7IpwCGs69+9auSpBs3bqi2tlYSeRPOwdbaBJyFm5ubJMnT01PS0M6b7o4OAEPfxx9/LEmaNWuWzf6O9o5xgKPs3LlTtbW1cnV1VWRkpB5//HGFh4c7OizAoqSkRDdu3NDYsWM1YcKELv0d+fT06dP2Dg2wyM3N1UcffaTW1lZNmDBBCxcuVGxsrKPDwjBw4cIFSZKHh4fGjBkjibwJ52BrbXZG3oSj7NmzR2fPnlVkZKSmTp0qaWjnTQpYGLCKigpJsrn4O7d3jAMc5ZVXXrH6+cUXX1RycrKSk5MdFBFgrbd86uvrq4CAANXV1amhoUGjRo2yZ3iAJCk1NdXq5+TkZCUmJurNN9+0+aIM4E7Ztm2bJOnRRx+Vl5eXJPImnIOttdkZeRP28tprr6m4uFhNTU06c+aMiouLFRoaqvT0dLm63n4AbyjnTR4hxIB1vDLWx8fHZr+vr6/VOMDeHnroIaWmpur8+fNqbm7W2bNn9eqrr8rd3V0vv/yy5R8dgKP1lk8lciocZ9q0aUpJSVFxcbEaGxt16dIlpaWlKSwsTAcOHND3vvc9R4eIu1hOTo527twpDw8Pbd682dJO3oSjdbc2JfIm7O/gwYPavXu39u/fr+LiYk2cOFHp6elWO/6Gct6kgIUBM8ZIklxcXHrsBxzlF7/4hZKSkjR16lR5e3srMjJSGzduVGZmpiRp06ZNamlpcWyQgHrPp53HAPaWlJSk9evXa8aMGfL19dWECRP09NNP68SJEwoMDFRmZqby8/MdHSbuQmfOnFFSUpKMMXrttdcs5w1J5E04Vk9rUyJvwv7++c9/yhijuro65eXlKSoqSgkJCXr11VctY4Zy3qSAhQHr2FLY1NRks7+5uVmS2B4LpzN//nx97Wtf07Vr13Ts2DFHhwP0mk8lciqcT0hIiFatWiXp9l9+gTupsrJSjz76qOrq6rRu3Tr95Cc/seonb8JRelubPSFvYrAFBAQoPj5eOTk5io2NVXJysk6cOCFpaOdNClgYsI5DsCsrK232d7RzWDac0T333CNJunLlioMjAXrPp01NTaqvr1dAQIBTnUcAkEsxGGpqajRv3jxVVFRo1apVSklJ6TKGvAlH6Mva7A15E/bg4eGh7373uzLGWN4qOJTzJgUsDFjHVtnCwkKb/R3tM2fOtFtMQF/V1dVJcr6/LmB4ioqKkpeXl6qrq23+o4J8CmdFLsWd1tDQoIULF6qkpERPPPGEduzYYfNxF/Im7K2va7M35E3YS1BQkCSpurpa0tDOmxSwMGBxcXHy9/fX+fPnderUqS79+/fvlyQ99thj9g4N6FF1dbUOHTok6YvXxQKO5O3trUceeUTSF7mzM/IpnJExRu+8844k8Vp43BE3btzQkiVLdPLkSS1YsEAZGRlyc3OzOZa8CXvqz9rsCXkT9vThhx9KkiIiIiQN8bxpgDvg5z//uZFkHnzwQdPY2Ghp37p1q5FkvvGNbzgwOgxnR48eNbm5uaa9vd2qvayszMTFxRlJ5tvf/raDosNwJMl4eXl12//ee+8ZSSYwMNCUlpZa2vPz842Xl5fx8/MztbW19ggVw0xPa7O6utrs3r3btLa2WrU3NDSY1atXG0lm/PjxpqmpyR6h4i7W1tZmli5daiSZ+Pj4Pq0p8ibsob9rk7wJe8nLyzNvv/22uXXrllX7zZs3zW9/+1vj6upqvL29TUVFhaVvqOZNF2Oc9Hh5DCmtra1KSEhQQUGBQkJCFB8fr/LychUUFCgwMFDHjh3TtGnTHB0mhqE333xTq1atUkhIiCIjIzV+/HhVVlbq3//+t1pbWxUdHa3c3FwFBwc7OlTcpf72t79ZvVa7oKBALi4umj17tqUtOTlZixcvtvz8wgsvaNu2bfLx8dG8efN08+ZNvffee2pvb9e+ffuUmJho1++Au1N/1ubFixc1ZcoU+fn56d5771V4eLjq6+tVWFio2tpaBQQEKDs7W3FxcY74KriLbNu2TS+88IIkaenSpfLz87M5LiUlxfJYjETexODr79okb8JeOv5/JygoSLGxsQoMDFRNTY2Kiop05coVjRgxQrt379aTTz5pNW9I5k1HV9Bw92hubjbJyckmIiLCeHp6mnHjxpnvf//7VpVewN4++eQTs2bNGjNr1iwzduxY4+7ubvz9/c2cOXPM1q1bTXNzs6NDxF1u165dRlKPn127dtmcFxsba3x8fIy/v79ZsGCBOXTokP2/AO5a/Vmb169fNy+99JJ5+OGHTVhYmPHy8jI+Pj4mOjrarF+/3lRWVjr2y+CusWnTpl7XpSRTVlbWZS55E4Opv2uTvAl7uXDhgtm4caOJi4szISEhxsPDw/j6+pro6Gjz3HPPmf/+97/dzh1qeZMdWAAAAAAAAHBqHOIOAAAAAAAAp0YBCwAAAAAAAE6NAhYAAAAAAACcGgUsAAAAAAAAODUKWAAAAAAAAHBqFLAAAAAAAADg1ChgAQAAAAAAwKlRwAIAAAAAAIBTo4AFAAAAAAAAp0YBCwAAAAAAAE6NAhYAAAAAAACcGgUsAAAAO3JxcbF8jh492u24ffv2WcZNnjy5x2vu3bvXMjYjI6PHsZMnT7aKwdYnISGh399r1apVGjVqlGpqavo9tz8SEhLk4uKiixcvDup9OmtpaVFISIgWL15st3sCAABr7o4OAAAAYLhKS0vTAw88YLPvrbfe6vN1UlNTrf57+fLlvc5JTEzUyJEjbfZNnz69z/eWpKKiIu3Zs0c//elPFRQU1K+5Q4G3t7c2bNigdevWKTc3V4888oijQwIAYNhxMcYYRwcBAAAwXLi4uMjLy0sRERG6evWqrly5Ind3678p1tbWKiQkRF/5yldUWFioSZMmdbvjqLq6WqGhoRoxYoQkqbW1VVVVVQoODrY5fvLkySovL1dZWVmvO7v6asmSJfr73/+uqqoqjR079o5cszsVFRVqbm5WRESEPDw8BvVenbW0tCg0NFSRkZEqKCiw230BAMBtPEIIAADgACtWrFBNTY0OHjzYpW/v3r26deuWkpKSer1ORkaG2tralJiYqCeeeEJtbW29PkZ4J126dEnZ2dlauHDhoBevJCk8PFzTp0+3a/FKur0LKzExUcePH1dhYaFd7w0AAChgAQAAOMSKFSvk4uJi81HBt956SyNHjtSSJUt6vU7H44NJSUmWgld/Hj8cqD/96U9qb2/XihUruvRdvHjRcqZWU1OT1q1bp4kTJ8rb21uzZs1SVlaWZeyf//xnzZ49W76+vho3bpyef/55tbS0dLlmd2dgdZwV9vnnn2vLli2KjIyUl5eXJk6cqJdeekk3btzocq3a2lpt3LhR0dHRGjlypPz9/RUZGamVK1fq+PHjXcY//fTTkqQdO3b099cEAAAGiDOwAAAAHGDSpEmKi4vTu+++q8bGRst5VGVlZTp69KhWrlwpHx+fHq9RUlKikydPKjQ01HIuU2hoqE6ePKmSkpJ+n2X1ZWRnZ0tSjwe/37x5U3PnztX58+c1Z84cNTY2Ki8vT0uXLtU//vEPFRUVacOGDfr617+u+fPn69ChQ9q+fbtqa2uVlpbWr3hWrFih7OxszZ49W1FRUTp06JC2bNmiqqoqq8JeY2Oj5syZo3Pnzumee+7RggULJN1+RDEjI0NTp07V7Nmzra794IMPysPDQzk5Of2KCQAADBw7sAAAABwkKSlJzc3N+stf/mJp6yiy2NrR9P917L5avny5XF1d5erqqqeeesrqOoOpsbFRH330kcLDw7s9c0uSjh49Km9vb5WWliorK0sffPCBdu7cqc8//1xr1qzRK6+8otzcXOXn5+udd97R6dOnFRwcrPT0dF24cKHP8ZSXl+v06dP6z3/+o9zcXGVlZenUqVMaPXq00tLSdP78ecvY/fv369y5c3ruuedUWlqqAwcO6MCBAzpx4oSqqqq0bNmyLtcfMWKEZs6cqYqKCpWXl/fvlwUAAAaEAhYAAICDPPnkk/L09LTaZZSWlqbx48dr7ty5Pc41xljmdT4rq/NjhD29q2fKlClycXGx+Xn99df7FP8nn3yitrY2RUVF9TjOzc1NO3bs0OjRoy1tK1eu1NixY3Xu3Dn9+Mc/Vnx8vKUvNDTUUsDLy8vrUywdtm/fbnU4/ZQpUyy/k0OHDlnar169Kkk23ygYHBys++67z+b1O3a1ffzxx/2KCwAADAyPEAIAADjI6NGjtWjRImVlZenTTz/VpUuXdPbsWa1du1Zubm49zs3Ly1N5ebnuu+8+3X///Zb2mJgYRUdHq7i4WIcPH7YqDHWWmJhoeWzx/5sxY0af4u8oAnUuTNkyefJkTZs2zarN1dVVkyZNUnV1tebNm9dlTkREhCTpypUrfYpFkjw8PGw+yhgZGdnlWrGxsZKkjRs3yt3dXd/85jctb3LsyZgxYyTdfvsjAACwHwpYAAAADpSUlKTMzEy9/fbbKisrs7T1pvPh7bau+bOf/UypqandFrBSUlKsdip9GdeuXZMkjRo1qsdxYWFhNtt9fX277e/os3X4endCQkJsFv46CnWdrzV37lytXbtWr7/+ur71rW/J09NT999/v+bPn68f/vCH3f5u/Pz8JH3x3QEAgH1QwAIAAHCgxx57TAEBAdqzZ48uX76se++9V7NmzepxTmtrq/bv3y/p9iOHnd/mJ0nXr1+XdPvNftu3b5eXl9egxO7v7291v+64uLgMqL+v+nudX//611q9erX++te/6v3339eRI0d0/PhxbdmyRXv37tXjjz/eZU5H4arjuwMAAPvgDCwAAAAH8vLy0rJly3Tq1Cn973//69Puq3fffddSSCkqKtKRI0esPkVFRZKk+vp6y1sCB0PHwe2fffbZoN1jsEVFRWnDhg06ePCgampqlJKSops3b2r16tU2x9fV1UmSxo4da88wAQAY9ihgAQAAONjKlSsVGBiooKCgfr198He/+52MMTY/f/jDHyQN7tsIo6Oj5e7urpKSkkG7hz2NGDFC69evV0hIiK5evWo546uzM2fOSJLVuWMAAGDwUcACAABwsPj4eNXU1Ki6ulqTJk3qcWxNTY0OHjwoNzc3LVu2rNtxiYmJ8vDwUE5OzqDtkPL19VVMTIyqqqp0+fLlQbnHYMnMzNSxY8e6tHfshBs1alSXw+lbW1tVVFSk8PBwhYeH2ytUAAAgzsACAAAYUjIyMnTr1i0tWLDA8gifLWPGjNG8efOUk5Ojffv26Uc/+pFV/4svvtjtWwh9fHz0xhtv9CmexYsX68SJE/rggw/6tHvMWfzrX//Stm3bFBYWppiYGPn5+eny5cs6fPiw2tvbtXnzZnl4eFjNOXLkiG7duqVFixY5KGoAAIYvClgAAABDSMfjg0899VSvY5cvX66cnBylpqZ2KWAdOHCg23n+/v59LmA988wz2rx5s9LT04dUAesHP/iB3N3dlZeXp+PHj+vatWsaP368Fi1apLVr1yohIaHLnPT0dEnSs88+a+doAQCAizHGODoIAAAADF1Lly5Vdna2KisrNW7cOEeHMyhaWloUGhqqyMhIFRQUODocAACGHc7AAgAAwIBs3rxZ7e3t2rp1q6NDGTS///3vVV9fr1/+8peODgUAgGGJHVgAAAAYsGeeeUb79u3TxYsXFRQU5Ohw7qiWlhZNnTpVMTExysnJcXQ4AAAMSxSwAAAAAAAA4NR4hBAAAAAAAABOjQIWAAAAAAAAnBoFLAAAAAAAADg1ClgAAAAAAABwahSwAAAAAAAA4NQoYAEAAAAAAMCpUcACAAAAAACAU6OABQAAAAAAAKdGAQsAAAAAAABOjQIWAAAAAAAAnBoFLAAAAAAAADg1ClgAAAAAAABwahSwAAAAAAAA4NQoYAEAAAAAAMCpUcACAAAAAACAU6OABQAAAAAAAKdGAQsAAAAAAABOjQIWAAAAAAAAnBoFLAAAAAAAADg1ClgAAAAAAABwahSwAAAAAAAA4NQoYAEAAAAAAMCpUcACAAAAAACAU6OABQAAAAAAAKdGAQsAAAAAAABO7f8AyzpeSsMnFbAAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display, Image\n",
    "\n",
    "OUT = Path(r\"C:\\Users\\shail_u9zs758\\analysis_outputs\")\n",
    "\n",
    "# show overall metrics file if you saved it (optional)\n",
    "seg_csv = OUT / \"segmented_errors.csv\"\n",
    "print(\"Segmented errors CSV:\", seg_csv)\n",
    "if seg_csv.exists():\n",
    "    df = pd.read_csv(seg_csv)\n",
    "    display(df.head(20))   # show top 20 rows\n",
    "\n",
    "# display saved PNGs\n",
    "for fname in [\"segmented_errors_by_Area.png\", \"segmented_errors_by_Category_grp.png\", \"segmented_errors_by_Vehicle.png\"]:\n",
    "    p = OUT / fname\n",
    "    if p.exists():\n",
    "        display(Image(filename=str(p)))\n",
    "    else:\n",
    "        print(\"Missing image:\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b6deae48-5907-4d46-bb25-2e9f2c0c9b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote markdown summary to: C:\\Users\\shail_u9zs758\\analysis_outputs\\segmented_summary.md\n",
      "\n",
      "--- Markdown preview ---\n",
      "\n",
      "# Segmented Error Analysis  Summary\n",
      "\n",
      "**Overall test metrics** were computed earlier (see analysis_outputs). Below are the worst-performing segments by MAE.\n",
      "\n",
      "## Top 5 groups (all group types) by MAE\n",
      "\n",
      "| rank | group_by | group | n | MAE | RMSE | R |\n",
      "|---:|---|---|---:|---:|---:|---:|\n",
      "| 1 | Category_grp | Other | 4294 | 29.275 | 41.770 | 0.429 |\n",
      "| 2 | Area | Semi-Urban  | 21 | 26.395 | 33.341 | -5.485 |\n",
      "| 3 | Vehicle | motorcycle  | 5097 | 25.919 | 36.306 | 0.534 |\n",
      "| 4 | Area | Metropolitian  | 6552 | 24.089 | 34.437 | 0.545 |\n",
      "| 5 | Area | Other | 230 | 22.393 | 30.634 | 0.613 |\n",
      "\n",
      "## Top 3 within each group type\n",
      "\n",
      "### Area\n",
      "\n",
      "| rank | group | n | MAE | RMSE | R |\n",
      "|---:|---|---:|---:|---:|---:|\n",
      "| 1 | Semi-Urban  | 21 | 26.395 | 33.341 | -5.485 |\n",
      "| 2 | Metropolitian  | 6552 | 24.089 | 34.437 | 0.545 |\n",
      "| 3 | Other | 230 | 22.393 | 30.634 | 0.613 |\n",
      "\n",
      "\n",
      "### Category_grp\n",
      "\n",
      "| rank | group | n | MAE | RMSE | R |\n",
      "|---:|---|---:|---:|---:|---:|\n",
      "| 1 | Other | 4294 | 29.275 | 41.770 | 0.429 |\n",
      "| 2 | Books | 565 | 18.672 | 23.254 | 0.760 |\n",
      "| 3 | Toys | 556 | 17.978 | 22.813 | 0.774 |\n",
      "\n",
      "\n",
      "### Vehicle\n",
      "\n",
      "| rank | group | n | MAE | RMSE | R |\n",
      "|---:|---|---:|---:|---:|---:|\n",
      "| 1 | motorcycle  | 5097 | 25.919 | 36.306 | 0.534 |\n",
      "| 2 | van | 733 | 21.032 | 30.616 | 0.576 |\n",
      "| 3 | scooter  | 2914 | 19.726 | 28.211 | 0.650 |\n",
      "\n",
      "\n",
      "Saved combined figure to: C:\\Users\\shail_u9zs758\\analysis_outputs\\segmented_combined.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shail_u9zs758\\AppData\\Local\\Temp\\ipykernel_22756\\2018728988.py:88: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "\n",
    "OUT = Path(r\"C:\\Users\\shail_u9zs758\\analysis_outputs\")\n",
    "CSV = OUT / \"segmented_errors.csv\"\n",
    "MD_OUT = OUT / \"segmented_summary.md\"\n",
    "PNG_OUT = OUT / \"segmented_combined.png\"\n",
    "\n",
    "if not CSV.exists():\n",
    "    raise FileNotFoundError(f\"{CSV} not found. Run the segmented analysis first.\")\n",
    "\n",
    "df = pd.read_csv(CSV)\n",
    "\n",
    "# --- Top 5 worst groups overall by MAE ---\n",
    "top5_overall = df.sort_values(\"MAE\", ascending=False).head(5).reset_index(drop=True)\n",
    "\n",
    "# --- Top 3 per group_by (Area, Category_grp, Vehicle) ---\n",
    "grouped_top3 = {}\n",
    "for g in df['group_by'].unique():\n",
    "    top3 = df[df['group_by']==g].sort_values(\"MAE\", ascending=False).head(3).reset_index(drop=True)\n",
    "    grouped_top3[g] = top3\n",
    "\n",
    "# --- Produce markdown text ---\n",
    "md_lines = []\n",
    "md_lines.append(\"# Segmented Error Analysis  Summary\\n\")\n",
    "md_lines.append(\"**Overall test metrics** were computed earlier (see analysis_outputs). Below are the worst-performing segments by MAE.\\n\")\n",
    "\n",
    "md_lines.append(\"## Top 5 groups (all group types) by MAE\\n\")\n",
    "md_lines.append(\"| rank | group_by | group | n | MAE | RMSE | R |\")\n",
    "md_lines.append(\"|---:|---|---|---:|---:|---:|---:|\")\n",
    "for i, row in top5_overall.iterrows():\n",
    "    md_lines.append(f\"| {i+1} | {row['group_by']} | {row['group']} | {int(row['n'])} | {row['MAE']:.3f} | {row['RMSE']:.3f} | {row['R2']:.3f} |\")\n",
    "\n",
    "md_lines.append(\"\\n## Top 3 within each group type\\n\")\n",
    "for g, tbl in grouped_top3.items():\n",
    "    md_lines.append(f\"### {g}\\n\")\n",
    "    md_lines.append(\"| rank | group | n | MAE | RMSE | R |\")\n",
    "    md_lines.append(\"|---:|---|---:|---:|---:|---:|\")\n",
    "    for i, row in tbl.iterrows():\n",
    "        md_lines.append(f\"| {i+1} | {row['group']} | {int(row['n'])} | {row['MAE']:.3f} | {row['RMSE']:.3f} | {row['R2']:.3f} |\")\n",
    "    md_lines.append(\"\\n\")\n",
    "\n",
    "md_text = \"\\n\".join(md_lines)\n",
    "\n",
    "# Save markdown file\n",
    "with open(MD_OUT, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(md_text)\n",
    "\n",
    "print(\"Wrote markdown summary to:\", MD_OUT)\n",
    "print(\"\\n--- Markdown preview ---\\n\")\n",
    "print(md_text)\n",
    "\n",
    "# --- Create combined 3-panel figure ---\n",
    "# Choose plot order and keep only groups that exist\n",
    "panels = []\n",
    "for panel in [\"Area\", \"Category_grp\", \"Vehicle\"]:\n",
    "    if panel in df['group_by'].unique():\n",
    "        sub = df[df['group_by']==panel].nlargest(10, 'MAE').sort_values('MAE')  # top 10 by MAE, ascending for hbar\n",
    "        panels.append((panel, sub))\n",
    "    else:\n",
    "        panels.append((panel, pd.DataFrame()))\n",
    "\n",
    "# Prepare figure\n",
    "n_panels = len(panels)\n",
    "fig, axes = plt.subplots(1, n_panels, figsize=(5*n_panels, 6), constrained_layout=True)\n",
    "\n",
    "if n_panels == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, (title, subdf) in zip(axes, panels):\n",
    "    if subdf.empty:\n",
    "        ax.text(0.5, 0.5, f\"No data for {title}\", ha='center', va='center', fontsize=12)\n",
    "        ax.set_axis_off()\n",
    "        continue\n",
    "    y = subdf['group'].astype(str)\n",
    "    x = subdf['MAE']\n",
    "    ax.barh(y, x)\n",
    "    ax.set_title(f\"Top groups by MAE  {title}\")\n",
    "    ax.set_xlabel(\"MAE (minutes)\")\n",
    "    ax.invert_yaxis()\n",
    "    # annotate values\n",
    "    for i, v in enumerate(x):\n",
    "        ax.text(v + 0.02*max(x), i, f\"{v:.2f}\", va='center', fontsize=9)\n",
    "\n",
    "plt.suptitle(\"Segmented MAE  Top groups (by MAE)\", fontsize=16)\n",
    "plt.savefig(PNG_OUT, dpi=200)\n",
    "plt.show()\n",
    "print(\"Saved combined figure to:\", PNG_OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6523c2a-402f-4c13-9f36-606e822d7516",
   "metadata": {},
   "source": [
    "![Segmented MAE](analysis_outputs/segmented_combined.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da9444e5-0a8e-41d8-a6b1-1f0174eb2ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working dir: C:\\Users\\shail_u9zs758\n",
      "Loaded data shape: (43739, 35)\n",
      "Detected columns -> agent: Agent_Age | timestamp: Order_Time | target: Delivery_Time\n",
      "Warning: could not parse timestamp to datetime, will still attempt fallback methods.\n",
      "Agent column found: Agent_Age  computing per-agent time-window history (7D/30D) if timestamp exists, otherwise index-based rolling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shail_u9zs758\\AppData\\Local\\Temp\\ipykernel_22756\\3223744076.py:65: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[ts_col] = pd.to_datetime(df[ts_col])\n",
      "C:\\Users\\shail_u9zs758\\AppData\\Local\\Temp\\ipykernel_22756\\3223744076.py:99: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_work = df_work.groupby(agent_col, group_keys=False).apply(compute_index_rolling).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added columns: ['agent_7d_count', 'agent_7d_mean', 'agent_30d_count', 'agent_30d_mean']\n",
      "Saved enriched dataset to: C:\\Users\\shail_u9zs758\\amazon_delivery_with_history.csv\n",
      "Model numeric features: ['distance_km', 'order_to_pickup_mins', 'Agent_Age', 'Agent_Rating_imputed', 'hour_sin', 'hour_cos', 'agent_7d_count', 'agent_7d_mean', 'agent_30d_count', 'agent_30d_mean']\n",
      "Model categorical features: ['Weather_imputed', 'Traffic', 'Vehicle', 'Area', 'Category_grp', 'part_of_day', 'distance_bucket', 'Traffic_Weather', 'Area_PartOfDay', 'CatTraffic']\n",
      "Trial 1/12\n",
      "  CV RMSE: 34.1551\n",
      "Trial 2/12\n",
      "  CV RMSE: 34.2750\n",
      "Trial 3/12\n",
      "  CV RMSE: 34.8366\n",
      "Trial 4/12\n",
      "  CV RMSE: 34.5247\n",
      "Trial 5/12\n",
      "  CV RMSE: 34.2308\n",
      "Trial 6/12\n",
      "  CV RMSE: 34.2018\n",
      "Trial 7/12\n",
      "  CV RMSE: 34.2435\n",
      "Trial 8/12\n",
      "  CV RMSE: 34.9525\n",
      "Trial 9/12\n",
      "  CV RMSE: 34.5886\n",
      "Trial 10/12\n",
      "  CV RMSE: 34.2544\n",
      "Trial 11/12\n",
      "  CV RMSE: 34.2334\n",
      "Trial 12/12\n",
      "  CV RMSE: 34.1898\n",
      "Best CV RMSE (train): 34.15514807407543 params: {'subsample': 1.0, 'reg_lambda': 0.0, 'reg_alpha': 0.2, 'num_leaves': 64, 'n_estimators': 300, 'min_child_samples': 5, 'max_depth': 6, 'learning_rate': 0.02, 'colsample_bytree': 0.7}\n",
      "Saved model to: C:\\Users\\shail_u9zs758\\lgbm_history_tuned.joblib\n",
      "Saved metrics to: C:\\Users\\shail_u9zs758\\history_training_metrics.json\n",
      "MLflow logging skipped/failed: file://C:\\Users\\shail_u9zs758\\mlruns is not a valid remote uri. For remote access on windows, please consider using a different scheme such as SMB (e.g. smb://<hostname>/<path>).\n",
      "=== Done. Method used: agent_index_rolling Agent column detected: Agent_Age === \n"
     ]
    }
   ],
   "source": [
    "# Robust agent-history / fallback + small retrain\n",
    "import os, json, joblib, warnings, math, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, ParameterSampler, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "print(\"Working dir:\", ROOT)\n",
    "\n",
    "# Filenames\n",
    "INPUT_CSV = ROOT / \"amazon_delivery_cleaned.csv\"\n",
    "OUT_CSV = ROOT / \"amazon_delivery_with_history.csv\"\n",
    "MODEL_OUT = ROOT / \"lgbm_history_tuned.joblib\"\n",
    "METRICS_OUT = ROOT / \"history_training_metrics.json\"\n",
    "MLFLOW_EXPERIMENT = \"agent_history_modeling\"\n",
    "\n",
    "# detection lists\n",
    "AGENT_ID_CANDIDATES = [\"Agent_ID\",\"AgentId\",\"agent_id\",\"AgentId\",\"Agent\",\"AgentID\",\"driver_id\",\"Driver_ID\",\"delivery_agent\"]\n",
    "TS_CANDIDATES = [\"Order_Time\",\"order_time\",\"order_timestamp\",\"order_datetime\",\"OrderDate\",\"Order_DateTime\",\"Timestamp\",\"created_at\"]\n",
    "TARGET_CANDIDATES = [\"Delivery_Time\",\"delivery_time\",\"DeliveryTime\",\"deliveryTime\",\"target\"]\n",
    "\n",
    "NUMERIC_FEATURES = ['distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed','hour_sin','hour_cos']\n",
    "CATEGORICAL_FEATURES = ['Weather_imputed','Traffic','Vehicle','Area','Category_grp','part_of_day','distance_bucket','Traffic_Weather','Area_PartOfDay','CatTraffic']\n",
    "\n",
    "N_ITER = 12\n",
    "CV_FOLDS = 3\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# load data\n",
    "if not INPUT_CSV.exists():\n",
    "    raise FileNotFoundError(f\"Input CSV not found: {INPUT_CSV}\")\n",
    "\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "print(\"Loaded data shape:\", df.shape)\n",
    "\n",
    "# detect agent, timestamp, target\n",
    "agent_col = next((c for c in AGENT_ID_CANDIDATES if c in df.columns), None)\n",
    "ts_col = next((c for c in TS_CANDIDATES if c in df.columns), None)\n",
    "target_col = next((c for c in TARGET_CANDIDATES if c in df.columns), None)\n",
    "\n",
    "# heuristic search if direct names not found: look for column names containing keywords\n",
    "if agent_col is None:\n",
    "    # look for any column name containing 'agent'/'driver'/'emp'/'deliver'\n",
    "    candidates = [c for c in df.columns if any(k in c.lower() for k in ['agent','driver','emp','deliver','courier'])]\n",
    "    # filter by uniqueness heuristic: not too many unique values (not a timestamp), not too few\n",
    "    found = None\n",
    "    for c in candidates:\n",
    "        nunique = df[c].nunique(dropna=True)\n",
    "        if 2 <= nunique <= max(10000, int(len(df)/2)):\n",
    "            found = c\n",
    "            break\n",
    "    if found:\n",
    "        agent_col = found\n",
    "\n",
    "print(\"Detected columns -> agent:\", agent_col, \"| timestamp:\", ts_col, \"| target:\", target_col)\n",
    "if target_col is None:\n",
    "    raise ValueError(\"Target column not found. Expected one of: \" + \", \".join(TARGET_CANDIDATES))\n",
    "\n",
    "# ensure timestamp parsed if present\n",
    "if ts_col is not None:\n",
    "    try:\n",
    "        df[ts_col] = pd.to_datetime(df[ts_col])\n",
    "    except Exception:\n",
    "        print(\"Warning: could not parse timestamp to datetime, will still attempt fallback methods.\")\n",
    "        # keep ts_col but may not use time-window features\n",
    "\n",
    "# Branch A: agent column found -> compute agent-history (7d / 30d)\n",
    "if agent_col is not None:\n",
    "    print(\"Agent column found:\", agent_col, \" computing per-agent time-window history (7D/30D) if timestamp exists, otherwise index-based rolling.\")\n",
    "    df_work = df.copy()\n",
    "    # if timestamp usable, do time-window per agent\n",
    "    use_time_window = (ts_col is not None) and pd.api.types.is_datetime64_any_dtype(df_work[ts_col])\n",
    "    if use_time_window:\n",
    "        df_work = df_work.sort_values([agent_col, ts_col]).reset_index(drop=True)\n",
    "        def compute_time_windows(g):\n",
    "            g = g.copy().set_index(ts_col)\n",
    "            g['agent_7d_count'] = g[target_col].rolling('7D', closed='left').count().astype(float)\n",
    "            g['agent_7d_mean'] = g[target_col].rolling('7D', closed='left').mean()\n",
    "            g['agent_30d_count'] = g[target_col].rolling('30D', closed='left').count().astype(float)\n",
    "            g['agent_30d_mean'] = g[target_col].rolling('30D', closed='left').mean()\n",
    "            return g.reset_index()\n",
    "        df_hist = df_work.groupby(agent_col, group_keys=False).apply(compute_time_windows)\n",
    "        for col in ['agent_7d_count','agent_7d_mean','agent_30d_count','agent_30d_mean']:\n",
    "            df_work[col] = df_hist[col].values\n",
    "        method_used = \"agent_time_window\"\n",
    "    else:\n",
    "        # index-based (last 7 / last 30 orders per agent)\n",
    "        df_work = df_work.sort_values([agent_col]).reset_index(drop=True)\n",
    "        def compute_index_rolling(g):\n",
    "            g = g.copy()\n",
    "            g['agent_7d_count'] = g[target_col].shift(1).rolling(window=7, min_periods=0).count().astype(float)\n",
    "            g['agent_7d_mean'] = g[target_col].shift(1).rolling(window=7, min_periods=0).mean()\n",
    "            g['agent_30d_count'] = g[target_col].shift(1).rolling(window=30, min_periods=0).count().astype(float)\n",
    "            g['agent_30d_mean'] = g[target_col].shift(1).rolling(window=30, min_periods=0).mean()\n",
    "            return g\n",
    "        df_work = df_work.groupby(agent_col, group_keys=False).apply(compute_index_rolling).reset_index(drop=True)\n",
    "        method_used = \"agent_index_rolling\"\n",
    "\n",
    "    added_cols = ['agent_7d_count','agent_7d_mean','agent_30d_count','agent_30d_mean']\n",
    "    print(\"Added columns:\", added_cols)\n",
    "    # impute safely\n",
    "    global_mean = df_work[target_col].median() if df_work[target_col].notna().any() else 0.0\n",
    "    df_work['agent_7d_count'] = df_work['agent_7d_count'].fillna(0.0)\n",
    "    df_work['agent_30d_count'] = df_work['agent_30d_count'].fillna(0.0)\n",
    "    df_work['agent_7d_mean'] = df_work['agent_7d_mean'].fillna(global_mean)\n",
    "    df_work['agent_30d_mean'] = df_work['agent_30d_mean'].fillna(global_mean)\n",
    "\n",
    "else:\n",
    "    # Branch B fallback: no agent id  compute global & area-level recent stats\n",
    "    print(\"No agent id found  computing dataset-level and Area-level recent stats as fallback.\")\n",
    "    df_work = df.copy()\n",
    "    if ts_col is not None and pd.api.types.is_datetime64_any_dtype(df_work[ts_col]):\n",
    "        df_work = df_work.sort_values(ts_col).reset_index(drop=True)\n",
    "        # global rolling: use time-window rolling on entire dataset\n",
    "        df_work = df_work.set_index(ts_col)\n",
    "        df_work['global_7d_count'] = df_work[target_col].rolling('7D', closed='left').count().astype(float)\n",
    "        df_work['global_7d_mean'] = df_work[target_col].rolling('7D', closed='left').mean()\n",
    "        df_work['global_30d_count'] = df_work[target_col].rolling('30D', closed='left').count().astype(float)\n",
    "        df_work['global_30d_mean'] = df_work[target_col].rolling('30D', closed='left').mean()\n",
    "        df_work = df_work.reset_index()\n",
    "        method_used = \"global_time_window\"\n",
    "    else:\n",
    "        # order-index based global rolling\n",
    "        df_work = df_work.reset_index(drop=True)\n",
    "        df_work['global_7d_count'] = df_work[target_col].shift(1).rolling(window=7, min_periods=0).count().astype(float)\n",
    "        df_work['global_7d_mean'] = df_work[target_col].shift(1).rolling(window=7, min_periods=0).mean()\n",
    "        df_work['global_30d_count'] = df_work[target_col].shift(1).rolling(window=30, min_periods=0).count().astype(float)\n",
    "        df_work['global_30d_mean'] = df_work[target_col].shift(1).rolling(window=30, min_periods=0).mean()\n",
    "        method_used = \"global_index_rolling\"\n",
    "\n",
    "    # area-level recent means if Area exists\n",
    "    if 'Area' in df_work.columns:\n",
    "        use_area = True\n",
    "        if ts_col is not None and pd.api.types.is_datetime64_any_dtype(df_work[ts_col]):\n",
    "            # compute area time-windowed means\n",
    "            df_area = df_work.set_index(ts_col).groupby('Area', group_keys=False)[target_col].rolling('7D', closed='left').mean().reset_index()\n",
    "            # df_area contains repeated timestamp & group; easier: compute per-area expanding with shift as fallback\n",
    "            # Simpler robust approach: compute last-7 / last-30 mean per area using index-based rolling after sorting by ts\n",
    "            df_work = df_work.sort_values(['Area', ts_col]).reset_index(drop=True)\n",
    "            df_work['area_7d_mean'] = df_work.groupby('Area')[target_col].shift(1).rolling(window=7, min_periods=0).mean().reset_index(drop=True)\n",
    "            df_work['area_30d_mean'] = df_work.groupby('Area')[target_col].shift(1).rolling(window=30, min_periods=0).mean().reset_index(drop=True)\n",
    "        else:\n",
    "            df_work = df_work.sort_values(['Area']).reset_index(drop=True)\n",
    "            df_work['area_7d_mean'] = df_work.groupby('Area')[target_col].shift(1).rolling(window=7, min_periods=0).mean().reset_index(drop=True)\n",
    "            df_work['area_30d_mean'] = df_work.groupby('Area')[target_col].shift(1).rolling(window=30, min_periods=0).mean().reset_index(drop=True)\n",
    "    else:\n",
    "        use_area = False\n",
    "\n",
    "    # impute safe\n",
    "    global_mean = df_work[target_col].median() if df_work[target_col].notna().any() else 0.0\n",
    "    for col in ['global_7d_count','global_30d_count']:\n",
    "        df_work[col] = df_work[col].fillna(0.0)\n",
    "    for col in ['global_7d_mean','global_30d_mean','area_7d_mean','area_30d_mean']:\n",
    "        if col in df_work.columns:\n",
    "            df_work[col] = df_work[col].fillna(global_mean)\n",
    "\n",
    "    if use_area:\n",
    "        added_cols = ['global_7d_count','global_7d_mean','global_30d_count','global_30d_mean','area_7d_mean','area_30d_mean']\n",
    "    else:\n",
    "        added_cols = ['global_7d_count','global_7d_mean','global_30d_count','global_30d_mean']\n",
    "\n",
    "    print(\"Added fallback columns:\", added_cols)\n",
    "\n",
    "# save enriched CSV\n",
    "df_work.to_csv(OUT_CSV, index=False)\n",
    "print(\"Saved enriched dataset to:\", OUT_CSV)\n",
    "\n",
    "# Build features list for modeling: keep earlier numeric + categorical, plus new numeric history cols\n",
    "new_numeric_cols = [c for c in ['agent_7d_count','agent_7d_mean','agent_30d_count','agent_30d_mean','global_7d_count','global_7d_mean','global_30d_count','global_30d_mean','area_7d_mean','area_30d_mean'] if c in df_work.columns]\n",
    "model_numeric = [c for c in NUMERIC_FEATURES if c in df_work.columns] + new_numeric_cols\n",
    "model_categorical = [c for c in CATEGORICAL_FEATURES if c in df_work.columns]\n",
    "features = model_numeric + model_categorical\n",
    "print(\"Model numeric features:\", model_numeric)\n",
    "print(\"Model categorical features:\", model_categorical)\n",
    "\n",
    "# Drop rows with missing target, split train/test\n",
    "df_work = df_work.dropna(subset=[target_col]).reset_index(drop=True)\n",
    "strat_col = 'Category_grp' if 'Category_grp' in df_work.columns else None\n",
    "train_df, test_df = train_test_split(df_work, test_size=0.20, random_state=RANDOM_STATE, stratify=df_work[strat_col] if strat_col is not None else None)\n",
    "X_train = train_df[features].copy()\n",
    "y_train = train_df[target_col].copy()\n",
    "X_test = test_df[features].copy()\n",
    "y_test = test_df[target_col].copy()\n",
    "\n",
    "# cast categorical dtypes\n",
    "for c in model_categorical:\n",
    "    X_train[c] = X_train[c].astype('category')\n",
    "    X_test[c] = X_test[c].astype('category')\n",
    "\n",
    "# Small randomized tuning (same as before)\n",
    "param_grid = {\n",
    "    \"num_leaves\": [31, 42, 64, 80],\n",
    "    \"max_depth\": [6, 9, 12],\n",
    "    \"learning_rate\": [0.01, 0.02, 0.05],\n",
    "    \"n_estimators\": [200, 300, 400],\n",
    "    \"subsample\": [0.6, 0.7, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.7, 0.8, 1.0],\n",
    "    \"reg_alpha\": [0.0, 0.1, 0.2],\n",
    "    \"reg_lambda\": [0.0, 0.1, 0.2],\n",
    "    \"min_child_samples\": [5, 10, 20],\n",
    "}\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "sampler = list(ParameterSampler(param_grid, n_iter=N_ITER, random_state=RANDOM_STATE))\n",
    "\n",
    "best_score = math.inf\n",
    "best_params = None\n",
    "for i, params in enumerate(sampler, 1):\n",
    "    print(f\"Trial {i}/{len(sampler)}\")\n",
    "    model = LGBMRegressor(**params, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    try:\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=CV_FOLDS, scoring=\"neg_mean_squared_error\", n_jobs=1)\n",
    "        mean_mse = -scores.mean()\n",
    "        rmse = float(np.sqrt(mean_mse))\n",
    "        print(f\"  CV RMSE: {rmse:.4f}\")\n",
    "        if rmse < best_score:\n",
    "            best_score = rmse\n",
    "            best_params = params\n",
    "    except Exception as e:\n",
    "        print(\"  Trial failed:\", e)\n",
    "        continue\n",
    "\n",
    "if best_params is None:\n",
    "    best_params = {\"num_leaves\":31, \"learning_rate\":0.02, \"n_estimators\":300, \"max_depth\":9, \"subsample\":0.7, \"colsample_bytree\":0.7, \"min_child_samples\":10}\n",
    "print(\"Best CV RMSE (train):\", best_score, \"params:\", best_params)\n",
    "\n",
    "# retrain final model\n",
    "final_model = LGBMRegressor(**best_params, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "final_model.fit(X_train, y_train, categorical_feature=model_categorical)\n",
    "\n",
    "y_pred = final_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "metrics = {\n",
    "    \"detection_agent_col\": agent_col if agent_col is not None else None,\n",
    "    \"method_used\": method_used,\n",
    "    \"best_cv_rmse_train\": float(best_score) if best_score != math.inf else None,\n",
    "    \"best_params\": best_params,\n",
    "    \"test_MAE\": float(mae),\n",
    "    \"test_RMSE\": float(rmse),\n",
    "    \"test_R2\": float(r2),\n",
    "    \"n_train\": int(X_train.shape[0]),\n",
    "    \"n_test\": int(X_test.shape[0]),\n",
    "    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "}\n",
    "\n",
    "joblib.dump(final_model, MODEL_OUT)\n",
    "with open(METRICS_OUT, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"Saved model to:\", MODEL_OUT)\n",
    "print(\"Saved metrics to:\", METRICS_OUT)\n",
    "\n",
    "# attempt MLflow log (graceful)\n",
    "try:\n",
    "    import mlflow\n",
    "    mlflow.set_tracking_uri(f\"file://{ROOT / 'mlruns'}\")\n",
    "    mlflow.set_experiment(MLFLOW_EXPERIMENT)\n",
    "    with mlflow.start_run(run_name=\"lgbm_history_tuned_auto\"):\n",
    "        mlflow.log_params({k:str(v) for k,v in best_params.items()})\n",
    "        mlflow.log_metric(\"test_MAE\", metrics[\"test_MAE\"])\n",
    "        mlflow.log_metric(\"test_RMSE\", metrics[\"test_RMSE\"])\n",
    "        mlflow.log_metric(\"test_R2\", metrics[\"test_R2\"])\n",
    "        mlflow.log_artifact(str(OUT_CSV), artifact_path=\"data\")\n",
    "        mlflow.log_artifact(str(MODEL_OUT), artifact_path=\"model\")\n",
    "        mlflow.log_artifact(str(METRICS_OUT), artifact_path=\"metrics\")\n",
    "    print(\"Logged to MLflow experiment:\", MLFLOW_EXPERIMENT)\n",
    "except Exception as e:\n",
    "    print(\"MLflow logging skipped/failed:\", e)\n",
    "\n",
    "print(\"=== Done. Method used:\", method_used, \"Agent column detected:\", agent_col, \"=== \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "178366b3-69dd-461d-9ea0-6d641b2d0579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working dir: C:\\Users\\shail_u9zs758\n",
      "Loaded data shape: (43739, 35)\n",
      "Final detected columns -> agent: Order_ID | timestamp: Order_Time | target: Delivery_Time\n",
      "Warning: could not parse timestamp reliably.\n",
      "Using agent column: Order_ID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shail_u9zs758\\AppData\\Local\\Temp\\ipykernel_22756\\2542800978.py:81: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[ts_col] = pd.to_datetime(df[ts_col])\n",
      "C:\\Users\\shail_u9zs758\\AppData\\Local\\Temp\\ipykernel_22756\\2542800978.py:113: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_work = df_work.groupby(agent_col, group_keys=False).apply(compute_index_rolling).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added columns: ['agent_7d_count', 'agent_7d_mean', 'agent_30d_count', 'agent_30d_mean']\n",
      "Saved enriched dataset to: C:\\Users\\shail_u9zs758\\amazon_delivery_with_history.csv\n",
      "Trial 1/12\n",
      "  CV RMSE: 34.0993\n",
      "Trial 2/12\n",
      "  CV RMSE: 34.1893\n",
      "Trial 3/12\n",
      "  CV RMSE: 34.7378\n",
      "Trial 4/12\n",
      "  CV RMSE: 34.5306\n",
      "Trial 5/12\n",
      "  CV RMSE: 34.1567\n",
      "Trial 6/12\n",
      "  CV RMSE: 34.1326\n",
      "Trial 7/12\n",
      "  CV RMSE: 34.1724\n",
      "Trial 8/12\n",
      "  CV RMSE: 34.8923\n",
      "Trial 9/12\n",
      "  CV RMSE: 34.5541\n",
      "Trial 10/12\n",
      "  CV RMSE: 34.2355\n",
      "Trial 11/12\n",
      "  CV RMSE: 34.1643\n",
      "Trial 12/12\n",
      "  CV RMSE: 34.1300\n",
      "Best CV RMSE (train): 34.099338685955544 params: {'subsample': 1.0, 'reg_lambda': 0.0, 'reg_alpha': 0.2, 'num_leaves': 64, 'n_estimators': 300, 'min_child_samples': 5, 'max_depth': 6, 'learning_rate': 0.02, 'colsample_bytree': 0.7}\n",
      "Saved model to: C:\\Users\\shail_u9zs758\\lgbm_history_tuned.joblib\n",
      "Saved metrics to: C:\\Users\\shail_u9zs758\\history_training_metrics.json\n",
      "MLflow logging skipped/failed: file://C:\\Users\\shail_u9zs758\\mlruns is not a valid remote uri. For remote access on windows, please consider using a different scheme such as SMB (e.g. smb://<hostname>/<path>).\n",
      "=== Done. Method used: agent_index_rolling Agent column detected: Order_ID === \n"
     ]
    }
   ],
   "source": [
    "# Robust re-run: safer agent-id detection (avoids picking Agent_Age) + feature creation + small retrain\n",
    "import os, json, joblib, warnings, math, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, ParameterSampler, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "print(\"Working dir:\", ROOT)\n",
    "\n",
    "INPUT_CSV = ROOT / \"amazon_delivery_cleaned.csv\"\n",
    "OUT_CSV = ROOT / \"amazon_delivery_with_history.csv\"\n",
    "MODEL_OUT = ROOT / \"lgbm_history_tuned.joblib\"\n",
    "METRICS_OUT = ROOT / \"history_training_metrics.json\"\n",
    "MLFLOW_EXPERIMENT = \"agent_history_modeling\"\n",
    "\n",
    "# detection lists (kept as before)\n",
    "AGENT_ID_CANDIDATES = [\"Agent_ID\",\"AgentId\",\"agent_id\",\"Agent\",\"AgentID\",\"driver_id\",\"Driver_ID\",\"delivery_agent\",\"courier_id\",\"agent\"]\n",
    "TS_CANDIDATES = [\"Order_Time\",\"order_time\",\"order_timestamp\",\"order_datetime\",\"OrderDate\",\"Order_DateTime\",\"Timestamp\",\"created_at\"]\n",
    "TARGET_CANDIDATES = [\"Delivery_Time\",\"delivery_time\",\"DeliveryTime\",\"deliveryTime\",\"target\"]\n",
    "\n",
    "NUMERIC_FEATURES = ['distance_km','order_to_pickup_mins','Agent_Age','Agent_Rating_imputed','hour_sin','hour_cos']\n",
    "CATEGORICAL_FEATURES = ['Weather_imputed','Traffic','Vehicle','Area','Category_grp','part_of_day','distance_bucket','Traffic_Weather','Area_PartOfDay','CatTraffic']\n",
    "\n",
    "N_ITER = 12\n",
    "CV_FOLDS = 3\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Safety exclusion tokens to avoid picking numeric columns like Agent_Age\n",
    "EXCLUDE_AGENT_TOKENS = ['age','rating','score','time','min','max','distance','km']\n",
    "\n",
    "# load data\n",
    "if not INPUT_CSV.exists():\n",
    "    raise FileNotFoundError(f\"Input CSV not found: {INPUT_CSV}\")\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "print(\"Loaded data shape:\", df.shape)\n",
    "\n",
    "# detect agent & timestamp & target\n",
    "agent_col = next((c for c in AGENT_ID_CANDIDATES if c in df.columns), None)\n",
    "ts_col = next((c for c in TS_CANDIDATES if c in df.columns), None)\n",
    "target_col = next((c for c in TARGET_CANDIDATES if c in df.columns), None)\n",
    "\n",
    "# fallback heuristic: search for columns containing 'agent'/'driver'/'id' but avoid columns with EXCLUDE tokens\n",
    "if agent_col is None:\n",
    "    candidates = [c for c in df.columns if any(k in c.lower() for k in ['agent','driver','courier','deliver','id'])]\n",
    "    # filter out columns with exclude tokens (like 'age' or 'rating')\n",
    "    candidates = [c for c in candidates if not any(tok in c.lower() for tok in EXCLUDE_AGENT_TOKENS)]\n",
    "    # sort candidates by cardinality heuristic: prefer moderate-high cardinality (not very small unique set)\n",
    "    scored = []\n",
    "    for c in candidates:\n",
    "        nunique = df[c].nunique(dropna=True)\n",
    "        scored.append((c, nunique))\n",
    "    scored = sorted(scored, key=lambda x: x[1], reverse=True)\n",
    "    if scored:\n",
    "        # choose top candidate only if cardinality > min threshold (e.g., > 30)\n",
    "        cand, nunique = scored[0]\n",
    "        if nunique >= 30:\n",
    "            agent_col = cand\n",
    "\n",
    "# Additional fallback: if still None, try to find any column with high cardinality and name including 'id'\n",
    "if agent_col is None:\n",
    "    for c in df.columns:\n",
    "        if 'id' in c.lower() and df[c].nunique(dropna=True) > 30 and not any(tok in c.lower() for tok in EXCLUDE_AGENT_TOKENS):\n",
    "            agent_col = c\n",
    "            break\n",
    "\n",
    "# Final safety: do not accept numeric columns that look like age/rating even if they match earlier heuristics\n",
    "if agent_col is not None and any(tok in agent_col.lower() for tok in EXCLUDE_AGENT_TOKENS):\n",
    "    print(\"Detected candidate agent column\", agent_col, \"but it includes exclude tokens; ignoring it.\")\n",
    "    agent_col = None\n",
    "\n",
    "print(\"Final detected columns -> agent:\", agent_col, \"| timestamp:\", ts_col, \"| target:\", target_col)\n",
    "if target_col is None:\n",
    "    raise ValueError(\"Target column not found. Expected one of: \" + \", \".join(TARGET_CANDIDATES))\n",
    "\n",
    "# parse timestamp if present\n",
    "if ts_col is not None:\n",
    "    try:\n",
    "        df[ts_col] = pd.to_datetime(df[ts_col])\n",
    "    except Exception:\n",
    "        print(\"Warning: could not parse timestamp reliably.\")\n",
    "\n",
    "# Branch A: agent column found\n",
    "if agent_col is not None:\n",
    "    print(\"Using agent column:\", agent_col)\n",
    "    df_work = df.copy()\n",
    "    # prefer time-window if timestamp is usable\n",
    "    use_time_window = (ts_col is not None) and pd.api.types.is_datetime64_any_dtype(df_work[ts_col])\n",
    "    if use_time_window:\n",
    "        df_work = df_work.sort_values([agent_col, ts_col]).reset_index(drop=True)\n",
    "        def compute_time_windows(g):\n",
    "            g = g.copy().set_index(ts_col)\n",
    "            g['agent_7d_count'] = g[target_col].rolling('7D', closed='left').count().astype(float)\n",
    "            g['agent_7d_mean'] = g[target_col].rolling('7D', closed='left').mean()\n",
    "            g['agent_30d_count'] = g[target_col].rolling('30D', closed='left').count().astype(float)\n",
    "            g['agent_30d_mean'] = g[target_col].rolling('30D', closed='left').mean()\n",
    "            return g.reset_index()\n",
    "        df_hist = df_work.groupby(agent_col, group_keys=False).apply(compute_time_windows)\n",
    "        for col in ['agent_7d_count','agent_7d_mean','agent_30d_count','agent_30d_mean']:\n",
    "            df_work[col] = df_hist[col].values\n",
    "        method_used = \"agent_time_window\"\n",
    "    else:\n",
    "        df_work = df_work.sort_values([agent_col]).reset_index(drop=True)\n",
    "        def compute_index_rolling(g):\n",
    "            g = g.copy()\n",
    "            g['agent_7d_count'] = g[target_col].shift(1).rolling(window=7, min_periods=0).count().astype(float)\n",
    "            g['agent_7d_mean'] = g[target_col].shift(1).rolling(window=7, min_periods=0).mean()\n",
    "            g['agent_30d_count'] = g[target_col].shift(1).rolling(window=30, min_periods=0).count().astype(float)\n",
    "            g['agent_30d_mean'] = g[target_col].shift(1).rolling(window=30, min_periods=0).mean()\n",
    "            return g\n",
    "        df_work = df_work.groupby(agent_col, group_keys=False).apply(compute_index_rolling).reset_index(drop=True)\n",
    "        method_used = \"agent_index_rolling\"\n",
    "    added_cols = ['agent_7d_count','agent_7d_mean','agent_30d_count','agent_30d_mean']\n",
    "    print(\"Added columns:\", added_cols)\n",
    "    # impute\n",
    "    global_mean = df_work[target_col].median() if df_work[target_col].notna().any() else 0.0\n",
    "    df_work['agent_7d_count'] = df_work['agent_7d_count'].fillna(0.0)\n",
    "    df_work['agent_30d_count'] = df_work['agent_30d_count'].fillna(0.0)\n",
    "    df_work['agent_7d_mean'] = df_work['agent_7d_mean'].fillna(global_mean)\n",
    "    df_work['agent_30d_mean'] = df_work['agent_30d_mean'].fillna(global_mean)\n",
    "\n",
    "else:\n",
    "    # Branch B fallback (global & area-level features)\n",
    "    print(\"No valid agent id found. Falling back to global/area recent stats.\")\n",
    "    df_work = df.copy()\n",
    "    if ts_col is not None and pd.api.types.is_datetime64_any_dtype(df_work[ts_col]):\n",
    "        df_work = df_work.sort_values(ts_col).reset_index(drop=True)\n",
    "        df_work = df_work.set_index(ts_col)\n",
    "        df_work['global_7d_count'] = df_work[target_col].rolling('7D', closed='left').count().astype(float)\n",
    "        df_work['global_7d_mean'] = df_work[target_col].rolling('7D', closed='left').mean()\n",
    "        df_work['global_30d_count'] = df_work[target_col].rolling('30D', closed='left').count().astype(float)\n",
    "        df_work['global_30d_mean'] = df_work[target_col].rolling('30D', closed='left').mean()\n",
    "        df_work = df_work.reset_index()\n",
    "        method_used = \"global_time_window\"\n",
    "    else:\n",
    "        df_work = df_work.reset_index(drop=True)\n",
    "        df_work['global_7d_count'] = df_work[target_col].shift(1).rolling(window=7, min_periods=0).count().astype(float)\n",
    "        df_work['global_7d_mean'] = df_work[target_col].shift(1).rolling(window=7, min_periods=0).mean()\n",
    "        df_work['global_30d_count'] = df_work[target_col].shift(1).rolling(window=30, min_periods=0).count().astype(float)\n",
    "        df_work['global_30d_mean'] = df_work[target_col].shift(1).rolling(window=30, min_periods=0).mean()\n",
    "        method_used = \"global_index_rolling\"\n",
    "\n",
    "    if 'Area' in df_work.columns:\n",
    "        df_work = df_work.sort_values(['Area', ts_col if ts_col is not None else df_work.index.name if df_work.index.name else df_work.columns[0]]).reset_index(drop=True)\n",
    "        df_work['area_7d_mean'] = df_work.groupby('Area')[target_col].shift(1).rolling(window=7, min_periods=0).mean().reset_index(drop=True)\n",
    "        df_work['area_30d_mean'] = df_work.groupby('Area')[target_col].shift(1).rolling(window=30, min_periods=0).mean().reset_index(drop=True)\n",
    "        added_cols = ['global_7d_count','global_7d_mean','global_30d_count','global_30d_mean','area_7d_mean','area_30d_mean']\n",
    "    else:\n",
    "        added_cols = ['global_7d_count','global_7d_mean','global_30d_count','global_30d_mean']\n",
    "\n",
    "    global_mean = df_work[target_col].median() if df_work[target_col].notna().any() else 0.0\n",
    "    for col in added_cols:\n",
    "        if col in ['global_7d_count','global_30d_count']:\n",
    "            df_work[col] = df_work[col].fillna(0.0)\n",
    "        else:\n",
    "            df_work[col] = df_work[col].fillna(global_mean)\n",
    "\n",
    "print(\"Saved enriched dataset to:\", OUT_CSV)\n",
    "df_work.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "# Prepare features for model\n",
    "new_numeric_cols = [c for c in ['agent_7d_count','agent_7d_mean','agent_30d_count','agent_30d_mean','global_7d_count','global_7d_mean','global_30d_count','global_30d_mean','area_7d_mean','area_30d_mean'] if c in df_work.columns]\n",
    "model_numeric = [c for c in NUMERIC_FEATURES if c in df_work.columns] + new_numeric_cols\n",
    "model_categorical = [c for c in CATEGORICAL_FEATURES if c in df_work.columns]\n",
    "features = model_numeric + model_categorical\n",
    "\n",
    "df_work = df_work.dropna(subset=[target_col]).reset_index(drop=True)\n",
    "strat_col = 'Category_grp' if 'Category_grp' in df_work.columns else None\n",
    "train_df, test_df = train_test_split(df_work, test_size=0.20, random_state=RANDOM_STATE, stratify=df_work[strat_col] if strat_col is not None else None)\n",
    "X_train = train_df[features].copy(); y_train = train_df[target_col].copy()\n",
    "X_test = test_df[features].copy(); y_test = test_df[target_col].copy()\n",
    "\n",
    "for c in model_categorical:\n",
    "    X_train[c] = X_train[c].astype('category'); X_test[c] = X_test[c].astype('category')\n",
    "\n",
    "# Tiny randomized search (n_iter=N_ITER)\n",
    "param_grid = {\n",
    "    \"num_leaves\": [31, 42, 64, 80],\n",
    "    \"max_depth\": [6, 9, 12],\n",
    "    \"learning_rate\": [0.01, 0.02, 0.05],\n",
    "    \"n_estimators\": [200, 300, 400],\n",
    "    \"subsample\": [0.6, 0.7, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.7, 0.8, 1.0],\n",
    "    \"reg_alpha\": [0.0, 0.1, 0.2],\n",
    "    \"reg_lambda\": [0.0, 0.1, 0.2],\n",
    "    \"min_child_samples\": [5, 10, 20],\n",
    "}\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "sampler = list(ParameterSampler(param_grid, n_iter=N_ITER, random_state=RANDOM_STATE))\n",
    "\n",
    "best_score = math.inf; best_params = None\n",
    "for i, params in enumerate(sampler, 1):\n",
    "    print(f\"Trial {i}/{len(sampler)}\")\n",
    "    model = LGBMRegressor(**params, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    try:\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=CV_FOLDS, scoring=\"neg_mean_squared_error\", n_jobs=1)\n",
    "        mean_mse = -scores.mean(); rmse = float(np.sqrt(mean_mse))\n",
    "        print(f\"  CV RMSE: {rmse:.4f}\")\n",
    "        if rmse < best_score:\n",
    "            best_score = rmse; best_params = params\n",
    "    except Exception as e:\n",
    "        print(\"  Trial failed:\", e)\n",
    "        continue\n",
    "\n",
    "if best_params is None:\n",
    "    best_params = {\"num_leaves\":31, \"learning_rate\":0.02, \"n_estimators\":300, \"max_depth\":9, \"subsample\":0.7, \"colsample_bytree\":0.7, \"min_child_samples\":10}\n",
    "\n",
    "print(\"Best CV RMSE (train):\", best_score, \"params:\", best_params)\n",
    "\n",
    "final_model = LGBMRegressor(**best_params, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "final_model.fit(X_train, y_train, categorical_feature=model_categorical)\n",
    "\n",
    "y_pred = final_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "metrics = {\n",
    "    \"agent_col_detected\": agent_col,\n",
    "    \"method_used\": method_used,\n",
    "    \"best_cv_rmse_train\": float(best_score) if best_score != math.inf else None,\n",
    "    \"best_params\": best_params,\n",
    "    \"test_MAE\": float(mae),\n",
    "    \"test_RMSE\": float(rmse),\n",
    "    \"test_R2\": float(r2),\n",
    "    \"n_train\": int(X_train.shape[0]),\n",
    "    \"n_test\": int(X_test.shape[0]),\n",
    "    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "}\n",
    "\n",
    "joblib.dump(final_model, MODEL_OUT)\n",
    "with open(METRICS_OUT, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"Saved model to:\", MODEL_OUT)\n",
    "print(\"Saved metrics to:\", METRICS_OUT)\n",
    "\n",
    "try:\n",
    "    import mlflow\n",
    "    mlflow.set_tracking_uri(f\"file://{ROOT / 'mlruns'}\")\n",
    "    mlflow.set_experiment(MLFLOW_EXPERIMENT)\n",
    "    with mlflow.start_run(run_name=\"lgbm_history_tuned_safe\"):\n",
    "        mlflow.log_params({k:str(v) for k,v in best_params.items()})\n",
    "        mlflow.log_metric(\"test_MAE\", metrics[\"test_MAE\"])\n",
    "        mlflow.log_metric(\"test_RMSE\", metrics[\"test_RMSE\"])\n",
    "        mlflow.log_metric(\"test_R2\", metrics[\"test_R2\"])\n",
    "        mlflow.log_artifact(str(OUT_CSV), artifact_path=\"data\")\n",
    "        mlflow.log_artifact(str(MODEL_OUT), artifact_path=\"model\")\n",
    "        mlflow.log_artifact(str(METRICS_OUT), artifact_path=\"metrics\")\n",
    "    print(\"Logged to MLflow experiment:\", MLFLOW_EXPERIMENT)\n",
    "except Exception as e:\n",
    "    print(\"MLflow logging skipped/failed:\", e)\n",
    "\n",
    "print(\"=== Done. Method used:\", method_used, \"Agent column detected:\", agent_col, \"=== \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "854ca6ff-50c1-4f75-8480-4364d4220840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local mlruns dir (filesystem): C:\\Users\\shail_u9zs758\\mlruns\n",
      "URI to use with mlflow: file:///C:/Users/shail_u9zs758/mlruns\n",
      "mlflow.get_tracking_uri() -> file:///C:/Users/shail_u9zs758/mlruns\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MlflowClient' object has no attribute 'list_experiments'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlflow.get_tracking_uri() ->\u001b[39m\u001b[38;5;124m\"\u001b[39m, mlflow\u001b[38;5;241m.\u001b[39mget_tracking_uri())\n\u001b[0;32m     17\u001b[0m client \u001b[38;5;241m=\u001b[39m MlflowClient(tracking_uri)\n\u001b[1;32m---> 18\u001b[0m exps \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mlist_experiments()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound experiments:\u001b[39m\u001b[38;5;124m\"\u001b[39m, [e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m exps])\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Show the last 5 runs from the 'agent_history_modeling' experiment if it exists\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MlflowClient' object has no attribute 'list_experiments'"
     ]
    }
   ],
   "source": [
    "# 1) Verify MLflow tracking URI and list experiments & recent runs\n",
    "from pathlib import Path\n",
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow\n",
    "\n",
    "ROOT = Path(r\"C:\\Users\\shail_u9zs758\").resolve()\n",
    "mlruns_dir = (ROOT / \"mlruns\").resolve()\n",
    "\n",
    "print(\"Local mlruns dir (filesystem):\", mlruns_dir)\n",
    "print(\"URI to use with mlflow:\", mlruns_dir.as_uri())\n",
    "\n",
    "# Point mlflow client to that folder (safe, uses file:/// form)\n",
    "tracking_uri = mlruns_dir.as_uri()\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "print(\"mlflow.get_tracking_uri() ->\", mlflow.get_tracking_uri())\n",
    "\n",
    "client = MlflowClient(tracking_uri)\n",
    "exps = client.list_experiments()\n",
    "print(\"Found experiments:\", [e.name for e in exps])\n",
    "\n",
    "# Show the last 5 runs from the 'agent_history_modeling' experiment if it exists\n",
    "exp = client.get_experiment_by_name(\"agent_history_modeling\")\n",
    "if exp:\n",
    "    print(\"Experiment id:\", exp.experiment_id, \"name:\", exp.name)\n",
    "    runs = client.search_runs(exp.experiment_id, order_by=[\"attributes.start_time DESC\"], max_results=10)\n",
    "    print(\"Recent runs (up to 10):\")\n",
    "    for r in runs:\n",
    "        print(\"-\", r.info.run_id, \"| status:\", r.info.status, \"| metrics:\", r.data.metrics)\n",
    "else:\n",
    "    print(\"Experiment 'agent_history_modeling' not found in this mlruns folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42132fd5-d6b9-432a-8365-7082b3b683ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/28 21:50:05 INFO mlflow.tracking.fluent: Experiment with name 'agent_history_modeling' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run id: 71ba002302a8413e8aac8c7c2f44d1e5\n",
      "Artifact URI for this run: file:///C:/Users/shail_u9zs758/mlruns/181570534030750579/71ba002302a8413e8aac8c7c2f44d1e5/artifacts\n"
     ]
    }
   ],
   "source": [
    "# 2) Re-log local artifacts as a new MLflow run (if UI doesn't show previous run)\n",
    "from pathlib import Path\n",
    "import json, mlflow\n",
    "\n",
    "ROOT = Path(r\"C:\\Users\\shail_u9zs758\").resolve()\n",
    "mlruns_dir = (ROOT / \"mlruns\").resolve()\n",
    "mlflow.set_tracking_uri(mlruns_dir.as_uri())\n",
    "mlflow.set_experiment(\"agent_history_modeling\")\n",
    "\n",
    "model_file = ROOT / \"lgbm_history_tuned.joblib\"\n",
    "metrics_file = ROOT / \"history_training_metrics.json\"\n",
    "data_file = ROOT / \"amazon_delivery_with_history.csv\"\n",
    "\n",
    "metrics = {}\n",
    "if metrics_file.exists():\n",
    "    metrics = json.loads(metrics_file.read_text(encoding=\"utf-8\"))\n",
    "else:\n",
    "    print(\"Warning: metrics file not found:\", metrics_file)\n",
    "\n",
    "with mlflow.start_run(run_name=\"relog_history_artifacts\"):\n",
    "    # log params if present in metrics\n",
    "    best_params = metrics.get(\"best_params\", {})\n",
    "    if best_params:\n",
    "        mlflow.log_params({k: str(v) for k,v in best_params.items()})\n",
    "    # log numeric metrics\n",
    "    for k in (\"test_MAE\",\"test_RMSE\",\"test_R2\",\"best_cv_rmse_train\"):\n",
    "        if k in metrics:\n",
    "            mlflow.log_metric(k, float(metrics[k]))\n",
    "    # log artifacts (if present)\n",
    "    if data_file.exists():\n",
    "        mlflow.log_artifact(str(data_file), artifact_path=\"data\")\n",
    "    if model_file.exists():\n",
    "        mlflow.log_artifact(str(model_file), artifact_path=\"model\")\n",
    "    if metrics_file.exists():\n",
    "        mlflow.log_artifact(str(metrics_file), artifact_path=\"metrics\")\n",
    "    print(\"Logged run id:\", mlflow.active_run().info.run_id)\n",
    "    print(\"Artifact URI for this run:\", mlflow.get_artifact_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d88a333f-6ae0-45f1-8c67-9435c94ce3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are relogged into the Mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b74d1f0-6726-4d23-bfbb-342750e1a050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model comparison CSV to: C:\\Users\\shail_u9zs758\\comparison_outputs\\model_comparison.csv\n",
      "Saved markdown summary to: C:\\Users\\shail_u9zs758\\comparison_outputs\\model_comparison.md\n",
      "\n",
      "Top 3 models by RMSE (if available):\n",
      " 1. baseline_linear -> RMSE=33.267, MAE=26.199, R2=0.585 :: file=linear_model_metrics.json\n",
      " 2. lgbm_tuning -> RMSE=33.762, MAE=23.733, R2=0.572 :: file=lgbm_tuning_summary.json\n",
      " 3. lgbm_tuned_metrics -> RMSE=33.762, MAE=23.733, R2=0.572 :: file=lgbm_tuning_summary.json\n",
      "\n",
      "Done. Files written to: C:\\Users\\shail_u9zs758\\comparison_outputs\n"
     ]
    }
   ],
   "source": [
    "# ===== Aggregate saved model metrics into a comparison table + markdown =====\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "ROOT = Path(r\"C:\\Users\\shail_u9zs758\")\n",
    "OUT = ROOT / \"comparison_outputs\"\n",
    "OUT.mkdir(exist_ok=True)\n",
    "\n",
    "# Candidate metric files we used in the project\n",
    "candidates = {\n",
    "    \"baseline_linear\": ROOT / \"linear_model_metrics.json\",\n",
    "    \"baseline_mlflow_summary\": ROOT / \"mlflow_models_summary.json\",\n",
    "    \"post_feature_engineering\": ROOT / \"mlflow_postfe_summary.json\",\n",
    "    \"tree_models\": ROOT / \"tree_models_summary.json\",\n",
    "    \"lgbm_tuning\": ROOT / \"lgbm_tuning_summary.json\",\n",
    "    \"lgbm_tuned_metrics\": ROOT / \"lgbm_tuning_summary.json\",   # sometimes same\n",
    "    \"optuna_native\": ROOT / \"optuna_native_outputs\" / \"optuna_summary.json\",  # optional\n",
    "    \"optuna_metrics_file\": ROOT / \"optuna_native_outputs\" / \"optuna_summary.json\",\n",
    "    \"history_model\": ROOT / \"history_training_metrics.json\",\n",
    "    \"lgbm_native\": ROOT / \"lgbm_native_cat_summary.json\",\n",
    "    \"shap_native\": ROOT / \"shap_native_outputs\" / \"shap_native_summary.json\"  # optional\n",
    "}\n",
    "\n",
    "# We'll search for files and try to extract MAE/RMSE/R2/best_params info\n",
    "rows = []\n",
    "\n",
    "def try_load_json(p):\n",
    "    try:\n",
    "        if p.exists():\n",
    "            return json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "    except Exception as e:\n",
    "        # some files may be plain text with python repr; ignore\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "# Known metric keys mapping / heuristics\n",
    "def extract_metrics(name, data):\n",
    "    # data may be dict with nested keys or list of runs - we'll search common keys\n",
    "    if data is None:\n",
    "        return {}\n",
    "    flat = {}\n",
    "    # flatten nested dictionaries up to two levels\n",
    "    def rec(prefix, obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for k,v in obj.items():\n",
    "                rec(prefix + (k if prefix==\"\" else \".\"+k), v)\n",
    "        else:\n",
    "            flat[prefix] = obj\n",
    "    if isinstance(data, dict):\n",
    "        rec(\"\", data)\n",
    "    # heuristics to find mae/rmse/r2\n",
    "    found = {}\n",
    "    for k,v in flat.items():\n",
    "        lk = k.lower()\n",
    "        if 'mae' in lk and 'test' in lk or lk.endswith('mae') or 'mae'==lk:\n",
    "            try: found['MAE'] = float(v)\n",
    "            except: pass\n",
    "        if 'rmse' in lk and ('test' in lk or lk.endswith('rmse') or 'rmse'==lk):\n",
    "            try: found['RMSE'] = float(v)\n",
    "            except: pass\n",
    "        if 'r2' in lk and ('test' in lk or lk.endswith('r2') or 'r2'==lk):\n",
    "            try: found['R2'] = float(v)\n",
    "            except: pass\n",
    "    # fallback: look for test_* keys\n",
    "    for key in ['test_MAE','test_RMSE','test_R2','mae','rmse','r2']:\n",
    "        if key in data and key not in found:\n",
    "            try:\n",
    "                found[key.replace('test_','').upper()] = float(data[key])\n",
    "            except:\n",
    "                pass\n",
    "    # also check 'test' nested dict\n",
    "    if 'test' in data and isinstance(data['test'], dict):\n",
    "        for k,v in data['test'].items():\n",
    "            lk = k.lower()\n",
    "            if 'mae' in lk and 'MAE' not in found:\n",
    "                try: found['MAE'] = float(v)\n",
    "                except: pass\n",
    "            if 'rmse' in lk and 'RMSE' not in found:\n",
    "                try: found['RMSE'] = float(v)\n",
    "                except: pass\n",
    "            if 'r2' in lk and 'R2' not in found:\n",
    "                try: found['R2'] = float(v)\n",
    "                except: pass\n",
    "    # also look for metrics keys at top-level .get('test_RMSE') etc\n",
    "    for k in ['test_RMSE','test_MAE','test_R2','test_rmse','test_mae','test_r2']:\n",
    "        if k in data:\n",
    "            try:\n",
    "                found[k.replace('test_','').upper()] = float(data[k])\n",
    "            except:\n",
    "                pass\n",
    "    return found\n",
    "\n",
    "# walk through candidate files and also common directories\n",
    "# 1) check exact candidate files\n",
    "for label, p in candidates.items():\n",
    "    if p.exists():\n",
    "        data = try_load_json(p)\n",
    "        metrics = extract_metrics(label, data if data is not None else {})\n",
    "        rows.append({\n",
    "            \"model_key\": label,\n",
    "            \"file\": str(p.relative_to(ROOT)),\n",
    "            \"MAE\": metrics.get(\"MAE\", np.nan),\n",
    "            \"RMSE\": metrics.get(\"RMSE\", np.nan),\n",
    "            \"R2\": metrics.get(\"R2\", np.nan),\n",
    "            \"notes\": None\n",
    "        })\n",
    "\n",
    "# 2) check common filenames we used earlier (fallbacks)\n",
    "extra_files = [\n",
    "    ROOT / \"linear_model_metrics.json\",\n",
    "    ROOT / \"linear_model_metrics.json\",  # baseline we printed earlier\n",
    "    ROOT / \"linear_model_metrics.json\",\n",
    "    ROOT / \"linear_model_coefficients.csv\",\n",
    "    ROOT / \"mlflow_models_summary.json\",\n",
    "    ROOT / \"mlflow_postfe_summary.json\",\n",
    "    ROOT / \"tree_models_summary.json\",\n",
    "    ROOT / \"lgbm_tuning_summary.json\",\n",
    "    ROOT / \"history_training_metrics.json\",\n",
    "    ROOT / \"optuna_native_outputs\" / \"optuna_summary.json\",\n",
    "    ROOT / \"optuna_native_outputs\" / \"optuna_study.pkl\"  # cannot load pickle, skip\n",
    "]\n",
    "seen = set([r['file'] for r in rows])\n",
    "for p in extra_files:\n",
    "    if p.exists():\n",
    "        rel = str(p.relative_to(ROOT))\n",
    "        if rel in seen:\n",
    "            continue\n",
    "        data = try_load_json(p)\n",
    "        metrics = extract_metrics(rel, data if data is not None else {})\n",
    "        rows.append({\n",
    "            \"model_key\": rel.replace('/', '_'),\n",
    "            \"file\": rel,\n",
    "            \"MAE\": metrics.get(\"MAE\", np.nan),\n",
    "            \"RMSE\": metrics.get(\"RMSE\", np.nan),\n",
    "            \"R2\": metrics.get(\"R2\", np.nan),\n",
    "            \"notes\": None\n",
    "        })\n",
    "        seen.add(rel)\n",
    "\n",
    "# 3) specifically include the history_training_metrics.json (we know it exists)\n",
    "hist = ROOT / \"history_training_metrics.json\"\n",
    "if hist.exists():\n",
    "    data = try_load_json(hist)\n",
    "    found = extract_metrics(\"history\", data if data is not None else {})\n",
    "    rows.append({\n",
    "        \"model_key\": \"agent_history\",\n",
    "        \"file\": str(hist.relative_to(ROOT)),\n",
    "        \"MAE\": found.get(\"MAE\", data.get(\"test_MAE\") if data and \"test_MAE\" in data else np.nan),\n",
    "        \"RMSE\": found.get(\"RMSE\", data.get(\"test_RMSE\") if data and \"test_RMSE\" in data else np.nan),\n",
    "        \"R2\": found.get(\"R2\", data.get(\"test_R2\") if data and \"test_R2\" in data else np.nan),\n",
    "        \"notes\": data.get(\"method_used\") if isinstance(data, dict) else None\n",
    "    })\n",
    "\n",
    "# 4) If MLflow runs exist under mlruns, read latest runs for experiments of interest\n",
    "mlruns_root = ROOT / \"mlruns\"\n",
    "if mlruns_root.exists():\n",
    "    try:\n",
    "        from mlflow.tracking import MlflowClient\n",
    "        client = MlflowClient(tracking_uri=str(mlruns_root.resolve().as_uri()))\n",
    "        for exp in client.list_experiments():\n",
    "            # get last run for this experiment\n",
    "            runs = client.search_runs(exp.experiment_id, order_by=[\"attributes.start_time DESC\"], max_results=5)\n",
    "            for r in runs:\n",
    "                # create a row per run but avoid duplicates\n",
    "                filetag = f\"mlflow:{exp.name}/{r.info.run_id}\"\n",
    "                if filetag in [x['file'] for x in rows]:\n",
    "                    continue\n",
    "                mm = {\"MAE\": np.nan, \"RMSE\": np.nan, \"R2\": np.nan}\n",
    "                # copy metrics if present\n",
    "                if hasattr(r, 'data') and r.data.metrics:\n",
    "                    mm['MAE'] = r.data.metrics.get('test_MAE', r.data.metrics.get('MAE', mm['MAE']))\n",
    "                    mm['RMSE'] = r.data.metrics.get('test_RMSE', r.data.metrics.get('RMSE', mm['RMSE']))\n",
    "                    mm['R2'] = r.data.metrics.get('test_R2', r.data.metrics.get('R2', mm['R2']))\n",
    "                rows.append({\n",
    "                    \"model_key\": f\"mlflow:{exp.name}\",\n",
    "                    \"file\": filetag,\n",
    "                    \"MAE\": mm['MAE'] if mm['MAE'] is not None else np.nan,\n",
    "                    \"RMSE\": mm['RMSE'] if mm['RMSE'] is not None else np.nan,\n",
    "                    \"R2\": mm['R2'] if mm['R2'] is not None else np.nan,\n",
    "                    \"notes\": exp.name\n",
    "                })\n",
    "    except Exception as e:\n",
    "        # ignore mlflow reading errors; we already relogged earlier\n",
    "        pass\n",
    "\n",
    "# Build DataFrame and clean up\n",
    "df_comp = pd.DataFrame(rows)\n",
    "if df_comp.empty:\n",
    "    print(\"No metric files found automatically. Please point me to the metrics JSON files if you want a comparison.\")\n",
    "else:\n",
    "    # normalize numeric columns\n",
    "    for col in [\"MAE\",\"RMSE\",\"R2\"]:\n",
    "        if col in df_comp.columns:\n",
    "            df_comp[col] = pd.to_numeric(df_comp[col], errors='coerce')\n",
    "    # sort by RMSE if available\n",
    "    if \"RMSE\" in df_comp.columns:\n",
    "        df_comp = df_comp.sort_values(\"RMSE\", ascending=True, na_position='last').reset_index(drop=True)\n",
    "\n",
    "    # save CSV\n",
    "    out_csv = OUT / \"model_comparison.csv\"\n",
    "    df_comp.to_csv(out_csv, index=False)\n",
    "    print(\"Saved model comparison CSV to:\", out_csv)\n",
    "\n",
    "    # make a readable markdown summary\n",
    "    md_lines = []\n",
    "    md_lines.append(\"# Model comparison  summary\\n\")\n",
    "    md_lines.append(f\"_Generated: {datetime.now().isoformat()}_\\n\")\n",
    "    md_lines.append(\"The table below aggregates available saved metrics (MAE / RMSE / R2) found in the project folder. Use this table to pick the best candidate for production.\\n\")\n",
    "    md_lines.append(\"| rank | model_key | file | MAE | RMSE | R2 | notes |\")\n",
    "    md_lines.append(\"|---:|---|---|---:|---:|---:|---|\")\n",
    "    for i, row in df_comp.iterrows():\n",
    "        md_lines.append(f\"| {i+1} | {row['model_key']} | {row['file']} | {row['MAE'] if not np.isnan(row['MAE']) else ''} | {row['RMSE'] if not np.isnan(row['RMSE']) else ''} | {row['R2'] if not np.isnan(row['R2']) else ''} | {row['notes'] if row['notes'] else ''} |\")\n",
    "\n",
    "    md_text = \"\\n\".join(md_lines)\n",
    "    md_path = OUT / \"model_comparison.md\"\n",
    "    md_path.write_text(md_text, encoding=\"utf-8\")\n",
    "    print(\"Saved markdown summary to:\", md_path)\n",
    "\n",
    "    # print a short console summary of the top 3 by RMSE (if RMSE exists)\n",
    "    print(\"\\nTop 3 models by RMSE (if available):\")\n",
    "    top3 = df_comp.dropna(subset=[\"RMSE\"]).nsmallest(3, \"RMSE\")\n",
    "    if top3.empty:\n",
    "        print(\"No RMSE values found in saved metrics  open specific metrics files.\")\n",
    "    else:\n",
    "        for i, r in top3.iterrows():\n",
    "            print(f\" {i+1}. {r['model_key']} -> RMSE={r['RMSE']:.3f}, MAE={r['MAE']:.3f}, R2={r['R2']:.3f} :: file={r['file']}\")\n",
    "\n",
    "print(\"\\nDone. Files written to:\", OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284afc32-433e-4b62-a42a-76f49ad72306",
   "metadata": {},
   "source": [
    "# Model comparison  summary\n",
    "\n",
    "_Generated: 2025-09-28T21:55:13.006115_\n",
    "\n",
    "The table below aggregates available saved metrics (MAE / RMSE / R2) found in the project folder. Use this table to pick the best candidate for production.\n",
    "\n",
    "| rank | model_key | file | MAE | RMSE | R2 | notes |\n",
    "|---:|---|---|---:|---:|---:|---|\n",
    "| 1 | baseline_linear | linear_model_metrics.json | 26.199269106727304 | 33.26708714044438 | 0.58456273301688 |  |\n",
    "| 2 | lgbm_tuning | lgbm_tuning_summary.json | 23.73340965125027 | 33.76228191749625 | 0.5721027604026586 |  |\n",
    "| 3 | lgbm_tuned_metrics | lgbm_tuning_summary.json | 23.73340965125027 | 33.76228191749625 | 0.5721027604026586 |  |\n",
    "| 4 | lgbm_native | lgbm_native_cat_summary.json | 23.67504075146352 | 33.78309273134831 | 0.5715750926178792 |  |\n",
    "| 5 | history_model | history_training_metrics.json | 23.805485531936476 | 33.89528774484167 | 0.5756897921185983 |  |\n",
    "| 6 | agent_history | history_training_metrics.json | 23.805485531936476 | 33.89528774484167 | 0.5756897921185983 | agent_index_rolling |\n",
    "| 7 | baseline_mlflow_summary | mlflow_models_summary.json |  |  |  |  |\n",
    "| 8 | post_feature_engineering | mlflow_postfe_summary.json |  |  |  |  |\n",
    "| 9 | tree_models | tree_models_summary.json |  |  |  |  |\n",
    "| 10 | shap_native | shap_native_outputs\\shap_native_summary.json |  |  |  |  |\n",
    "| 11 | linear_model_coefficients.csv | linear_model_coefficients.csv |  |  |  |  |\n",
    "| 12 | optuna_native_outputs\\optuna_study.pkl | optuna_native_outputs\\optuna_study.pkl |  |  |  |  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8bb1c5a2-4bf4-4646-adcd-76f9b66c932c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working dir: C:\\Users\\shail_u9zs758\n",
      "Loaded data shape: (43739, 39)\n",
      "Loaded model type: <class 'lightgbm.sklearn.LGBMRegressor'>\n",
      "Model expects 20 features. Example: ['distance_km', 'order_to_pickup_mins', 'Agent_Age', 'Agent_Rating_imputed', 'hour_sin', 'hour_cos', 'agent_7d_count', 'agent_7d_mean', 'agent_30d_count', 'agent_30d_mean']\n",
      "Loaded category_levels.json for category restoration.\n",
      "Constructed X_shap_full shape: (5000, 20)\n",
      "Feature alignment successful. Dtypes sample:\n",
      "distance_km              float64\n",
      "order_to_pickup_mins     float64\n",
      "Agent_Age                  int64\n",
      "Agent_Rating_imputed     float64\n",
      "hour_sin                 float64\n",
      "hour_cos                 float64\n",
      "agent_7d_count           float64\n",
      "agent_7d_mean            float64\n",
      "agent_30d_count          float64\n",
      "agent_30d_mean           float64\n",
      "Weather_imputed         category\n",
      "Traffic                 category\n",
      "Vehicle                 category\n",
      "Area                    category\n",
      "Category_grp            category\n",
      "dtype: object\n",
      "Creating TreeExplainer and computing SHAP (may take some time)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shail_u9zs758\\AppData\\Local\\Temp\\ipykernel_22756\\653237675.py:124: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if c in df.columns and (pd.api.types.is_categorical_dtype(df[c]) or pd.api.types.is_object_dtype(df[c])):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP computed. shape: (5000, 20)\n",
      "Saved top20 to: C:\\Users\\shail_u9zs758\\shap_final_outputs_aligned\\shap_aligned_top20.csv\n",
      "Saved sample SHAP CSV: C:\\Users\\shail_u9zs758\\shap_final_outputs_aligned\\shap_aligned_sample_values.csv\n",
      "Saved compressed SHAP array: C:\\Users\\shail_u9zs758\\shap_final_outputs_aligned\\shap_aligned_full.npz\n",
      "Saved summary plot: C:\\Users\\shail_u9zs758\\shap_final_outputs_aligned\\shap_aligned_summary.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/28 22:10:24 INFO mlflow.tracking.fluent: Experiment with name 'explainability_final_shap' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dependence plots: [WindowsPath('C:/Users/shail_u9zs758/shap_final_outputs_aligned/shap_aligned_dependence_Traffic_Weather.png'), WindowsPath('C:/Users/shail_u9zs758/shap_final_outputs_aligned/shap_aligned_dependence_Agent_Age.png'), WindowsPath('C:/Users/shail_u9zs758/shap_final_outputs_aligned/shap_aligned_dependence_Agent_Rating_imputed.png')]\n",
      "Saved summary json: C:\\Users\\shail_u9zs758\\shap_final_outputs_aligned\\shap_aligned_summary.json\n",
      "Logged shap artifacts to MLflow.\n",
      "\n",
      "=== Done. All SHAP artifacts are in: C:\\Users\\shail_u9zs758\\shap_final_outputs_aligned\n",
      "Top 10 features by mean |SHAP|:\n",
      "                feature  mean_abs_shap\n",
      "0       Traffic_Weather      13.544519\n",
      "1             Agent_Age      13.090216\n",
      "2  Agent_Rating_imputed      10.183570\n",
      "3           distance_km       9.395164\n",
      "4               Vehicle       5.388113\n",
      "5            CatTraffic       4.550448\n",
      "6       Weather_imputed       3.032434\n",
      "7          Category_grp       1.975678\n",
      "8       distance_bucket       1.755210\n",
      "9        Area_PartOfDay       1.275955\n"
     ]
    }
   ],
   "source": [
    "# === Robust SHAP run that aligns features to the trained LightGBM model ===\n",
    "import os, json, joblib, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ROOT = Path(r\"C:\\Users\\shail_u9zs758\")\n",
    "MODEL_FILE = ROOT / \"lgbm_history_tuned.joblib\"\n",
    "DATA_FILE = ROOT / \"amazon_delivery_with_history.csv\"\n",
    "OUT_DIR = ROOT / \"shap_final_outputs_aligned\"\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "MAX_SHAP_ROWS = 5000\n",
    "SAMPLE_SEED = 42\n",
    "\n",
    "print(\"Working dir:\", ROOT)\n",
    "if not MODEL_FILE.exists():\n",
    "    raise FileNotFoundError(\"Model not found: \" + str(MODEL_FILE))\n",
    "if not DATA_FILE.exists():\n",
    "    raise FileNotFoundError(\"Data not found: \" + str(DATA_FILE))\n",
    "\n",
    "# load dataset and model\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "model = joblib.load(MODEL_FILE)\n",
    "print(\"Loaded data shape:\", df.shape)\n",
    "print(\"Loaded model type:\", type(model))\n",
    "\n",
    "# retrieve model feature names (robust for LGBM scikit-learn wrapper or Booster)\n",
    "model_feature_names = None\n",
    "try:\n",
    "    # scikit-learn LGBMRegressor exposes booster_.feature_name()\n",
    "    if hasattr(model, \"booster_\") and model.booster_ is not None:\n",
    "        model_feature_names = model.booster_.feature_name()\n",
    "    elif hasattr(model, \"feature_name_\"):\n",
    "        model_feature_names = model.feature_name_\n",
    "    else:\n",
    "        # fallback: try attribute 'feature_name' (LightGBM native)\n",
    "        model_feature_names = getattr(model, \"feature_name\", None)\n",
    "except Exception:\n",
    "    model_feature_names = None\n",
    "\n",
    "if not model_feature_names:\n",
    "    # Try to load a saved list if you have 'category_levels.json' or 'feature_names.json'\n",
    "    fallback_file = ROOT / \"category_levels.json\"\n",
    "    if fallback_file.exists():\n",
    "        print(\"Loading category_levels.json for feature names fallback.\")\n",
    "        cat_levels = json.loads(fallback_file.read_text(encoding=\"utf-8\"))\n",
    "        # sometimes we stored a 'feature_names' key there; else assume top keys\n",
    "        model_feature_names = cat_levels.get(\"feature_names\", list(cat_levels.keys()))\n",
    "    else:\n",
    "        raise RuntimeError(\"Could not determine model feature names. Model object lacks feature info.\")\n",
    "\n",
    "model_feature_names = list(model_feature_names)\n",
    "print(\"Model expects\", len(model_feature_names), \"features. Example:\", model_feature_names[:10])\n",
    "\n",
    "# target detection\n",
    "target_candidates = [\"Delivery_Time\",\"delivery_time\",\"DeliveryTime\",\"target\"]\n",
    "target_col = next((c for c in target_candidates if c in df.columns), None)\n",
    "if target_col is None:\n",
    "    raise ValueError(\"Target column not found in data file.\")\n",
    "\n",
    "# Build X_shap_full with exact model feature columns, preserving order\n",
    "# Start with an empty DF indexed by a sample from df\n",
    "n_rows = min(MAX_SHAP_ROWS, len(df))\n",
    "rng = np.random.RandomState(SAMPLE_SEED)\n",
    "sample_idx = rng.choice(df.index, size=n_rows, replace=False)\n",
    "df_sample = df.loc[sample_idx].copy().reset_index(drop=True)\n",
    "\n",
    "# We'll try to infer columns type from the training dataset if possible:\n",
    "# If category_levels.json exists, it may contain category lists for categorical columns\n",
    "category_levels_file = ROOT / \"category_levels.json\"\n",
    "category_levels = {}\n",
    "if category_levels_file.exists():\n",
    "    try:\n",
    "        category_levels = json.loads(category_levels_file.read_text(encoding=\"utf-8\"))\n",
    "        print(\"Loaded category_levels.json for category restoration.\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not load category_levels.json:\", e)\n",
    "\n",
    "# Build X_shap_full by iterating model_feature_names\n",
    "X_cols = {}\n",
    "for feat in model_feature_names:\n",
    "    if feat in df_sample.columns:\n",
    "        X_cols[feat] = df_sample[feat].copy()\n",
    "    else:\n",
    "        # feature missing from sample/data  decide fallback\n",
    "        # If category_levels contains levels for this feature, use its most common level\n",
    "        if feat in category_levels and isinstance(category_levels[feat], list) and len(category_levels[feat])>0:\n",
    "            fill_val = category_levels[feat][0]  # most frequent stored first usually\n",
    "            X_cols[feat] = pd.Series([fill_val]*len(df_sample))\n",
    "        else:\n",
    "            # infer from original df: if feature exists anywhere in df (maybe in full df), use mode/median\n",
    "            if feat in df.columns:\n",
    "                # shouldn't reach but be safe\n",
    "                col = df[feat]\n",
    "                if pd.api.types.is_numeric_dtype(col):\n",
    "                    X_cols[feat] = pd.Series([float(col.median())]*len(df_sample))\n",
    "                else:\n",
    "                    mode = col.mode(dropna=True)\n",
    "                    fill_val = mode.iloc[0] if len(mode)>0 else \"unknown\"\n",
    "                    X_cols[feat] = pd.Series([fill_val]*len(df_sample))\n",
    "            else:\n",
    "                # completely missing column  decide numeric vs categorical by suffix heuristics\n",
    "                if any(tok in feat.lower() for tok in ['count','mean','_cnt','_mean','agent','global','hour','sin','cos','distance','km','mins','rating']):\n",
    "                    # numeric fallback\n",
    "                    X_cols[feat] = pd.Series([0.0]*len(df_sample))\n",
    "                else:\n",
    "                    X_cols[feat] = pd.Series([\"unknown\"]*len(df_sample))\n",
    "\n",
    "# Assemble dataframe in exact order\n",
    "X_shap_full = pd.DataFrame(X_cols, columns=model_feature_names)\n",
    "print(\"Constructed X_shap_full shape:\", X_shap_full.shape)\n",
    "\n",
    "# Now coerce dtypes for categorical features:\n",
    "# Use category_levels mapping if present to set categories; otherwise if column in original df is object/categorical\n",
    "for c in X_shap_full.columns:\n",
    "    # if category_levels has explicit categories for column\n",
    "    if c in category_levels and isinstance(category_levels[c], list):\n",
    "        cats = category_levels[c]\n",
    "        X_shap_full[c] = pd.Categorical(X_shap_full[c], categories=cats)\n",
    "    else:\n",
    "        # if original df had this column and dtype was object/categorical -> cast to category\n",
    "        if c in df.columns and (pd.api.types.is_categorical_dtype(df[c]) or pd.api.types.is_object_dtype(df[c])):\n",
    "            X_shap_full[c] = X_shap_full[c].astype('category')\n",
    "        else:\n",
    "            # try numeric conversion if majority numeric-like\n",
    "            try:\n",
    "                X_shap_full[c] = pd.to_numeric(X_shap_full[c])\n",
    "            except Exception:\n",
    "                # leave as is (string)\n",
    "                X_shap_full[c] = X_shap_full[c].astype('category')\n",
    "\n",
    "# Quick check: number of features matches model\n",
    "if X_shap_full.shape[1] != len(model_feature_names):\n",
    "    raise RuntimeError(f\"Feature alignment failed: X has {X_shap_full.shape[1]} cols, model expects {len(model_feature_names)}\")\n",
    "\n",
    "print(\"Feature alignment successful. Dtypes sample:\")\n",
    "print(X_shap_full.dtypes.head(15))\n",
    "\n",
    "# Now compute SHAP values\n",
    "try:\n",
    "    import shap\n",
    "except Exception as e:\n",
    "    raise ImportError(\"Please install shap (pip install shap). Error: \" + str(e))\n",
    "\n",
    "print(\"Creating TreeExplainer and computing SHAP (may take some time)...\")\n",
    "explainer = shap.TreeExplainer(model)\n",
    "# shap_values will match the number of features\n",
    "shap_values = explainer.shap_values(X_shap_full)\n",
    "if isinstance(shap_values, list):\n",
    "    shap_arr = np.array(shap_values[0])\n",
    "else:\n",
    "    shap_arr = np.array(shap_values)\n",
    "print(\"SHAP computed. shape:\", shap_arr.shape)\n",
    "\n",
    "# Compute mean abs shap and save outputs as before\n",
    "mean_abs_shap = np.mean(np.abs(shap_arr), axis=0)\n",
    "feat_imp = pd.DataFrame({\"feature\": model_feature_names, \"mean_abs_shap\": mean_abs_shap}).sort_values(\"mean_abs_shap\", ascending=False).reset_index(drop=True)\n",
    "top20 = feat_imp.head(20)\n",
    "top20_path = OUT_DIR / \"shap_aligned_top20.csv\"\n",
    "top20.to_csv(top20_path, index=False)\n",
    "print(\"Saved top20 to:\", top20_path)\n",
    "\n",
    "# compressed full array & sample CSV\n",
    "npz_path = OUT_DIR / \"shap_aligned_full.npz\"\n",
    "np.savez_compressed(npz_path, shap=shap_arr, features=np.array(model_feature_names), index=np.array(df_sample.index))\n",
    "sample_vals = pd.DataFrame(shap_arr, columns=model_feature_names, index=df_sample.index)\n",
    "sample_csv = OUT_DIR / \"shap_aligned_sample_values.csv\"\n",
    "sample_vals.to_csv(sample_csv, index=True)\n",
    "print(\"Saved sample SHAP CSV:\", sample_csv)\n",
    "print(\"Saved compressed SHAP array:\", npz_path)\n",
    "\n",
    "# summary plot (bar)\n",
    "plt.figure(figsize=(8,6))\n",
    "plot_df = feat_imp.head(30).sort_values(\"mean_abs_shap\")\n",
    "plt.barh(plot_df[\"feature\"], plot_df[\"mean_abs_shap\"])\n",
    "plt.xlabel(\"mean |SHAP value|\")\n",
    "plt.title(\"SHAP feature importance (aligned)  final model\")\n",
    "plt.tight_layout()\n",
    "summary_png = OUT_DIR / \"shap_aligned_summary.png\"\n",
    "plt.savefig(summary_png, dpi=200); plt.close()\n",
    "print(\"Saved summary plot:\", summary_png)\n",
    "\n",
    "# dependence plots for top 3 features (attempt)\n",
    "top_feats = top20['feature'].tolist()[:3]\n",
    "dep_paths = []\n",
    "for feat in top_feats:\n",
    "    try:\n",
    "        plt.figure(figsize=(8,6))\n",
    "        shap.dependence_plot(feat, shap_arr, X_shap_full, show=False)\n",
    "        p = OUT_DIR / f\"shap_aligned_dependence_{feat}.png\"\n",
    "        plt.title(f\"Dependence: {feat}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(p, dpi=200); plt.close()\n",
    "        dep_paths.append(p)\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Could not create dependence plot for {feat}: {e}\")\n",
    "\n",
    "print(\"Saved dependence plots:\", dep_paths)\n",
    "\n",
    "# JSON summary\n",
    "summary = {\n",
    "    \"n_rows\": int(n_rows),\n",
    "    \"model_features_count\": len(model_feature_names),\n",
    "    \"top3\": top_feats,\n",
    "    \"top20_csv\": str(top20_path.relative_to(ROOT)),\n",
    "    \"summary_png\": str(summary_png.relative_to(ROOT)),\n",
    "    \"dependence_plots\": [str(p.relative_to(ROOT)) for p in dep_paths]\n",
    "}\n",
    "(OUT_DIR / \"shap_aligned_summary.json\").write_text(json.dumps(summary, indent=2))\n",
    "print(\"Saved summary json:\", OUT_DIR / \"shap_aligned_summary.json\")\n",
    "\n",
    "# try logging to MLflow (graceful)\n",
    "try:\n",
    "    import mlflow\n",
    "    mlruns_dir = ROOT / \"mlruns\"\n",
    "    mlflow.set_tracking_uri(mlruns_dir.resolve().as_uri())\n",
    "    mlflow.set_experiment(\"explainability_final_shap\")\n",
    "    with mlflow.start_run(run_name=\"shap_aligned_run\"):\n",
    "        mlflow.log_artifact(str(top20_path), artifact_path=\"shap\")\n",
    "        mlflow.log_artifact(str(summary_png), artifact_path=\"shap\")\n",
    "        for p in dep_paths:\n",
    "            mlflow.log_artifact(str(p), artifact_path=\"shap\")\n",
    "        mlflow.log_artifact(str(sample_csv), artifact_path=\"shap\")\n",
    "        mlflow.log_artifact(str(npz_path), artifact_path=\"shap\")\n",
    "        mlflow.log_artifact(str(OUT_DIR / \"shap_aligned_summary.json\"), artifact_path=\"shap\")\n",
    "    print(\"Logged shap artifacts to MLflow.\")\n",
    "except Exception as e:\n",
    "    print(\"MLflow logging skipped/failed:\", e)\n",
    "\n",
    "print(\"\\n=== Done. All SHAP artifacts are in:\", OUT_DIR)\n",
    "print(\"Top 10 features by mean |SHAP|:\")\n",
    "print(top20.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892fd04b-4015-4075-a98c-60cc95860b4d",
   "metadata": {},
   "source": [
    "## Top 10 SHAP Features (Final Model)\n",
    "\n",
    "| Rank | Feature               | Mean \\|SHAP\\| | Interpretation |\n",
    "|------|-----------------------|---------------:|----------------|\n",
    "| 1    | **Traffic_Weather**   | 13.54          | Combined condition of traffic & weather is the **strongest driver** of delivery time. Bad weather + high traffic greatly increases predicted delays. |\n",
    "| 2    | **Agent_Age**         | 13.09          | Older delivery agents tend to take more (or less, depending on direction) time; age strongly influences efficiency. |\n",
    "| 3    | **Agent_Rating_imputed** | 10.18       | Customer/ops rating captures reliability. Higher-rated agents tend to be faster/more consistent. |\n",
    "| 4    | **distance_km**       | 9.39           | Longer distances naturally increase delivery time, but its effect is *non-linear* (trees pick that up). |\n",
    "| 5    | **Vehicle**           | 5.39           | Mode of transport (bike, van, motorcycle) directly impacts speed  motorcycles likely faster in traffic, vans slower. |\n",
    "| 6    | **CatTraffic**        | 4.55           | Interaction between product category and traffic  some items are more delay-prone in heavy traffic (e.g. bulky packages). |\n",
    "| 7    | **Weather_imputed**   | 3.03           | Specific weather types (rain, fog, sunny) individually matter; e.g., rain slows delivery beyond traffic effects. |\n",
    "| 8    | **Category_grp**      | 1.98           | Type of product (Grocery, Electronics, Apparel) matters  groceries may need faster handling vs. bulky items. |\n",
    "| 9    | **distance_bucket**   | 1.76           | Distance groupings add extra interpretability: short vs. long trips behave differently. |\n",
    "| 10   | **Area_PartOfDay**    | 1.28           | Area  Time-of-day interactions show urban rush hours vs. suburban late hours have distinct patterns. |\n",
    "\n",
    "---\n",
    "\n",
    "## Insights\n",
    "\n",
    "1. **External conditions dominate**  \n",
    "   Traffic & weather (together and separately) explain the largest share of variance. This matches business intuition: delays are environment-driven.\n",
    "\n",
    "2. **Agent factors matter**  \n",
    "   Agent age & rating are nearly as influential as distance itself. This highlights the role of **human efficiency**.\n",
    "\n",
    "3. **Distance is strong but not dominant**  \n",
    "   Its important, but environmental and agent factors combined are even stronger.\n",
    "\n",
    "4. **Category & vehicle effects**  \n",
    "   Specific product types and delivery vehicles affect predictability (bulky items + van in traffic are worst-case scenarios).\n",
    "\n",
    "---\n",
    "\n",
    "## Recommended Actions (Project / Business)\n",
    "\n",
    "- **Data collection focus**: Ensure reliable logs of weather, traffic, and agent ratings  these are critical signals.  \n",
    "- **Ops levers**: Optimize assignment  match high-rated/younger agents + motorcycles for traffic-heavy grocery deliveries.  \n",
    "- **Model improvement**: Consider adding *real-time traffic speed indices* or *live weather severity levels* for even better accuracy.  \n",
    "- **Explainability**: Use these SHAP plots in your report / Streamlit app to justify why the model predicts longer times in certain scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2f56e41-5edf-4582-b13c-4d500d51ff49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shail_u9zs758\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\pyfunc\\utils\\data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n",
      "2025/09/29 21:12:33 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37eb61cc75d8467394aeed926f7f637e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/29 21:12:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run logged, run_id: 6e89f004939146c890b3119c2926ad37\n",
      "Model logged and registration attempted. Open MLflow UI to confirm.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'lgbm_native_cat_prod' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'lgbm_native_cat_prod'.\n"
     ]
    }
   ],
   "source": [
    "# mlflow_register_model.py\n",
    "from pathlib import Path\n",
    "import mlflow, joblib, json\n",
    "ROOT = Path(r\"C:\\Users\\shail_u9zs758\").resolve()\n",
    "\n",
    "# path to local joblib\n",
    "local_model = ROOT / \"lgbm_history_tuned.joblib\"\n",
    "if not local_model.exists():\n",
    "    raise FileNotFoundError(local_model)\n",
    "\n",
    "# ensure mlruns tracking uri uses file:/// form\n",
    "mlruns_dir = (ROOT / \"mlruns\").resolve()\n",
    "mlflow.set_tracking_uri(mlruns_dir.as_uri())\n",
    "\n",
    "# Create a small run and log the local model as pyfunc wrapper\n",
    "from mlflow.pyfunc import PythonModel, PyFuncModel\n",
    "import os\n",
    "\n",
    "class SimplePyfuncModel(PythonModel):\n",
    "    def load_context(self, context):\n",
    "        import joblib\n",
    "        self.model = joblib.load(context.artifacts[\"model_path\"])\n",
    "    def predict(self, context, model_input):\n",
    "        # model_input is a pandas DataFrame\n",
    "        return self.model.predict(model_input)\n",
    "\n",
    "with mlflow.start_run(run_name=\"register_lgbm_history_as_pyfunc\"):\n",
    "    mlflow.log_artifact(str(local_model), artifact_path=\"model_artifacts\")\n",
    "    artifacts = {\"model_path\": str(local_model)}\n",
    "    # This will attempt to save a pyfunc model that references the joblib artifact\n",
    "    mlflow.pyfunc.log_model(artifact_path=\"pyfunc_model\", python_model=SimplePyfuncModel(), artifacts=artifacts, registered_model_name=\"lgbm_native_cat_prod\")\n",
    "    run_id = mlflow.active_run().info.run_id\n",
    "    print(\"Run logged, run_id:\", run_id)\n",
    "    print(\"Model logged and registration attempted. Open MLflow UI to confirm.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e11316c-6cf1-497d-9c90-eba06346c2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered model: lgbm_native_cat_prod\n",
      "version: 2 stage: None run_id: 6e89f004939146c890b3119c2926ad37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shail_u9zs758\\AppData\\Local\\Temp\\ipykernel_22756\\3680185502.py:12: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  versions = client.get_latest_versions(\"lgbm_native_cat_prod\")\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "mlflow.set_tracking_uri(\"file:///C:/Users/shail_u9zs758/mlruns\")\n",
    "client = MlflowClient()\n",
    "\n",
    "# metadata about the registered model\n",
    "rm = client.get_registered_model(\"lgbm_native_cat_prod\")\n",
    "print(\"Registered model:\", rm.name)\n",
    "\n",
    "# list versions\n",
    "versions = client.get_latest_versions(\"lgbm_native_cat_prod\")\n",
    "for v in versions:\n",
    "    print(\"version:\", v.version, \"stage:\", v.current_stage, \"run_id:\", v.run_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "075f465a-8a2b-4264-a8f7-c649f190f002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [129.91857456]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shail_u9zs758\\AppData\\Local\\Temp\\ipykernel_22756\\3856461590.py:26: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(df[c]) or df[c].dtype == object:\n"
     ]
    }
   ],
   "source": [
    "# align_and_predict.py  -- run inside your project folder\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "ROOT = Path(r\"C:\\Users\\shail_u9zs758\")\n",
    "CAT_FILE = ROOT / \"category_levels.json\"        # you already have this\n",
    "MODEL_URI = \"models:/lgbm_native_cat_prod/1\"    # or use runs:/<run_id>/pyfunc_model\n",
    "\n",
    "def prepare_input(df, category_levels, feature_order=None):\n",
    "    # Ensure df is a DataFrame\n",
    "    df = pd.DataFrame(df).copy()\n",
    "\n",
    "    # 1) Add missing categorical cols (use first saved category as safe fill)\n",
    "    for col, cats in category_levels.items():\n",
    "        if col in df.columns:\n",
    "            # cast to categorical with the exact categories/order from training\n",
    "            df[col] = pd.Categorical(df[col], categories=cats)\n",
    "        else:\n",
    "            # create a column filled with the first category (safe default)\n",
    "            df[col] = pd.Categorical([cats[0]] * len(df), categories=cats)\n",
    "\n",
    "    # 2) Fill missing numeric columns (median) and categorical NAs (first category)\n",
    "    for c in df.columns:\n",
    "        if pd.api.types.is_categorical_dtype(df[c]) or df[c].dtype == object:\n",
    "            # if category, fillna with first known category for that column if available\n",
    "            if c in category_levels and len(category_levels[c])>0:\n",
    "                fill = category_levels[c][0]\n",
    "            else:\n",
    "                mode = df[c].mode(dropna=True)\n",
    "                fill = mode.iloc[0] if len(mode)>0 else \"unknown\"\n",
    "            df[c] = df[c].fillna(fill)\n",
    "            df[c] = pd.Categorical(df[c], categories=(category_levels.get(c) if c in category_levels else None))\n",
    "        else:\n",
    "            # numeric fallback\n",
    "            try:\n",
    "                med = df[c].median(skipna=True)\n",
    "                if pd.isna(med):\n",
    "                    med = 0.0\n",
    "            except Exception:\n",
    "                med = 0.0\n",
    "            df[c] = df[c].fillna(med)\n",
    "\n",
    "    # 3) If feature_order provided, ensure exact order and create any missing features\n",
    "    if feature_order:\n",
    "        for feat in feature_order:\n",
    "            if feat not in df.columns:\n",
    "                # create numeric 0 or categorical default\n",
    "                if feat in category_levels:\n",
    "                    df[feat] = pd.Categorical([category_levels[feat][0]] * len(df), categories=category_levels[feat])\n",
    "                else:\n",
    "                    df[feat] = 0.0\n",
    "        df = df[feature_order]  # reorder to exactly what model expects\n",
    "\n",
    "    return df\n",
    "\n",
    "# ------------------ load model and category levels ------------------\n",
    "mlflow.set_tracking_uri((ROOT / \"mlruns\").resolve().as_uri())\n",
    "model = mlflow.pyfunc.load_model(MODEL_URI)\n",
    "\n",
    "# load category levels (dict: column -> [cat1, cat2, ...])\n",
    "with open(CAT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    cat_levels = json.load(f)\n",
    "\n",
    "# OPTIONAL: if you saved training feature order in the json, use it:\n",
    "feature_order = cat_levels.get(\"feature_names\") if isinstance(cat_levels, dict) and \"feature_names\" in cat_levels else None\n",
    "\n",
    "# ------------------ example sample (use your real sample) ------------------\n",
    "sample_df = pd.DataFrame([{\n",
    "    \"distance_km\": 10,\n",
    "    \"order_to_pickup_mins\": 8,\n",
    "    \"Agent_Age\": 28,\n",
    "    \"Agent_Rating_imputed\": 4.5,\n",
    "    \"hour_sin\": 0.5,\n",
    "    \"hour_cos\": 0.86,\n",
    "    \"Weather_imputed\": \"Cloudy\",\n",
    "    \"Traffic\": \"High\",\n",
    "    \"Vehicle\": \"motorcycle\",\n",
    "    \"Area\": \"Urban\",\n",
    "    \"Category_grp\": \"Grocery\"\n",
    "    # add agent_7d_count/agent_30d_mean/etc if model expects them\n",
    "}])\n",
    "\n",
    "# prepare input so categories + order match training\n",
    "X = prepare_input(sample_df, cat_levels, feature_order=feature_order)\n",
    "\n",
    "# predict\n",
    "preds = model.predict(X)\n",
    "print(\"preds:\", preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85adff15-50a7-4a02-aee1-64e52866a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted delivery time: 129.9 minutes    2h 10m\n"
     ]
    }
   ],
   "source": [
    "# convert minutes -> \"Hh Mm\" and print nicely\n",
    "pred_min = 129.91857456\n",
    "pred_min_rounded = round(max(0.0, pred_min), 1)\n",
    "hours = int(pred_min_rounded // 60)\n",
    "mins = int(round(pred_min_rounded % 60))\n",
    "print(f\"Predicted delivery time: {pred_min_rounded} minutes    {hours}h {mins}m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe8bb56-dcc7-4b1a-a3c9-4040bf4c6e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
